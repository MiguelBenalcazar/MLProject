{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from itertools import product\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataFinal():\n",
    "    def __init__(self):\n",
    "        self.original = pd.read_csv('../html2023-spring-final-project/train.csv')\n",
    "        self.orginDataset = self.original.copy()\n",
    "        self.get_labels()\n",
    "        data = self.dataPreprocessing(self.original)\n",
    "        self.createEncodeDataTraining(data)\n",
    "        self.splitDataset()\n",
    "\n",
    "        self.originalTest = pd.read_csv('../html2023-spring-final-project/test.csv')\n",
    "        datatest = self.dataPreprocessing(self.originalTest)\n",
    "        self.createEncodeDataTesting(datatest) \n",
    "        self.testDatasetFile()  \n",
    "\n",
    "      \n",
    "\n",
    "    def get_labels(self):\n",
    "        self.labels = self.original['Danceability']\n",
    "        self.original.drop(['Danceability'], axis=1, inplace=True) \n",
    "\n",
    "    def fillOptions(self, data, option = 'max'):\n",
    "        if data.isna().sum() != len(data):\n",
    "            if option == 'max':\n",
    "                return data.value_counts().idxmax()\n",
    "            elif option == 'mean':\n",
    "                return data.mean()\n",
    "            elif option == 'median':\n",
    "                return data.median()\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "    def filterArtistComposerDance(self, data, nameColumnFill):\n",
    "\n",
    "        listArtist = data['Artist'].unique()\n",
    "        listComposer = data['Composer'].unique()\n",
    "    \n",
    "        filter = list(product(listArtist, listComposer))\n",
    "\n",
    "        newData = pd.DataFrame(columns=data.columns)\n",
    "\n",
    "        for i in filter:\n",
    "            artist, composer = i[0], i[1]\n",
    "            filterData = data[(data['Artist'] == artist) & (data['Composer'] == composer) ].copy()\n",
    "            if len(filterData) != 0:\n",
    "            # Fill column Name\n",
    "                for nameColumn in nameColumnFill:\n",
    "                    fillInfo = self.fillOptions(filterData[nameColumn], option = 'max')\n",
    "                    if fillInfo != None:\n",
    "                        filterData.loc[:,nameColumn].fillna(fillInfo, inplace=True)\n",
    "\n",
    "                newData = pd.concat([newData, filterData], ignore_index=True)\n",
    "        return newData\n",
    "    \n",
    "    def filterArtist(self, data, nameColumnFill):\n",
    "        listDance = data['Artist'].unique()\n",
    "        filter = listDance\n",
    "\n",
    "\n",
    "        newData = pd.DataFrame(columns=data.columns)\n",
    "\n",
    "        for i in filter:\n",
    "            dance = i\n",
    "            filterData = data[ (data['Artist'] == dance)].copy()\n",
    "    \n",
    "    \n",
    "            if len(filterData) != 0:\n",
    "                # Fill column Name\n",
    "                for nameColumn in nameColumnFill:\n",
    "                    fillInfo = self.fillOptions(filterData[nameColumn], option = 'max')\n",
    "                    if fillInfo != None:\n",
    "                        filterData.loc[:,nameColumn].fillna(fillInfo, inplace=True)\n",
    "\n",
    "                newData = pd.concat([newData, filterData], ignore_index=True)\n",
    "\n",
    "        return newData\n",
    "    \n",
    "    def filterFillData(self, data, nameColumnFill):\n",
    "        if not data.isnull().any().any():\n",
    "            return data\n",
    "        else:\n",
    "            for nameColumn in nameColumnFill:\n",
    "                fillInfo = self.fillOptions(data[nameColumn], option = 'max')\n",
    "                if fillInfo != None:\n",
    "                    data.loc[:,nameColumn].fillna(fillInfo, inplace=True)\n",
    "        return data\n",
    "    \n",
    "    def dataPreprocessing(self, original):\n",
    "    \n",
    "        # pd.options.mode.chained_assignment = None\n",
    "\n",
    "        data = original.copy()\n",
    "\n",
    "        nameColumnFill = ['Energy', 'Key', 'Loudness', 'Speechiness', 'Acousticness', 'Instrumentalness', 'Liveness', 'Valence', 'Tempo', 'Duration_ms', 'Duration_ms', 'Views', 'Likes', \"Stream\" , \"Comments\"]\n",
    "\n",
    "        # License and official_video\n",
    "        data['Licensed'].fillna(data['official_video'], inplace=True)\n",
    "        data['Licensed'].fillna(False, inplace=True)\n",
    "\n",
    "        data['official_video'].fillna(data['Licensed'], inplace=True)\n",
    "        data['official_video'].fillna(False, inplace=True)\n",
    "\n",
    "        data['official_video'].fillna(False, inplace=True)\n",
    "        data['Licensed'].fillna(False, inplace=True)\n",
    "\n",
    "        data['Licensed'] =  data['Licensed'].map({True: 1, False: 0})\n",
    "        data['official_video'] = data['official_video'].map({True: 1, False: 0})\n",
    "    \n",
    "        # Create new class = 'Unknown'\n",
    "        data['Composer'].fillna(\"Unknown\", inplace=True)\n",
    "        data['Artist'].fillna(\"Unknown\", inplace=True)\n",
    "        data['Album_type'].fillna(\"Unknown\", inplace=True)\n",
    "\n",
    "        newData = self.filterArtistComposerDance(data, nameColumnFill)\n",
    "        data = newData.copy()\n",
    "\n",
    "        newData = self.filterArtist(data, nameColumnFill)\n",
    "        data = newData.copy()\n",
    "\n",
    "        newData = self.filterFillData(data, nameColumnFill)\n",
    "        data = newData.copy()\n",
    "\n",
    "        #Transform type key to use as class\n",
    "        data['Key'] = data['Key'].astype(int)\n",
    "        data['Key'] = data['Key'].astype(str)\n",
    "\n",
    "        data = data.sort_values('id')\n",
    "\n",
    "        # DELETE Track, Album, Uri, Url_spotify, Url_youtube, Description, Title, Channel, id, Comments\n",
    "        data.drop(['Track', 'Album', 'Uri', 'Url_spotify', 'Url_youtube', 'Description', 'Title', 'Channel', 'id'], axis=1, inplace=True)\n",
    "\n",
    "        # pd.options.mode.chained_assignment = 'warn'\n",
    "\n",
    "        return data\n",
    "    \n",
    "    def convertEncoderPD(self, data, prefix = 'key'):\n",
    "        titleKeys = []\n",
    "        for i in range(data.shape[1]):\n",
    "            titleKeys.append(f'{prefix}_{i}')\n",
    "    \n",
    "        return pd.DataFrame(data=data, columns= titleKeys)\n",
    "    \n",
    "    # minX -60  maxX = 0  ~ 0 - 1\n",
    "    # y = (-1/60) x\n",
    "    def scaleMinMaxLoudness(self, data):\n",
    "        return -data/60\n",
    "    \n",
    "    def createEncodeDataTraining(self, data):\n",
    "\n",
    "        encoderKey = OneHotEncoder()\n",
    "        encodedKey = encoderKey.fit_transform(data[['Key']])\n",
    "        Key = encodedKey.toarray()\n",
    "        key_pd = self.convertEncoderPD(Key, prefix = 'key')\n",
    "\n",
    "        encoderAlbumType = OneHotEncoder()\n",
    "        encodedKeyAlbumType = encoderAlbumType.fit_transform(data[['Album_type']])\n",
    "        AlbumType = encodedKeyAlbumType.toarray()\n",
    "        AlbumType_pd = self.convertEncoderPD(AlbumType, prefix = 'AlbumType')\n",
    "\n",
    "        encoderComposer = OneHotEncoder()\n",
    "        encodedKeyComposer = encoderComposer.fit_transform(data[['Composer']])\n",
    "        Composer = encodedKeyComposer.toarray()\n",
    "        Composer_pd = self.convertEncoderPD(Composer, prefix = 'Composer')\n",
    "\n",
    "        encoderArtist = OneHotEncoder()\n",
    "        encodedArtist = encoderArtist.fit_transform(data[['Artist']])\n",
    "        Artist =  encodedArtist.toarray()\n",
    "        Artist_pd = self.convertEncoderPD(Artist, prefix = 'Artist')\n",
    "\n",
    "        # encoderArtist = LabelEncoder()\n",
    "        # encodedArtist = encoderArtist.fit_transform(data[['Artist']])\n",
    "        # # encodedArtist = encodedArtist.ravel()\n",
    "        # Artist_pd =  pd.DataFrame(data=encodedArtist, columns= [\"Artist\"])\n",
    "\n",
    "        data.drop(['Key','Album_type', 'Composer',  'Artist'], axis=1, inplace=True)\n",
    "\n",
    "        data = pd.concat([data, key_pd, AlbumType_pd, Composer_pd, Artist_pd], axis=1)\n",
    "\n",
    "        scaledLoudness = self.scaleMinMaxLoudness(data[['Loudness']])\n",
    "        data['Loudness'] = scaledLoudness\n",
    "\n",
    "        newMinMaxScaler = ['Tempo', 'Duration_ms', 'Views', 'Likes', 'Stream', 'Comments']\n",
    "\n",
    "        scaler = MinMaxScaler()\n",
    "        scaledData = scaler.fit_transform(data[newMinMaxScaler])\n",
    "\n",
    "        for i in range(scaledData.shape[1]):\n",
    "            data[newMinMaxScaler[i]] = scaledData[:, i]\n",
    "\n",
    "\n",
    "        self.dataEncoders = {\"key\": encoderKey, 'AlbumType': encoderAlbumType, 'Composer': encoderComposer, \"Artist\":encoderArtist}\n",
    "        self.stdScaler = scaler\n",
    "        self.data = data\n",
    "\n",
    "    def createEncodeDataTesting(self, data):\n",
    "\n",
    "        encoderKey = self.dataEncoders['key']\n",
    "        encodedKey = encoderKey.transform(data[['Key']])\n",
    "        Key = encodedKey.toarray()\n",
    "        key_pd = self.convertEncoderPD(Key, prefix = 'key')\n",
    "\n",
    "        encoderAlbumType = self.dataEncoders['AlbumType']\n",
    "        encodedKeyAlbumType = encoderAlbumType.transform(data[['Album_type']])\n",
    "        AlbumType = encodedKeyAlbumType.toarray()\n",
    "        AlbumType_pd = self.convertEncoderPD(AlbumType, prefix = 'AlbumType')\n",
    "\n",
    "        encoderComposer = self.dataEncoders['Composer']\n",
    "        encodedKeyComposer = encoderComposer.transform(data[['Composer']])\n",
    "        Composer = encodedKeyComposer.toarray()\n",
    "        Composer_pd = self.convertEncoderPD(Composer, prefix = 'Composer')  \n",
    "\n",
    "        encoderArtist = self.dataEncoders['Artist']\n",
    "        encodedArtist = encoderArtist.fit_transform(data[['Artist']])\n",
    "        Artist =  encodedArtist.toarray()\n",
    "        Artist_pd = self.convertEncoderPD(Artist, prefix = 'Artist') \n",
    "\n",
    "        # encoderArtist = self.dataEncoders['Artist']\n",
    "        # encodedArtist = encoderArtist.transform(data[['Artist']])\n",
    "        # encodedArtist = encodedArtist.ravel()\n",
    "        # Artist_pd =  pd.DataFrame(data=encodedArtist, columns= [\"Artist\"])\n",
    "\n",
    "        data.drop(['Key','Album_type', 'Composer',  'Artist'], axis=1, inplace=True)\n",
    "\n",
    "        data = pd.concat([data, key_pd, AlbumType_pd, Composer_pd, Artist_pd], axis=1)\n",
    "\n",
    "        scaledLoudness = self.scaleMinMaxLoudness(data[['Loudness']])\n",
    "        data['Loudness'] = scaledLoudness\n",
    "\n",
    "        newMinMaxScaler = ['Tempo', 'Duration_ms', 'Views', 'Likes', 'Stream', 'Comments']\n",
    "\n",
    "        scaler = self.stdScaler\n",
    "        scaledData = scaler.transform(data[newMinMaxScaler])\n",
    "\n",
    "        for i in range(scaledData.shape[1]):\n",
    "            data[newMinMaxScaler[i]] = scaledData[:, i]\n",
    "\n",
    "        self.dataTestFileLabels =  np.zeros((len(data),1))\n",
    "        self.dataTestFile =  data\n",
    "\n",
    "    def dataBlocksGenerator(self, data):\n",
    "        musicMarket = pd.concat([data['Energy'], data['Valence'], data['Tempo'], data.iloc[:, 8:15]], axis=1)\n",
    "        musicStats = pd.concat([data.iloc[:, 0:8], data.loc[:, data.columns.str.startswith(\"key\")]], axis=1)       \n",
    "        musicArtistComposer = pd.concat([data['Energy'], data['Valence'], data['Tempo'], data.loc[:, data.columns.str.startswith(\"key\")], data.loc[:, data.columns.str.startswith(\"Artist\")], data.loc[:, data.columns.str.startswith(\"Composer\")], data.loc[:, data.columns.str.startswith(\"AlbumType\")]], axis=1)\n",
    "\n",
    "        return musicMarket, musicStats, musicArtistComposer \n",
    "\n",
    "    class DataPreparation(Dataset):\n",
    "        def __init__(\n",
    "                self, \n",
    "                musicMarket, \n",
    "                musicStats, \n",
    "                musicArtistComposer, \n",
    "                labels):\n",
    "            \n",
    "            self.musicMarket = torch.from_numpy(np.asarray(musicMarket).astype(np.float32)).to(torch.float32)\n",
    "            self.musicStats = torch.from_numpy(np.asarray(musicStats).astype(np.float32)).to(torch.float32)\n",
    "            self.musicArtistComposer = torch.from_numpy(np.asarray(musicArtistComposer).astype(np.float32)).to(torch.float32)\n",
    "            self.labels = torch.from_numpy(np.asarray(labels, dtype=np.float32).reshape(labels.shape[0], 1)).to(torch.float32)\n",
    "            \n",
    "            self.n_samples = labels.shape[0]\n",
    "\n",
    "        def __getitem__(self, index):\n",
    "            return self.musicMarket[index], \\\n",
    "            self.musicStats[index], \\\n",
    "            self.musicArtistComposer[index], \\\n",
    "            self.labels[index]\n",
    "        \n",
    "        def __len__(self):\n",
    "            return self.n_samples\n",
    "\n",
    "    def splitDataset(self):\n",
    "        train_X, test_X, train_Y, test_Y = train_test_split(self.data, self.labels, test_size = 0.20, random_state = 123)\n",
    "        train_X, Validation_X, train_Y, Validation_Y = train_test_split(train_X, train_Y, test_size = 0.20, random_state = 123)\n",
    "\n",
    "        train_musicMarket, train_musicStats, train_musicArtistComposer = self.dataBlocksGenerator(train_X)\n",
    "        Validation_musicMarket, Validation_musicStats, Validation_musicArtistComposer = self.dataBlocksGenerator(Validation_X)\n",
    "        test_musicMarket, test_musicStats, test_musicArtistComposer = self.dataBlocksGenerator(test_X)\n",
    "        \n",
    "        self.train = self.DataPreparation(train_musicMarket, train_musicStats, train_musicArtistComposer, train_Y)\n",
    "        self.validate = self.DataPreparation(Validation_musicMarket, Validation_musicStats, Validation_musicArtistComposer, Validation_Y)\n",
    "        self.test = self.DataPreparation(test_musicMarket, test_musicStats, test_musicArtistComposer, test_Y)\n",
    "\n",
    "    def testDatasetFile(self):\n",
    "       test_musicMarket, test_musicStats, test_musicArtistComposer = self.dataBlocksGenerator(self.dataTestFile) \n",
    "       self.testDATAFILE = self.DataPreparation(test_musicMarket, test_musicStats, test_musicArtistComposer, self.dataTestFileLabels)\n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        musicMarket = 10\n",
    "        musicStats = 19\n",
    "        musicArtistComposer = 126\n",
    "\n",
    "        out_musicMarket = 4\n",
    "        out_musicStats = 8\n",
    "        out_musicArtistComposer = 32\n",
    "\n",
    "        concat = out_musicMarket + out_musicStats + out_musicArtistComposer\n",
    "        \n",
    "        # music Market\n",
    "        self.mMl1 = nn.Linear(musicMarket, 8)\n",
    "        self.mMact1 = nn.ReLU()\n",
    "        self.mMd1 = nn.Dropout(p=0.2)\n",
    "\n",
    "        self.mMl2 = nn.Linear(8, 6)\n",
    "        self.mMact2 = nn.ReLU()\n",
    "        self.mMd2 = nn.Dropout(p=0.2)\n",
    "\n",
    "        self.mMl3 = nn.Linear(6, out_musicMarket)\n",
    "        self.mMact3 = nn.ReLU()\n",
    "        self.mMd3 = nn.Dropout(p=0.2)\n",
    "\n",
    "        # music Stats\n",
    "        self.mSl1 = nn.Linear(musicStats, 16)\n",
    "        self.mSact1 = nn.ReLU()\n",
    "        self.mSd1 = nn.Dropout(p=0.2) \n",
    "\n",
    "        self.mSl3 = nn.Linear(16, 12)\n",
    "        self.mSact3 = nn.ReLU()\n",
    "        self.mSd3 = nn.Dropout(p=0.2)\n",
    "\n",
    "        self.mSl5 = nn.Linear(12, out_musicStats)\n",
    "        self.mSact5 = nn.ReLU()\n",
    "        self.mSd5 = nn.Dropout(p=0.2)\n",
    "\n",
    "        # music musicArtistComposer\n",
    "        self.mAl1 = nn.Linear(musicArtistComposer, 96)\n",
    "        self.mAact1 = nn.ReLU()\n",
    "        self.mAd1 = nn.Dropout(p=0.2) \n",
    "\n",
    "        self.mAl2 = nn.Linear(96, 64)\n",
    "        self.mAact2 = nn.ReLU()\n",
    "        self.mAd2 = nn.Dropout(p=0.2) \n",
    "\n",
    "        self.mAl3 = nn.Linear(64, out_musicArtistComposer)\n",
    "        self.mAact3 = nn.ReLU()\n",
    "        self.mAd3 = nn.Dropout(p=0.2) \n",
    "\n",
    "        # Concatenation\n",
    "        self.cCl1 = nn.Linear(concat, 36)\n",
    "        self.cCact1 = nn.ReLU()\n",
    "        self.cCd1 = nn.Dropout(p=0.2) \n",
    "\n",
    "        self.cCl2 = nn.Linear(36, 16)\n",
    "        self.cCact2 = nn.ReLU()\n",
    "        self.cCd2 = nn.Dropout(p=0.2) \n",
    "\n",
    "        self.cCl3 = nn.Linear(16, 4)\n",
    "        self.cCact3 = nn.ReLU()\n",
    "        self.cCd3 = nn.Dropout(p=0.2) \n",
    "\n",
    "        self.cCl4 = nn.Linear(4, 1)\n",
    "        self.out = nn.ReLU()\n",
    "        # self.out = nn.Softmax(dim=1)\n",
    "    \n",
    "    def forward(self, musicMarket, musicStats, musicArtistComposer):\n",
    "        # music Market\n",
    "        outmM = self.mMl1(musicMarket)\n",
    "        outmM = self.mMact1(outmM)\n",
    "        outmM = self.mMd1(outmM)\n",
    "\n",
    "        outmM = self.mMl2(outmM)\n",
    "        outmM = self.mMact2(outmM)\n",
    "        outmM = self.mMd2(outmM)\n",
    "\n",
    "        outmM = self.mMl3(outmM)\n",
    "        outmM = self.mMact3(outmM)\n",
    "        outmM = self.mMd3(outmM)\n",
    "\n",
    "        # music Stats   \n",
    "        outmS = self.mSl1(musicStats)\n",
    "        outmS = self.mSact1(outmS)\n",
    "        outmS = self.mSd1(outmS) \n",
    "\n",
    "        outmS = self.mSl3(outmS)\n",
    "        outmS = self.mSact3(outmS)\n",
    "        outmS = self.mSd3(outmS)\n",
    "\n",
    "        outmS = self.mSl5(outmS)\n",
    "        outmS = self.mSact5(outmS)\n",
    "        outmS = self.mSd5(outmS)\n",
    "\n",
    "        # music musicArtistComposer\n",
    "        outmA = self.mAl1(musicArtistComposer)\n",
    "        outmA = self.mAact1(outmA)\n",
    "        outmA = self.mAd1(outmA)\n",
    "\n",
    "        outmA = self.mAl2(outmA)\n",
    "        outmA = self.mAact2(outmA)\n",
    "        outmA = self.mAd2(outmA) \n",
    "\n",
    "        outmA = self.mAl3(outmA)\n",
    "        outmA = self.mAact3(outmA)\n",
    "        outmA = self.mAd3(outmA) \n",
    "\n",
    "        concat = torch.cat((outmM, outmS, outmA), 1)\n",
    "\n",
    "        # Concatenation\n",
    "        out = self.cCl1(concat)\n",
    "        out = self.cCact1(out)\n",
    "        out = self.cCd1(out) \n",
    "\n",
    "        out = self.cCl2(out)\n",
    "        out = self.cCact2(out)\n",
    "        out = self.cCd2(out) \n",
    "\n",
    "        out = self.cCl3(out)\n",
    "        out = self.cCact3(out)\n",
    "        out = self.cCd3(out) \n",
    "\n",
    "        out = self.cCl4(out)\n",
    "        return out # self.out(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DLModel():\n",
    "    def __init__(self, train, test, validate, learning_rate=1e-6, epoch = 10, batch_size = 16, device = 'cpu', loadModelFlag = False, loadModelFile = ''):\n",
    "        self.lr = learning_rate\n",
    "        self.epoch = epoch\n",
    "        self.batch_size = batch_size\n",
    "        self.device = self.getDevice(device)\n",
    "\n",
    "        self.train = DataLoader(dataset = train, batch_size = self.batch_size, shuffle = True)\n",
    "        self.validation = DataLoader(dataset = validate, batch_size = self.batch_size, shuffle = False)\n",
    "        self.test = DataLoader(dataset = test, batch_size = self.batch_size, shuffle = False)\n",
    "\n",
    "        \n",
    "        \n",
    "        self.model = self.loadModel(loadModelFlag = loadModelFlag, loadModelFile = loadModelFile)\n",
    "        # Define the loss function\n",
    "        self.criterion = nn.MSELoss()\n",
    "        # self.criterion = nn.CrossEntropyLoss()\n",
    "        # Create an SGD optimizer with L1 regularization\n",
    "        self.optimizer = torch.optim.SGD(self.model.parameters(), lr=self.lr, weight_decay=0.001)\n",
    "\n",
    "    def loadModel(self, loadModelFlag = False, loadModelFile = ''):\n",
    "        if loadModelFlag:\n",
    "            if loadModelFile != '':\n",
    "                return torch.load(loadModelFile).to(self.device)\n",
    "        return Model().to(self.device)\n",
    "    \n",
    "    def getDevice(self, device):\n",
    "        if device != 'cpu':\n",
    "            is_cuda =  torch.cuda.is_available()\n",
    "            if is_cuda:\n",
    "                return torch.device('cuda')\n",
    "            return torch.device('cpu')\n",
    "        return torch.device('cpu')\n",
    "    \n",
    "    def metric(self, y, y_hat):\n",
    "        return np.mean(np.abs(y_hat - y))\n",
    "\n",
    "    def trainModel(self, process_factor=2, patiente = 2, show_process = False, earlyStopFlag=True):\n",
    "        self.lossTraining = []\n",
    "        self.accTraining = []\n",
    "        self.lossValidation = []\n",
    "        self.accValidation  = []\n",
    "\n",
    "        patiente_acum = 0  # patiente counter\n",
    "\n",
    "        prev_metric = float('inf')  # best loss from validation\n",
    "        best_Model =  copy.deepcopy(self.model.state_dict()) # best model\n",
    "        self.best_epoch = 0\n",
    "\n",
    "        process = tqdm(range(self.epoch),  desc = 'Epoch ===> ')\n",
    "        for epoch in process:\n",
    "            y_hat = []\n",
    "            y = []\n",
    "            flag = True\n",
    "\n",
    "            loss_train = 0.0\n",
    "            acc_train  = 0.0\n",
    "\n",
    "            self.model.train()\n",
    "            for idx, (musicMarket, musicStats, musicArtistComposer, labels) in enumerate(self.train):\n",
    "                musicMarket = musicMarket.to(self.device)\n",
    "                musicStats = musicStats.to(self.device)\n",
    "                musicArtistComposer = musicArtistComposer.to(self.device)\n",
    "                labels = labels.to(self.device)\n",
    "\n",
    "                # forward\n",
    "                outputs = self.model(musicMarket, musicStats, musicArtistComposer)\n",
    "                loss = self.criterion(outputs, labels)\n",
    "            \n",
    "                # backward\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                self.optimizer.zero_grad()\n",
    "\n",
    "\n",
    "                '''\n",
    "                    ---------------  Get predicted to calculate accuracy ----------------\n",
    "                '''\n",
    "                predicted = outputs.cpu().detach().numpy()\n",
    "                ground_truth = labels.cpu().detach().numpy()\n",
    "\n",
    "                if flag:\n",
    "                    y_hat = predicted\n",
    "                    y = ground_truth\n",
    "                    flag = False\n",
    "\n",
    "                y_hat = np.append(y_hat, predicted)\n",
    "                y = np.append(y, ground_truth)\n",
    "\n",
    "                acc = self.metric(y, y_hat)\n",
    "\n",
    "                if show_process:\n",
    "                    if (idx + 1) % process_factor== 0:\n",
    "                        text = f'Training Stage ==> Epoch: {epoch} / {self.epoch - 1} | Step: {idx} / {len(self.train)} | Training loss: {loss.item():.5f} |  Training Evaluation Metric (MAE): {acc:.5f}'\n",
    "                        print(text)\n",
    "\n",
    "                loss_train = loss.item()\n",
    "                acc_train = acc\n",
    "\n",
    "                process.set_postfix({'Epoch':epoch,\n",
    "                    'training_loss': loss_train, \n",
    "                    'training Acc': acc_train, \n",
    "                    'Step': idx,\n",
    "                    'from': len(self.train)\n",
    "                    })\n",
    "            \n",
    "            self.lossTraining.append(loss_train)\n",
    "            self.accTraining.append(acc_train)\n",
    "            metric = self.metric(y, y_hat)\n",
    "\n",
    "            text = f'Training Stage ==> Epoch: {epoch} / {self.epoch - 1} | Training loss: {loss_train:.5f} |  Training Accuracy: {acc:.5f} | Training Metric (MAE): {metric:.5f}'\n",
    "            print(text)\n",
    "                \n",
    "\n",
    "\n",
    "            ''' \n",
    "            ----------------------------------  EVALUATION STAGE  ---------------------------------------\n",
    "                \n",
    "            '''\n",
    "            y_hat = []\n",
    "            y = []\n",
    "            flag = True\n",
    "\n",
    "            loss_val = 0.0\n",
    "            acc_val  = 0.0\n",
    "      \n",
    "      \n",
    "            self.model.eval()\n",
    "            with torch.no_grad():\n",
    "                for idx, (musicMarket, musicStats, musicArtistComposer, labels) in enumerate(self.validation):\n",
    "                    musicMarket = musicMarket.to(self.device)\n",
    "                    musicStats = musicStats.to(self.device)\n",
    "                    musicArtistComposer = musicArtistComposer.to(self.device)\n",
    "                    labels = labels.to(self.device)\n",
    "\n",
    "                    '''\n",
    "                    ---------------   Forward    --------------------\n",
    "                    '''\n",
    "\n",
    "                    outputs = self.model(musicMarket, musicStats, musicArtistComposer)\n",
    "                    loss = self.criterion(outputs, labels)\n",
    "\n",
    "\n",
    "                    predicted = outputs.cpu().detach().numpy()\n",
    "                    ground_truth = labels.cpu().detach().numpy()\n",
    "\n",
    "                    if flag:\n",
    "                        y_hat = predicted\n",
    "                        y = ground_truth\n",
    "                        flag = False\n",
    "\n",
    "                    y_hat = np.append(y_hat, predicted)\n",
    "                    y = np.append(y, ground_truth)\n",
    "\n",
    "                    acc = self.metric(y, y_hat)\n",
    "\n",
    "                    if show_process:\n",
    "                        if (idx + 1) % process_factor== 0:\n",
    "                            text = f'Validation Stage ==> Epoch: {epoch} / {self.epoch - 1} | Step: {idx} / {len(self.validation)} | Validation loss: {loss.item():.5f} |  Validation Evaluation Metric (MAE): {acc:.5f}'\n",
    "                            print(text)\n",
    "\n",
    "                    loss_val = loss.item()\n",
    "                    acc_val = acc\n",
    "                    process.set_postfix({'Epoch':epoch,\n",
    "                    'validation_loss': loss_val, \n",
    "                    'Validation Acc': acc_val, \n",
    "                    'Step': idx,\n",
    "                    'from': len(self.validation)\n",
    "                    })\n",
    "            \n",
    "                self.lossValidation.append(loss_val)\n",
    "                self.accValidation.append(acc_val)\n",
    "                metric = self.metric(y, y_hat)\n",
    "                text = f'Validation Stage ==> Epoch: {epoch} / {self.epoch - 1} | Validation loss: {loss_val:.5f} |  Validation Accuracy: {acc:.5f} | Validation Metric (MAE)): {metric:.5f}'\n",
    "                print(text)\n",
    "\n",
    "                if metric < prev_metric:\n",
    "                    prev_metric = metric\n",
    "                    best_Model =  copy.deepcopy(self.model.state_dict())\n",
    "                    torch.save(self.model, f'./model/model_EPOCH_{epoch}')\n",
    "\n",
    "                    np.save(f'./training/lossTraining_EPOCH_{epoch}',np.asarray(self.lossTraining))\n",
    "                    np.save(f'./training/accTraining_EPOCH_{epoch}',np.asarray(self.accTraining))\n",
    "                    np.save(f'./training/lossValidation_EPOCH_{epoch}',np.asarray(self.lossValidation))\n",
    "                    np.save(f'./training/accValidation_EPOCH_{epoch}',np.asarray(self.accValidation))\n",
    "          \n",
    "    \n",
    "                    self.best_epoch = epoch\n",
    "                    patiente_acum = 0\n",
    "                else:\n",
    "                    patiente_acum += 1\n",
    "\n",
    "\n",
    "                if earlyStopFlag and patiente_acum > patiente:\n",
    "                    # Load best model in current model\n",
    "                    self.model.load_state_dict(best_Model)\n",
    "          \n",
    "                    print(f'Early Stop Load Model from best epoch {self.best_epoch}')\n",
    "                    break\n",
    "            \n",
    "            if ~earlyStopFlag:\n",
    "                # Load best model in current model\n",
    "                self.model.load_state_dict(best_Model)\n",
    "                print(f'Load Model from best epoch {self.best_epoch}') \n",
    "\n",
    "                process.update(1)\n",
    "            process.close()\n",
    "    \n",
    "    def testinfModel(self, dataset):\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        y_hat = []\n",
    "        y = []\n",
    "        flag = True\n",
    "\n",
    "        lossTest = 0.0\n",
    "        accTest  = 0.0\n",
    "\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            for idx, (musicMarket, musicStats, musicArtistComposer, labels) in enumerate(dataset):\n",
    "                print(musicMarket.shape, musicStats.shape, musicArtistComposer.shape)\n",
    "                musicMarket = musicMarket.to(self.device)\n",
    "                musicStats = musicStats.to(self.device)\n",
    "                musicArtistComposer = musicArtistComposer.to(self.device)\n",
    "                labels = labels.to(self.device)\n",
    "\n",
    "                '''\n",
    "                ---------------   Forward    --------------------\n",
    "                '''\n",
    "\n",
    "                outputs = self.model(musicMarket, musicStats, musicArtistComposer)\n",
    "                loss = self.criterion(outputs, labels)\n",
    "\n",
    "\n",
    "                predicted = outputs.cpu().detach().numpy()\n",
    "                ground_truth = labels.cpu().detach().numpy()\n",
    "\n",
    "                if flag:\n",
    "                    y_hat = predicted\n",
    "                    y = ground_truth\n",
    "                    flag = False\n",
    "\n",
    "                y_hat = np.append(y_hat, predicted)\n",
    "                y = np.append(y, ground_truth)\n",
    "                lossTest = loss.item()\n",
    "                accTest = self.metric(y, y_hat)\n",
    "\n",
    "            text = f'Loss: {lossTest:.5f} |  Validation Accuracy: {accTest:.5f}'\n",
    "            print(text)\n",
    "            return y, y_hat\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = DataFinal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Danceability', 'Energy', 'Key', 'Loudness', 'Speechiness',\n",
       "       'Acousticness', 'Instrumentalness', 'Liveness', 'Valence', 'Tempo',\n",
       "       'Duration_ms', 'Views', 'Likes', 'Stream', 'Album_type', 'Licensed',\n",
       "       'official_video', 'id', 'Track', 'Album', 'Uri', 'Url_spotify',\n",
       "       'Url_youtube', 'Comments', 'Description', 'Title', 'Channel',\n",
       "       'Composer', 'Artist'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.orginDataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0.0\n",
       "1        0.0\n",
       "2        0.0\n",
       "3        1.0\n",
       "4        4.0\n",
       "        ... \n",
       "17165    3.0\n",
       "17166    2.0\n",
       "17167    1.0\n",
       "17168    1.0\n",
       "17169    2.0\n",
       "Name: Danceability, Length: 17170, dtype: float64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.orginDataset['Danceability']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(data=f.orginDataset, x=\"Energy\", hue=\"Danceability\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0.000273\n",
       "1        0.184220\n",
       "2             NaN\n",
       "3        0.209585\n",
       "4             NaN\n",
       "           ...   \n",
       "17165    0.794023\n",
       "17166    0.820026\n",
       "17167    0.571787\n",
       "17168    0.451218\n",
       "17169    0.825294\n",
       "Name: Energy, Length: 17170, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.original['Energy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = f.labels.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = DLModel(f.train, f.validate, f.test,  epoch = 100000, batch_size = 1024, learning_rate=2.6e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch ===> :   0%|          | 1/100000 [00:00<13:17:26,  2.09it/s, Epoch=0, validation_loss=32.8, Validation Acc=4.92, Step=3, from=4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Stage ==> Epoch: 0 / 99999 | Training loss: 33.13607 |  Training Accuracy: 4.88562 | Training Metric (MAE): 4.88562\n",
      "Validation Stage ==> Epoch: 0 / 99999 | Validation loss: 32.77778 |  Validation Accuracy: 4.91565 | Validation Metric (MAE)): 4.91565\n",
      "Load Model from best epoch 0\n",
      "Training Stage ==> Epoch: 1 / 99999 | Training loss: 32.98310 |  Training Accuracy: 4.89809 | Training Metric (MAE): 4.89809\n",
      "Validation Stage ==> Epoch: 1 / 99999 | Validation loss: 32.77420 |  Validation Accuracy: 4.91529 | Validation Metric (MAE)): 4.91529\n",
      "Load Model from best epoch 1\n",
      "Training Stage ==> Epoch: 2 / 99999 | Training loss: 33.95529 |  Training Accuracy: 4.88692 | Training Metric (MAE): 4.88692\n",
      "Validation Stage ==> Epoch: 2 / 99999 | Validation loss: 32.77062 |  Validation Accuracy: 4.91493 | Validation Metric (MAE)): 4.91493\n",
      "Load Model from best epoch 2\n",
      "Training Stage ==> Epoch: 3 / 99999 | Training loss: 34.24881 |  Training Accuracy: 4.89736 | Training Metric (MAE): 4.89736\n",
      "Validation Stage ==> Epoch: 3 / 99999 | Validation loss: 32.76704 |  Validation Accuracy: 4.91457 | Validation Metric (MAE)): 4.91457\n",
      "Load Model from best epoch 3\n",
      "Training Stage ==> Epoch: 4 / 99999 | Training loss: 31.43793 |  Training Accuracy: 4.88264 | Training Metric (MAE): 4.88264\n",
      "Validation Stage ==> Epoch: 4 / 99999 | Validation loss: 32.76347 |  Validation Accuracy: 4.91421 | Validation Metric (MAE)): 4.91421\n",
      "Load Model from best epoch 4\n",
      "Training Stage ==> Epoch: 5 / 99999 | Training loss: 32.15368 |  Training Accuracy: 4.90482 | Training Metric (MAE): 4.90482\n",
      "Validation Stage ==> Epoch: 5 / 99999 | Validation loss: 32.75988 |  Validation Accuracy: 4.91384 | Validation Metric (MAE)): 4.91384\n",
      "Load Model from best epoch 5\n",
      "Training Stage ==> Epoch: 6 / 99999 | Training loss: 31.28911 |  Training Accuracy: 4.88451 | Training Metric (MAE): 4.88451\n",
      "Validation Stage ==> Epoch: 6 / 99999 | Validation loss: 32.75632 |  Validation Accuracy: 4.91348 | Validation Metric (MAE)): 4.91348\n",
      "Load Model from best epoch 6\n",
      "Training Stage ==> Epoch: 7 / 99999 | Training loss: 31.15499 |  Training Accuracy: 4.88500 | Training Metric (MAE): 4.88500\n",
      "Validation Stage ==> Epoch: 7 / 99999 | Validation loss: 32.75275 |  Validation Accuracy: 4.91312 | Validation Metric (MAE)): 4.91312\n",
      "Load Model from best epoch 7\n",
      "Training Stage ==> Epoch: 8 / 99999 | Training loss: 32.26916 |  Training Accuracy: 4.89850 | Training Metric (MAE): 4.89850\n",
      "Validation Stage ==> Epoch: 8 / 99999 | Validation loss: 32.74916 |  Validation Accuracy: 4.91276 | Validation Metric (MAE)): 4.91276\n",
      "Load Model from best epoch 8\n",
      "Training Stage ==> Epoch: 9 / 99999 | Training loss: 32.29697 |  Training Accuracy: 4.87930 | Training Metric (MAE): 4.87930\n",
      "Validation Stage ==> Epoch: 9 / 99999 | Validation loss: 32.74558 |  Validation Accuracy: 4.91240 | Validation Metric (MAE)): 4.91240\n",
      "Load Model from best epoch 9\n",
      "Training Stage ==> Epoch: 10 / 99999 | Training loss: 31.32827 |  Training Accuracy: 4.89214 | Training Metric (MAE): 4.89214\n",
      "Validation Stage ==> Epoch: 10 / 99999 | Validation loss: 32.74201 |  Validation Accuracy: 4.91204 | Validation Metric (MAE)): 4.91204\n",
      "Load Model from best epoch 10\n",
      "Training Stage ==> Epoch: 11 / 99999 | Training loss: 30.62756 |  Training Accuracy: 4.88977 | Training Metric (MAE): 4.88977\n",
      "Validation Stage ==> Epoch: 11 / 99999 | Validation loss: 32.73845 |  Validation Accuracy: 4.91168 | Validation Metric (MAE)): 4.91168\n",
      "Load Model from best epoch 11\n",
      "Training Stage ==> Epoch: 12 / 99999 | Training loss: 33.56121 |  Training Accuracy: 4.87866 | Training Metric (MAE): 4.87866\n",
      "Validation Stage ==> Epoch: 12 / 99999 | Validation loss: 32.73488 |  Validation Accuracy: 4.91131 | Validation Metric (MAE)): 4.91131\n",
      "Load Model from best epoch 12\n",
      "Training Stage ==> Epoch: 13 / 99999 | Training loss: 30.73666 |  Training Accuracy: 4.87817 | Training Metric (MAE): 4.87817\n",
      "Validation Stage ==> Epoch: 13 / 99999 | Validation loss: 32.73132 |  Validation Accuracy: 4.91095 | Validation Metric (MAE)): 4.91095\n",
      "Load Model from best epoch 13\n",
      "Training Stage ==> Epoch: 14 / 99999 | Training loss: 32.51128 |  Training Accuracy: 4.88799 | Training Metric (MAE): 4.88799\n",
      "Validation Stage ==> Epoch: 14 / 99999 | Validation loss: 32.72776 |  Validation Accuracy: 4.91059 | Validation Metric (MAE)): 4.91059\n",
      "Load Model from best epoch 14\n",
      "Training Stage ==> Epoch: 15 / 99999 | Training loss: 32.92289 |  Training Accuracy: 4.88993 | Training Metric (MAE): 4.88993\n",
      "Validation Stage ==> Epoch: 15 / 99999 | Validation loss: 32.72417 |  Validation Accuracy: 4.91023 | Validation Metric (MAE)): 4.91023\n",
      "Load Model from best epoch 15\n",
      "Training Stage ==> Epoch: 16 / 99999 | Training loss: 34.13221 |  Training Accuracy: 4.88448 | Training Metric (MAE): 4.88448\n",
      "Validation Stage ==> Epoch: 16 / 99999 | Validation loss: 32.72060 |  Validation Accuracy: 4.90987 | Validation Metric (MAE)): 4.90987\n",
      "Load Model from best epoch 16\n",
      "Training Stage ==> Epoch: 17 / 99999 | Training loss: 31.90484 |  Training Accuracy: 4.87686 | Training Metric (MAE): 4.87686\n",
      "Validation Stage ==> Epoch: 17 / 99999 | Validation loss: 32.71704 |  Validation Accuracy: 4.90951 | Validation Metric (MAE)): 4.90951\n",
      "Load Model from best epoch 17\n",
      "Training Stage ==> Epoch: 18 / 99999 | Training loss: 31.79332 |  Training Accuracy: 4.88203 | Training Metric (MAE): 4.88203\n",
      "Validation Stage ==> Epoch: 18 / 99999 | Validation loss: 32.71347 |  Validation Accuracy: 4.90915 | Validation Metric (MAE)): 4.90915\n",
      "Load Model from best epoch 18\n",
      "Training Stage ==> Epoch: 19 / 99999 | Training loss: 30.38185 |  Training Accuracy: 4.88759 | Training Metric (MAE): 4.88759\n",
      "Validation Stage ==> Epoch: 19 / 99999 | Validation loss: 32.70992 |  Validation Accuracy: 4.90879 | Validation Metric (MAE)): 4.90879\n",
      "Load Model from best epoch 19\n",
      "Training Stage ==> Epoch: 20 / 99999 | Training loss: 31.57648 |  Training Accuracy: 4.87394 | Training Metric (MAE): 4.87394\n",
      "Validation Stage ==> Epoch: 20 / 99999 | Validation loss: 32.70636 |  Validation Accuracy: 4.90843 | Validation Metric (MAE)): 4.90843\n",
      "Load Model from best epoch 20\n",
      "Training Stage ==> Epoch: 21 / 99999 | Training loss: 31.65881 |  Training Accuracy: 4.87760 | Training Metric (MAE): 4.87760\n",
      "Validation Stage ==> Epoch: 21 / 99999 | Validation loss: 32.70280 |  Validation Accuracy: 4.90807 | Validation Metric (MAE)): 4.90807\n",
      "Load Model from best epoch 21\n",
      "Training Stage ==> Epoch: 22 / 99999 | Training loss: 32.07729 |  Training Accuracy: 4.90258 | Training Metric (MAE): 4.90258\n",
      "Validation Stage ==> Epoch: 22 / 99999 | Validation loss: 32.69923 |  Validation Accuracy: 4.90771 | Validation Metric (MAE)): 4.90771\n",
      "Load Model from best epoch 22\n",
      "Training Stage ==> Epoch: 23 / 99999 | Training loss: 31.87136 |  Training Accuracy: 4.87896 | Training Metric (MAE): 4.87896\n",
      "Validation Stage ==> Epoch: 23 / 99999 | Validation loss: 32.69567 |  Validation Accuracy: 4.90735 | Validation Metric (MAE)): 4.90735\n",
      "Load Model from best epoch 23\n",
      "Training Stage ==> Epoch: 24 / 99999 | Training loss: 32.05717 |  Training Accuracy: 4.89743 | Training Metric (MAE): 4.89743\n",
      "Validation Stage ==> Epoch: 24 / 99999 | Validation loss: 32.69212 |  Validation Accuracy: 4.90699 | Validation Metric (MAE)): 4.90699\n",
      "Load Model from best epoch 24\n",
      "Training Stage ==> Epoch: 25 / 99999 | Training loss: 31.33473 |  Training Accuracy: 4.88263 | Training Metric (MAE): 4.88263\n",
      "Validation Stage ==> Epoch: 25 / 99999 | Validation loss: 32.68856 |  Validation Accuracy: 4.90663 | Validation Metric (MAE)): 4.90663\n",
      "Load Model from best epoch 25\n",
      "Training Stage ==> Epoch: 26 / 99999 | Training loss: 33.67451 |  Training Accuracy: 4.88163 | Training Metric (MAE): 4.88163\n",
      "Validation Stage ==> Epoch: 26 / 99999 | Validation loss: 32.68500 |  Validation Accuracy: 4.90627 | Validation Metric (MAE)): 4.90627\n",
      "Load Model from best epoch 26\n",
      "Training Stage ==> Epoch: 27 / 99999 | Training loss: 32.43183 |  Training Accuracy: 4.88408 | Training Metric (MAE): 4.88408\n",
      "Validation Stage ==> Epoch: 27 / 99999 | Validation loss: 32.68145 |  Validation Accuracy: 4.90591 | Validation Metric (MAE)): 4.90591\n",
      "Load Model from best epoch 27\n",
      "Training Stage ==> Epoch: 28 / 99999 | Training loss: 31.72613 |  Training Accuracy: 4.89201 | Training Metric (MAE): 4.89201\n",
      "Validation Stage ==> Epoch: 28 / 99999 | Validation loss: 32.67789 |  Validation Accuracy: 4.90555 | Validation Metric (MAE)): 4.90555\n",
      "Load Model from best epoch 28\n",
      "Training Stage ==> Epoch: 29 / 99999 | Training loss: 31.88251 |  Training Accuracy: 4.88357 | Training Metric (MAE): 4.88357\n",
      "Validation Stage ==> Epoch: 29 / 99999 | Validation loss: 32.67434 |  Validation Accuracy: 4.90519 | Validation Metric (MAE)): 4.90519\n",
      "Load Model from best epoch 29\n",
      "Training Stage ==> Epoch: 30 / 99999 | Training loss: 32.67668 |  Training Accuracy: 4.88408 | Training Metric (MAE): 4.88408\n",
      "Validation Stage ==> Epoch: 30 / 99999 | Validation loss: 32.67079 |  Validation Accuracy: 4.90483 | Validation Metric (MAE)): 4.90483\n",
      "Load Model from best epoch 30\n",
      "Training Stage ==> Epoch: 31 / 99999 | Training loss: 31.68907 |  Training Accuracy: 4.87578 | Training Metric (MAE): 4.87578\n",
      "Validation Stage ==> Epoch: 31 / 99999 | Validation loss: 32.66724 |  Validation Accuracy: 4.90447 | Validation Metric (MAE)): 4.90447\n",
      "Load Model from best epoch 31\n",
      "Training Stage ==> Epoch: 32 / 99999 | Training loss: 32.64869 |  Training Accuracy: 4.88036 | Training Metric (MAE): 4.88036\n",
      "Validation Stage ==> Epoch: 32 / 99999 | Validation loss: 32.66369 |  Validation Accuracy: 4.90411 | Validation Metric (MAE)): 4.90411\n",
      "Load Model from best epoch 32\n",
      "Training Stage ==> Epoch: 33 / 99999 | Training loss: 31.54206 |  Training Accuracy: 4.88560 | Training Metric (MAE): 4.88560\n",
      "Validation Stage ==> Epoch: 33 / 99999 | Validation loss: 32.66015 |  Validation Accuracy: 4.90375 | Validation Metric (MAE)): 4.90375\n",
      "Load Model from best epoch 33\n",
      "Training Stage ==> Epoch: 34 / 99999 | Training loss: 32.81738 |  Training Accuracy: 4.87564 | Training Metric (MAE): 4.87564\n",
      "Validation Stage ==> Epoch: 34 / 99999 | Validation loss: 32.65660 |  Validation Accuracy: 4.90339 | Validation Metric (MAE)): 4.90339\n",
      "Load Model from best epoch 34\n",
      "Training Stage ==> Epoch: 35 / 99999 | Training loss: 31.95620 |  Training Accuracy: 4.87842 | Training Metric (MAE): 4.87842\n",
      "Validation Stage ==> Epoch: 35 / 99999 | Validation loss: 32.65306 |  Validation Accuracy: 4.90303 | Validation Metric (MAE)): 4.90303\n",
      "Load Model from best epoch 35\n",
      "Training Stage ==> Epoch: 36 / 99999 | Training loss: 34.31115 |  Training Accuracy: 4.87268 | Training Metric (MAE): 4.87268\n",
      "Validation Stage ==> Epoch: 36 / 99999 | Validation loss: 32.64951 |  Validation Accuracy: 4.90267 | Validation Metric (MAE)): 4.90267\n",
      "Load Model from best epoch 36\n",
      "Training Stage ==> Epoch: 37 / 99999 | Training loss: 33.28053 |  Training Accuracy: 4.87884 | Training Metric (MAE): 4.87884\n",
      "Validation Stage ==> Epoch: 37 / 99999 | Validation loss: 32.64597 |  Validation Accuracy: 4.90231 | Validation Metric (MAE)): 4.90231\n",
      "Load Model from best epoch 37\n",
      "Training Stage ==> Epoch: 38 / 99999 | Training loss: 31.74442 |  Training Accuracy: 4.87684 | Training Metric (MAE): 4.87684\n",
      "Validation Stage ==> Epoch: 38 / 99999 | Validation loss: 32.64242 |  Validation Accuracy: 4.90195 | Validation Metric (MAE)): 4.90195\n",
      "Load Model from best epoch 38\n",
      "Training Stage ==> Epoch: 39 / 99999 | Training loss: 32.16866 |  Training Accuracy: 4.86954 | Training Metric (MAE): 4.86954\n",
      "Validation Stage ==> Epoch: 39 / 99999 | Validation loss: 32.63888 |  Validation Accuracy: 4.90159 | Validation Metric (MAE)): 4.90159\n",
      "Load Model from best epoch 39\n",
      "Training Stage ==> Epoch: 40 / 99999 | Training loss: 32.94932 |  Training Accuracy: 4.88815 | Training Metric (MAE): 4.88815\n",
      "Validation Stage ==> Epoch: 40 / 99999 | Validation loss: 32.63534 |  Validation Accuracy: 4.90123 | Validation Metric (MAE)): 4.90123\n",
      "Load Model from best epoch 40\n",
      "Training Stage ==> Epoch: 41 / 99999 | Training loss: 30.75052 |  Training Accuracy: 4.87617 | Training Metric (MAE): 4.87617\n",
      "Validation Stage ==> Epoch: 41 / 99999 | Validation loss: 32.63181 |  Validation Accuracy: 4.90088 | Validation Metric (MAE)): 4.90088\n",
      "Load Model from best epoch 41\n",
      "Training Stage ==> Epoch: 42 / 99999 | Training loss: 32.73932 |  Training Accuracy: 4.89028 | Training Metric (MAE): 4.89028\n",
      "Validation Stage ==> Epoch: 42 / 99999 | Validation loss: 32.62827 |  Validation Accuracy: 4.90052 | Validation Metric (MAE)): 4.90052\n",
      "Load Model from best epoch 42\n",
      "Training Stage ==> Epoch: 43 / 99999 | Training loss: 33.24439 |  Training Accuracy: 4.87369 | Training Metric (MAE): 4.87369\n",
      "Validation Stage ==> Epoch: 43 / 99999 | Validation loss: 32.62473 |  Validation Accuracy: 4.90016 | Validation Metric (MAE)): 4.90016\n",
      "Load Model from best epoch 43\n",
      "Training Stage ==> Epoch: 44 / 99999 | Training loss: 32.35968 |  Training Accuracy: 4.88559 | Training Metric (MAE): 4.88559\n",
      "Validation Stage ==> Epoch: 44 / 99999 | Validation loss: 32.62120 |  Validation Accuracy: 4.89980 | Validation Metric (MAE)): 4.89980\n",
      "Load Model from best epoch 44\n",
      "Training Stage ==> Epoch: 45 / 99999 | Training loss: 31.17588 |  Training Accuracy: 4.88261 | Training Metric (MAE): 4.88261\n",
      "Validation Stage ==> Epoch: 45 / 99999 | Validation loss: 32.61766 |  Validation Accuracy: 4.89944 | Validation Metric (MAE)): 4.89944\n",
      "Load Model from best epoch 45\n",
      "Training Stage ==> Epoch: 46 / 99999 | Training loss: 33.18682 |  Training Accuracy: 4.87583 | Training Metric (MAE): 4.87583\n",
      "Validation Stage ==> Epoch: 46 / 99999 | Validation loss: 32.61412 |  Validation Accuracy: 4.89908 | Validation Metric (MAE)): 4.89908\n",
      "Load Model from best epoch 46\n",
      "Training Stage ==> Epoch: 47 / 99999 | Training loss: 31.94356 |  Training Accuracy: 4.88157 | Training Metric (MAE): 4.88157\n",
      "Validation Stage ==> Epoch: 47 / 99999 | Validation loss: 32.61059 |  Validation Accuracy: 4.89872 | Validation Metric (MAE)): 4.89872\n",
      "Load Model from best epoch 47\n",
      "Training Stage ==> Epoch: 48 / 99999 | Training loss: 30.92537 |  Training Accuracy: 4.89160 | Training Metric (MAE): 4.89160\n",
      "Validation Stage ==> Epoch: 48 / 99999 | Validation loss: 32.60705 |  Validation Accuracy: 4.89836 | Validation Metric (MAE)): 4.89836\n",
      "Load Model from best epoch 48\n",
      "Training Stage ==> Epoch: 49 / 99999 | Training loss: 31.50878 |  Training Accuracy: 4.86784 | Training Metric (MAE): 4.86784\n",
      "Validation Stage ==> Epoch: 49 / 99999 | Validation loss: 32.60352 |  Validation Accuracy: 4.89801 | Validation Metric (MAE)): 4.89801\n",
      "Load Model from best epoch 49\n",
      "Training Stage ==> Epoch: 50 / 99999 | Training loss: 31.40702 |  Training Accuracy: 4.87567 | Training Metric (MAE): 4.87567\n",
      "Validation Stage ==> Epoch: 50 / 99999 | Validation loss: 32.59999 |  Validation Accuracy: 4.89765 | Validation Metric (MAE)): 4.89765\n",
      "Load Model from best epoch 50\n",
      "Training Stage ==> Epoch: 51 / 99999 | Training loss: 32.45128 |  Training Accuracy: 4.88647 | Training Metric (MAE): 4.88647\n",
      "Validation Stage ==> Epoch: 51 / 99999 | Validation loss: 32.59646 |  Validation Accuracy: 4.89729 | Validation Metric (MAE)): 4.89729\n",
      "Load Model from best epoch 51\n",
      "Training Stage ==> Epoch: 52 / 99999 | Training loss: 30.04726 |  Training Accuracy: 4.88766 | Training Metric (MAE): 4.88766\n",
      "Validation Stage ==> Epoch: 52 / 99999 | Validation loss: 32.59294 |  Validation Accuracy: 4.89693 | Validation Metric (MAE)): 4.89693\n",
      "Load Model from best epoch 52\n",
      "Training Stage ==> Epoch: 53 / 99999 | Training loss: 33.02846 |  Training Accuracy: 4.87603 | Training Metric (MAE): 4.87603\n",
      "Validation Stage ==> Epoch: 53 / 99999 | Validation loss: 32.58940 |  Validation Accuracy: 4.89657 | Validation Metric (MAE)): 4.89657\n",
      "Load Model from best epoch 53\n",
      "Training Stage ==> Epoch: 54 / 99999 | Training loss: 30.81563 |  Training Accuracy: 4.87371 | Training Metric (MAE): 4.87371\n",
      "Validation Stage ==> Epoch: 54 / 99999 | Validation loss: 32.58588 |  Validation Accuracy: 4.89622 | Validation Metric (MAE)): 4.89622\n",
      "Load Model from best epoch 54\n",
      "Training Stage ==> Epoch: 55 / 99999 | Training loss: 32.16970 |  Training Accuracy: 4.87309 | Training Metric (MAE): 4.87309\n",
      "Validation Stage ==> Epoch: 55 / 99999 | Validation loss: 32.58235 |  Validation Accuracy: 4.89586 | Validation Metric (MAE)): 4.89586\n",
      "Load Model from best epoch 55\n",
      "Training Stage ==> Epoch: 56 / 99999 | Training loss: 31.99582 |  Training Accuracy: 4.87991 | Training Metric (MAE): 4.87991\n",
      "Validation Stage ==> Epoch: 56 / 99999 | Validation loss: 32.57883 |  Validation Accuracy: 4.89550 | Validation Metric (MAE)): 4.89550\n",
      "Load Model from best epoch 56\n",
      "Training Stage ==> Epoch: 57 / 99999 | Training loss: 30.59613 |  Training Accuracy: 4.86902 | Training Metric (MAE): 4.86902\n",
      "Validation Stage ==> Epoch: 57 / 99999 | Validation loss: 32.57531 |  Validation Accuracy: 4.89514 | Validation Metric (MAE)): 4.89514\n",
      "Load Model from best epoch 57\n",
      "Training Stage ==> Epoch: 58 / 99999 | Training loss: 31.37088 |  Training Accuracy: 4.87283 | Training Metric (MAE): 4.87283\n",
      "Validation Stage ==> Epoch: 58 / 99999 | Validation loss: 32.57178 |  Validation Accuracy: 4.89479 | Validation Metric (MAE)): 4.89479\n",
      "Load Model from best epoch 58\n",
      "Training Stage ==> Epoch: 59 / 99999 | Training loss: 30.41039 |  Training Accuracy: 4.87209 | Training Metric (MAE): 4.87209\n",
      "Validation Stage ==> Epoch: 59 / 99999 | Validation loss: 32.56826 |  Validation Accuracy: 4.89443 | Validation Metric (MAE)): 4.89443\n",
      "Load Model from best epoch 59\n",
      "Training Stage ==> Epoch: 60 / 99999 | Training loss: 33.20059 |  Training Accuracy: 4.88069 | Training Metric (MAE): 4.88069\n",
      "Validation Stage ==> Epoch: 60 / 99999 | Validation loss: 32.56474 |  Validation Accuracy: 4.89407 | Validation Metric (MAE)): 4.89407\n",
      "Load Model from best epoch 60\n",
      "Training Stage ==> Epoch: 61 / 99999 | Training loss: 31.43942 |  Training Accuracy: 4.88632 | Training Metric (MAE): 4.88632\n",
      "Validation Stage ==> Epoch: 61 / 99999 | Validation loss: 32.56122 |  Validation Accuracy: 4.89371 | Validation Metric (MAE)): 4.89371\n",
      "Load Model from best epoch 61\n",
      "Training Stage ==> Epoch: 62 / 99999 | Training loss: 33.14968 |  Training Accuracy: 4.88119 | Training Metric (MAE): 4.88119\n",
      "Validation Stage ==> Epoch: 62 / 99999 | Validation loss: 32.55770 |  Validation Accuracy: 4.89336 | Validation Metric (MAE)): 4.89336\n",
      "Load Model from best epoch 62\n",
      "Training Stage ==> Epoch: 63 / 99999 | Training loss: 32.30169 |  Training Accuracy: 4.86261 | Training Metric (MAE): 4.86261\n",
      "Validation Stage ==> Epoch: 63 / 99999 | Validation loss: 32.55418 |  Validation Accuracy: 4.89300 | Validation Metric (MAE)): 4.89300\n",
      "Load Model from best epoch 63\n",
      "Training Stage ==> Epoch: 64 / 99999 | Training loss: 32.38240 |  Training Accuracy: 4.87219 | Training Metric (MAE): 4.87219\n",
      "Validation Stage ==> Epoch: 64 / 99999 | Validation loss: 32.55065 |  Validation Accuracy: 4.89264 | Validation Metric (MAE)): 4.89264\n",
      "Load Model from best epoch 64\n",
      "Training Stage ==> Epoch: 65 / 99999 | Training loss: 31.34807 |  Training Accuracy: 4.88443 | Training Metric (MAE): 4.88443\n",
      "Validation Stage ==> Epoch: 65 / 99999 | Validation loss: 32.54713 |  Validation Accuracy: 4.89228 | Validation Metric (MAE)): 4.89228\n",
      "Load Model from best epoch 65\n",
      "Training Stage ==> Epoch: 66 / 99999 | Training loss: 30.89319 |  Training Accuracy: 4.86495 | Training Metric (MAE): 4.86495\n",
      "Validation Stage ==> Epoch: 66 / 99999 | Validation loss: 32.54361 |  Validation Accuracy: 4.89193 | Validation Metric (MAE)): 4.89193\n",
      "Load Model from best epoch 66\n",
      "Training Stage ==> Epoch: 67 / 99999 | Training loss: 32.01764 |  Training Accuracy: 4.86447 | Training Metric (MAE): 4.86447\n",
      "Validation Stage ==> Epoch: 67 / 99999 | Validation loss: 32.54009 |  Validation Accuracy: 4.89157 | Validation Metric (MAE)): 4.89157\n",
      "Load Model from best epoch 67\n",
      "Training Stage ==> Epoch: 68 / 99999 | Training loss: 31.27730 |  Training Accuracy: 4.88626 | Training Metric (MAE): 4.88626\n",
      "Validation Stage ==> Epoch: 68 / 99999 | Validation loss: 32.53658 |  Validation Accuracy: 4.89121 | Validation Metric (MAE)): 4.89121\n",
      "Load Model from best epoch 68\n",
      "Training Stage ==> Epoch: 69 / 99999 | Training loss: 32.15635 |  Training Accuracy: 4.87173 | Training Metric (MAE): 4.87173\n",
      "Validation Stage ==> Epoch: 69 / 99999 | Validation loss: 32.53306 |  Validation Accuracy: 4.89085 | Validation Metric (MAE)): 4.89085\n",
      "Load Model from best epoch 69\n",
      "Training Stage ==> Epoch: 70 / 99999 | Training loss: 33.31720 |  Training Accuracy: 4.86315 | Training Metric (MAE): 4.86315\n",
      "Validation Stage ==> Epoch: 70 / 99999 | Validation loss: 32.52954 |  Validation Accuracy: 4.89049 | Validation Metric (MAE)): 4.89049\n",
      "Load Model from best epoch 70\n",
      "Training Stage ==> Epoch: 71 / 99999 | Training loss: 33.26872 |  Training Accuracy: 4.85813 | Training Metric (MAE): 4.85813\n",
      "Validation Stage ==> Epoch: 71 / 99999 | Validation loss: 32.52602 |  Validation Accuracy: 4.89014 | Validation Metric (MAE)): 4.89014\n",
      "Load Model from best epoch 71\n",
      "Training Stage ==> Epoch: 72 / 99999 | Training loss: 31.82713 |  Training Accuracy: 4.87560 | Training Metric (MAE): 4.87560\n",
      "Validation Stage ==> Epoch: 72 / 99999 | Validation loss: 32.52250 |  Validation Accuracy: 4.88978 | Validation Metric (MAE)): 4.88978\n",
      "Load Model from best epoch 72\n",
      "Training Stage ==> Epoch: 73 / 99999 | Training loss: 31.60347 |  Training Accuracy: 4.86660 | Training Metric (MAE): 4.86660\n",
      "Validation Stage ==> Epoch: 73 / 99999 | Validation loss: 32.51899 |  Validation Accuracy: 4.88942 | Validation Metric (MAE)): 4.88942\n",
      "Load Model from best epoch 73\n",
      "Training Stage ==> Epoch: 74 / 99999 | Training loss: 32.31083 |  Training Accuracy: 4.86767 | Training Metric (MAE): 4.86767\n",
      "Validation Stage ==> Epoch: 74 / 99999 | Validation loss: 32.51549 |  Validation Accuracy: 4.88907 | Validation Metric (MAE)): 4.88907\n",
      "Load Model from best epoch 74\n",
      "Training Stage ==> Epoch: 75 / 99999 | Training loss: 31.36045 |  Training Accuracy: 4.86367 | Training Metric (MAE): 4.86367\n",
      "Validation Stage ==> Epoch: 75 / 99999 | Validation loss: 32.51198 |  Validation Accuracy: 4.88871 | Validation Metric (MAE)): 4.88871\n",
      "Load Model from best epoch 75\n",
      "Training Stage ==> Epoch: 76 / 99999 | Training loss: 32.97144 |  Training Accuracy: 4.84861 | Training Metric (MAE): 4.84861\n",
      "Validation Stage ==> Epoch: 76 / 99999 | Validation loss: 32.50847 |  Validation Accuracy: 4.88835 | Validation Metric (MAE)): 4.88835\n",
      "Load Model from best epoch 76\n",
      "Training Stage ==> Epoch: 77 / 99999 | Training loss: 32.03680 |  Training Accuracy: 4.86242 | Training Metric (MAE): 4.86242\n",
      "Validation Stage ==> Epoch: 77 / 99999 | Validation loss: 32.50496 |  Validation Accuracy: 4.88800 | Validation Metric (MAE)): 4.88800\n",
      "Load Model from best epoch 77\n",
      "Training Stage ==> Epoch: 78 / 99999 | Training loss: 30.94777 |  Training Accuracy: 4.87338 | Training Metric (MAE): 4.87338\n",
      "Validation Stage ==> Epoch: 78 / 99999 | Validation loss: 32.50146 |  Validation Accuracy: 4.88764 | Validation Metric (MAE)): 4.88764\n",
      "Load Model from best epoch 78\n",
      "Training Stage ==> Epoch: 79 / 99999 | Training loss: 31.85008 |  Training Accuracy: 4.86786 | Training Metric (MAE): 4.86786\n",
      "Validation Stage ==> Epoch: 79 / 99999 | Validation loss: 32.49795 |  Validation Accuracy: 4.88728 | Validation Metric (MAE)): 4.88728\n",
      "Load Model from best epoch 79\n",
      "Training Stage ==> Epoch: 80 / 99999 | Training loss: 32.28313 |  Training Accuracy: 4.87250 | Training Metric (MAE): 4.87250\n",
      "Validation Stage ==> Epoch: 80 / 99999 | Validation loss: 32.49444 |  Validation Accuracy: 4.88693 | Validation Metric (MAE)): 4.88693\n",
      "Load Model from best epoch 80\n",
      "Training Stage ==> Epoch: 81 / 99999 | Training loss: 31.25559 |  Training Accuracy: 4.86569 | Training Metric (MAE): 4.86569\n",
      "Validation Stage ==> Epoch: 81 / 99999 | Validation loss: 32.49093 |  Validation Accuracy: 4.88657 | Validation Metric (MAE)): 4.88657\n",
      "Load Model from best epoch 81\n",
      "Training Stage ==> Epoch: 82 / 99999 | Training loss: 31.65933 |  Training Accuracy: 4.86754 | Training Metric (MAE): 4.86754\n",
      "Validation Stage ==> Epoch: 82 / 99999 | Validation loss: 32.48742 |  Validation Accuracy: 4.88621 | Validation Metric (MAE)): 4.88621\n",
      "Load Model from best epoch 82\n",
      "Training Stage ==> Epoch: 83 / 99999 | Training loss: 31.18796 |  Training Accuracy: 4.85578 | Training Metric (MAE): 4.85578\n",
      "Validation Stage ==> Epoch: 83 / 99999 | Validation loss: 32.48392 |  Validation Accuracy: 4.88586 | Validation Metric (MAE)): 4.88586\n",
      "Load Model from best epoch 83\n",
      "Training Stage ==> Epoch: 84 / 99999 | Training loss: 33.60379 |  Training Accuracy: 4.85696 | Training Metric (MAE): 4.85696\n",
      "Validation Stage ==> Epoch: 84 / 99999 | Validation loss: 32.48041 |  Validation Accuracy: 4.88550 | Validation Metric (MAE)): 4.88550\n",
      "Load Model from best epoch 84\n",
      "Training Stage ==> Epoch: 85 / 99999 | Training loss: 33.17440 |  Training Accuracy: 4.86426 | Training Metric (MAE): 4.86426\n",
      "Validation Stage ==> Epoch: 85 / 99999 | Validation loss: 32.47691 |  Validation Accuracy: 4.88515 | Validation Metric (MAE)): 4.88515\n",
      "Load Model from best epoch 85\n",
      "Training Stage ==> Epoch: 86 / 99999 | Training loss: 31.14564 |  Training Accuracy: 4.86477 | Training Metric (MAE): 4.86477\n",
      "Validation Stage ==> Epoch: 86 / 99999 | Validation loss: 32.47339 |  Validation Accuracy: 4.88479 | Validation Metric (MAE)): 4.88479\n",
      "Load Model from best epoch 86\n",
      "Training Stage ==> Epoch: 87 / 99999 | Training loss: 31.20501 |  Training Accuracy: 4.86428 | Training Metric (MAE): 4.86428\n",
      "Validation Stage ==> Epoch: 87 / 99999 | Validation loss: 32.46991 |  Validation Accuracy: 4.88443 | Validation Metric (MAE)): 4.88443\n",
      "Load Model from best epoch 87\n",
      "Training Stage ==> Epoch: 88 / 99999 | Training loss: 32.37603 |  Training Accuracy: 4.87336 | Training Metric (MAE): 4.87336\n",
      "Validation Stage ==> Epoch: 88 / 99999 | Validation loss: 32.46640 |  Validation Accuracy: 4.88408 | Validation Metric (MAE)): 4.88408\n",
      "Load Model from best epoch 88\n",
      "Training Stage ==> Epoch: 89 / 99999 | Training loss: 31.85566 |  Training Accuracy: 4.85411 | Training Metric (MAE): 4.85411\n",
      "Validation Stage ==> Epoch: 89 / 99999 | Validation loss: 32.46290 |  Validation Accuracy: 4.88372 | Validation Metric (MAE)): 4.88372\n",
      "Load Model from best epoch 89\n",
      "Training Stage ==> Epoch: 90 / 99999 | Training loss: 31.01822 |  Training Accuracy: 4.86412 | Training Metric (MAE): 4.86412\n",
      "Validation Stage ==> Epoch: 90 / 99999 | Validation loss: 32.45941 |  Validation Accuracy: 4.88337 | Validation Metric (MAE)): 4.88337\n",
      "Load Model from best epoch 90\n",
      "Training Stage ==> Epoch: 91 / 99999 | Training loss: 31.67780 |  Training Accuracy: 4.85896 | Training Metric (MAE): 4.85896\n",
      "Validation Stage ==> Epoch: 91 / 99999 | Validation loss: 32.45591 |  Validation Accuracy: 4.88301 | Validation Metric (MAE)): 4.88301\n",
      "Load Model from best epoch 91\n",
      "Training Stage ==> Epoch: 92 / 99999 | Training loss: 32.22005 |  Training Accuracy: 4.86227 | Training Metric (MAE): 4.86227\n",
      "Validation Stage ==> Epoch: 92 / 99999 | Validation loss: 32.45240 |  Validation Accuracy: 4.88265 | Validation Metric (MAE)): 4.88265\n",
      "Load Model from best epoch 92\n",
      "Training Stage ==> Epoch: 93 / 99999 | Training loss: 30.16418 |  Training Accuracy: 4.86716 | Training Metric (MAE): 4.86716\n",
      "Validation Stage ==> Epoch: 93 / 99999 | Validation loss: 32.44891 |  Validation Accuracy: 4.88230 | Validation Metric (MAE)): 4.88230\n",
      "Load Model from best epoch 93\n",
      "Training Stage ==> Epoch: 94 / 99999 | Training loss: 32.02764 |  Training Accuracy: 4.87188 | Training Metric (MAE): 4.87188\n",
      "Validation Stage ==> Epoch: 94 / 99999 | Validation loss: 32.44542 |  Validation Accuracy: 4.88194 | Validation Metric (MAE)): 4.88194\n",
      "Load Model from best epoch 94\n",
      "Training Stage ==> Epoch: 95 / 99999 | Training loss: 31.52814 |  Training Accuracy: 4.86060 | Training Metric (MAE): 4.86060\n",
      "Validation Stage ==> Epoch: 95 / 99999 | Validation loss: 32.44192 |  Validation Accuracy: 4.88158 | Validation Metric (MAE)): 4.88158\n",
      "Load Model from best epoch 95\n",
      "Training Stage ==> Epoch: 96 / 99999 | Training loss: 32.51037 |  Training Accuracy: 4.85905 | Training Metric (MAE): 4.85905\n",
      "Validation Stage ==> Epoch: 96 / 99999 | Validation loss: 32.43843 |  Validation Accuracy: 4.88123 | Validation Metric (MAE)): 4.88123\n",
      "Load Model from best epoch 96\n",
      "Training Stage ==> Epoch: 97 / 99999 | Training loss: 32.62638 |  Training Accuracy: 4.86625 | Training Metric (MAE): 4.86625\n",
      "Validation Stage ==> Epoch: 97 / 99999 | Validation loss: 32.43493 |  Validation Accuracy: 4.88087 | Validation Metric (MAE)): 4.88087\n",
      "Load Model from best epoch 97\n",
      "Training Stage ==> Epoch: 98 / 99999 | Training loss: 32.95816 |  Training Accuracy: 4.86239 | Training Metric (MAE): 4.86239\n",
      "Validation Stage ==> Epoch: 98 / 99999 | Validation loss: 32.43144 |  Validation Accuracy: 4.88052 | Validation Metric (MAE)): 4.88052\n",
      "Load Model from best epoch 98\n",
      "Training Stage ==> Epoch: 99 / 99999 | Training loss: 32.26207 |  Training Accuracy: 4.85718 | Training Metric (MAE): 4.85718\n",
      "Validation Stage ==> Epoch: 99 / 99999 | Validation loss: 32.42796 |  Validation Accuracy: 4.88016 | Validation Metric (MAE)): 4.88016\n",
      "Load Model from best epoch 99\n",
      "Training Stage ==> Epoch: 100 / 99999 | Training loss: 31.54976 |  Training Accuracy: 4.85376 | Training Metric (MAE): 4.85376\n",
      "Validation Stage ==> Epoch: 100 / 99999 | Validation loss: 32.42446 |  Validation Accuracy: 4.87981 | Validation Metric (MAE)): 4.87981\n",
      "Load Model from best epoch 100\n",
      "Training Stage ==> Epoch: 101 / 99999 | Training loss: 32.66232 |  Training Accuracy: 4.85874 | Training Metric (MAE): 4.85874\n",
      "Validation Stage ==> Epoch: 101 / 99999 | Validation loss: 32.42097 |  Validation Accuracy: 4.87945 | Validation Metric (MAE)): 4.87945\n",
      "Load Model from best epoch 101\n",
      "Training Stage ==> Epoch: 102 / 99999 | Training loss: 31.30647 |  Training Accuracy: 4.85843 | Training Metric (MAE): 4.85843\n",
      "Validation Stage ==> Epoch: 102 / 99999 | Validation loss: 32.41748 |  Validation Accuracy: 4.87910 | Validation Metric (MAE)): 4.87910\n",
      "Load Model from best epoch 102\n",
      "Training Stage ==> Epoch: 103 / 99999 | Training loss: 31.18178 |  Training Accuracy: 4.85783 | Training Metric (MAE): 4.85783\n",
      "Validation Stage ==> Epoch: 103 / 99999 | Validation loss: 32.41400 |  Validation Accuracy: 4.87874 | Validation Metric (MAE)): 4.87874\n",
      "Load Model from best epoch 103\n",
      "Training Stage ==> Epoch: 104 / 99999 | Training loss: 32.63816 |  Training Accuracy: 4.85944 | Training Metric (MAE): 4.85944\n",
      "Validation Stage ==> Epoch: 104 / 99999 | Validation loss: 32.41051 |  Validation Accuracy: 4.87839 | Validation Metric (MAE)): 4.87839\n",
      "Load Model from best epoch 104\n",
      "Training Stage ==> Epoch: 105 / 99999 | Training loss: 32.41868 |  Training Accuracy: 4.86628 | Training Metric (MAE): 4.86628\n",
      "Validation Stage ==> Epoch: 105 / 99999 | Validation loss: 32.40702 |  Validation Accuracy: 4.87803 | Validation Metric (MAE)): 4.87803\n",
      "Load Model from best epoch 105\n",
      "Training Stage ==> Epoch: 106 / 99999 | Training loss: 31.68749 |  Training Accuracy: 4.86370 | Training Metric (MAE): 4.86370\n",
      "Validation Stage ==> Epoch: 106 / 99999 | Validation loss: 32.40353 |  Validation Accuracy: 4.87768 | Validation Metric (MAE)): 4.87768\n",
      "Load Model from best epoch 106\n",
      "Training Stage ==> Epoch: 107 / 99999 | Training loss: 32.63218 |  Training Accuracy: 4.85410 | Training Metric (MAE): 4.85410\n",
      "Validation Stage ==> Epoch: 107 / 99999 | Validation loss: 32.40005 |  Validation Accuracy: 4.87732 | Validation Metric (MAE)): 4.87732\n",
      "Load Model from best epoch 107\n",
      "Training Stage ==> Epoch: 108 / 99999 | Training loss: 30.24618 |  Training Accuracy: 4.85741 | Training Metric (MAE): 4.85741\n",
      "Validation Stage ==> Epoch: 108 / 99999 | Validation loss: 32.39657 |  Validation Accuracy: 4.87697 | Validation Metric (MAE)): 4.87697\n",
      "Load Model from best epoch 108\n",
      "Training Stage ==> Epoch: 109 / 99999 | Training loss: 31.01072 |  Training Accuracy: 4.86139 | Training Metric (MAE): 4.86139\n",
      "Validation Stage ==> Epoch: 109 / 99999 | Validation loss: 32.39309 |  Validation Accuracy: 4.87661 | Validation Metric (MAE)): 4.87661\n",
      "Load Model from best epoch 109\n",
      "Training Stage ==> Epoch: 110 / 99999 | Training loss: 29.93030 |  Training Accuracy: 4.85939 | Training Metric (MAE): 4.85939\n",
      "Validation Stage ==> Epoch: 110 / 99999 | Validation loss: 32.38962 |  Validation Accuracy: 4.87626 | Validation Metric (MAE)): 4.87626\n",
      "Load Model from best epoch 110\n",
      "Training Stage ==> Epoch: 111 / 99999 | Training loss: 31.36891 |  Training Accuracy: 4.85136 | Training Metric (MAE): 4.85136\n",
      "Validation Stage ==> Epoch: 111 / 99999 | Validation loss: 32.38613 |  Validation Accuracy: 4.87590 | Validation Metric (MAE)): 4.87590\n",
      "Load Model from best epoch 111\n",
      "Training Stage ==> Epoch: 112 / 99999 | Training loss: 31.15433 |  Training Accuracy: 4.87530 | Training Metric (MAE): 4.87530\n",
      "Validation Stage ==> Epoch: 112 / 99999 | Validation loss: 32.38265 |  Validation Accuracy: 4.87555 | Validation Metric (MAE)): 4.87555\n",
      "Load Model from best epoch 112\n",
      "Training Stage ==> Epoch: 113 / 99999 | Training loss: 30.13062 |  Training Accuracy: 4.84795 | Training Metric (MAE): 4.84795\n",
      "Validation Stage ==> Epoch: 113 / 99999 | Validation loss: 32.37918 |  Validation Accuracy: 4.87519 | Validation Metric (MAE)): 4.87519\n",
      "Load Model from best epoch 113\n",
      "Training Stage ==> Epoch: 114 / 99999 | Training loss: 30.76956 |  Training Accuracy: 4.86084 | Training Metric (MAE): 4.86084\n",
      "Validation Stage ==> Epoch: 114 / 99999 | Validation loss: 32.37571 |  Validation Accuracy: 4.87484 | Validation Metric (MAE)): 4.87484\n",
      "Load Model from best epoch 114\n",
      "Training Stage ==> Epoch: 115 / 99999 | Training loss: 31.45809 |  Training Accuracy: 4.85476 | Training Metric (MAE): 4.85476\n",
      "Validation Stage ==> Epoch: 115 / 99999 | Validation loss: 32.37223 |  Validation Accuracy: 4.87449 | Validation Metric (MAE)): 4.87449\n",
      "Load Model from best epoch 115\n",
      "Training Stage ==> Epoch: 116 / 99999 | Training loss: 32.89937 |  Training Accuracy: 4.85271 | Training Metric (MAE): 4.85271\n",
      "Validation Stage ==> Epoch: 116 / 99999 | Validation loss: 32.36876 |  Validation Accuracy: 4.87413 | Validation Metric (MAE)): 4.87413\n",
      "Load Model from best epoch 116\n",
      "Training Stage ==> Epoch: 117 / 99999 | Training loss: 31.11576 |  Training Accuracy: 4.85228 | Training Metric (MAE): 4.85228\n",
      "Validation Stage ==> Epoch: 117 / 99999 | Validation loss: 32.36528 |  Validation Accuracy: 4.87378 | Validation Metric (MAE)): 4.87378\n",
      "Load Model from best epoch 117\n",
      "Training Stage ==> Epoch: 118 / 99999 | Training loss: 32.73209 |  Training Accuracy: 4.85052 | Training Metric (MAE): 4.85052\n",
      "Validation Stage ==> Epoch: 118 / 99999 | Validation loss: 32.36180 |  Validation Accuracy: 4.87342 | Validation Metric (MAE)): 4.87342\n",
      "Load Model from best epoch 118\n",
      "Training Stage ==> Epoch: 119 / 99999 | Training loss: 30.29524 |  Training Accuracy: 4.85199 | Training Metric (MAE): 4.85199\n",
      "Validation Stage ==> Epoch: 119 / 99999 | Validation loss: 32.35832 |  Validation Accuracy: 4.87307 | Validation Metric (MAE)): 4.87307\n",
      "Load Model from best epoch 119\n",
      "Training Stage ==> Epoch: 120 / 99999 | Training loss: 31.76977 |  Training Accuracy: 4.84755 | Training Metric (MAE): 4.84755\n",
      "Validation Stage ==> Epoch: 120 / 99999 | Validation loss: 32.35485 |  Validation Accuracy: 4.87271 | Validation Metric (MAE)): 4.87271\n",
      "Load Model from best epoch 120\n",
      "Training Stage ==> Epoch: 121 / 99999 | Training loss: 32.00934 |  Training Accuracy: 4.85265 | Training Metric (MAE): 4.85265\n",
      "Validation Stage ==> Epoch: 121 / 99999 | Validation loss: 32.35136 |  Validation Accuracy: 4.87236 | Validation Metric (MAE)): 4.87236\n",
      "Load Model from best epoch 121\n",
      "Training Stage ==> Epoch: 122 / 99999 | Training loss: 31.44771 |  Training Accuracy: 4.85427 | Training Metric (MAE): 4.85427\n",
      "Validation Stage ==> Epoch: 122 / 99999 | Validation loss: 32.34790 |  Validation Accuracy: 4.87201 | Validation Metric (MAE)): 4.87201\n",
      "Load Model from best epoch 122\n",
      "Training Stage ==> Epoch: 123 / 99999 | Training loss: 30.69299 |  Training Accuracy: 4.85160 | Training Metric (MAE): 4.85160\n",
      "Validation Stage ==> Epoch: 123 / 99999 | Validation loss: 32.34444 |  Validation Accuracy: 4.87165 | Validation Metric (MAE)): 4.87165\n",
      "Load Model from best epoch 123\n",
      "Training Stage ==> Epoch: 124 / 99999 | Training loss: 32.68841 |  Training Accuracy: 4.85893 | Training Metric (MAE): 4.85893\n",
      "Validation Stage ==> Epoch: 124 / 99999 | Validation loss: 32.34096 |  Validation Accuracy: 4.87130 | Validation Metric (MAE)): 4.87130\n",
      "Load Model from best epoch 124\n",
      "Training Stage ==> Epoch: 125 / 99999 | Training loss: 32.73022 |  Training Accuracy: 4.86391 | Training Metric (MAE): 4.86391\n",
      "Validation Stage ==> Epoch: 125 / 99999 | Validation loss: 32.33749 |  Validation Accuracy: 4.87094 | Validation Metric (MAE)): 4.87094\n",
      "Load Model from best epoch 125\n",
      "Training Stage ==> Epoch: 126 / 99999 | Training loss: 32.94175 |  Training Accuracy: 4.83871 | Training Metric (MAE): 4.83871\n",
      "Validation Stage ==> Epoch: 126 / 99999 | Validation loss: 32.33402 |  Validation Accuracy: 4.87059 | Validation Metric (MAE)): 4.87059\n",
      "Load Model from best epoch 126\n",
      "Training Stage ==> Epoch: 127 / 99999 | Training loss: 29.88815 |  Training Accuracy: 4.85318 | Training Metric (MAE): 4.85318\n",
      "Validation Stage ==> Epoch: 127 / 99999 | Validation loss: 32.33057 |  Validation Accuracy: 4.87024 | Validation Metric (MAE)): 4.87024\n",
      "Load Model from best epoch 127\n",
      "Training Stage ==> Epoch: 128 / 99999 | Training loss: 31.66287 |  Training Accuracy: 4.84756 | Training Metric (MAE): 4.84756\n",
      "Validation Stage ==> Epoch: 128 / 99999 | Validation loss: 32.32710 |  Validation Accuracy: 4.86988 | Validation Metric (MAE)): 4.86988\n",
      "Load Model from best epoch 128\n",
      "Training Stage ==> Epoch: 129 / 99999 | Training loss: 31.66904 |  Training Accuracy: 4.85899 | Training Metric (MAE): 4.85899\n",
      "Validation Stage ==> Epoch: 129 / 99999 | Validation loss: 32.32364 |  Validation Accuracy: 4.86953 | Validation Metric (MAE)): 4.86953\n",
      "Load Model from best epoch 129\n",
      "Training Stage ==> Epoch: 130 / 99999 | Training loss: 30.90703 |  Training Accuracy: 4.85454 | Training Metric (MAE): 4.85454\n",
      "Validation Stage ==> Epoch: 130 / 99999 | Validation loss: 32.32018 |  Validation Accuracy: 4.86918 | Validation Metric (MAE)): 4.86918\n",
      "Load Model from best epoch 130\n",
      "Training Stage ==> Epoch: 131 / 99999 | Training loss: 32.54845 |  Training Accuracy: 4.85287 | Training Metric (MAE): 4.85287\n",
      "Validation Stage ==> Epoch: 131 / 99999 | Validation loss: 32.31670 |  Validation Accuracy: 4.86882 | Validation Metric (MAE)): 4.86882\n",
      "Load Model from best epoch 131\n",
      "Training Stage ==> Epoch: 132 / 99999 | Training loss: 30.69008 |  Training Accuracy: 4.86308 | Training Metric (MAE): 4.86308\n",
      "Validation Stage ==> Epoch: 132 / 99999 | Validation loss: 32.31324 |  Validation Accuracy: 4.86847 | Validation Metric (MAE)): 4.86847\n",
      "Load Model from best epoch 132\n",
      "Training Stage ==> Epoch: 133 / 99999 | Training loss: 32.16182 |  Training Accuracy: 4.86428 | Training Metric (MAE): 4.86428\n",
      "Validation Stage ==> Epoch: 133 / 99999 | Validation loss: 32.30980 |  Validation Accuracy: 4.86812 | Validation Metric (MAE)): 4.86812\n",
      "Load Model from best epoch 133\n",
      "Training Stage ==> Epoch: 134 / 99999 | Training loss: 30.86563 |  Training Accuracy: 4.84115 | Training Metric (MAE): 4.84115\n",
      "Validation Stage ==> Epoch: 134 / 99999 | Validation loss: 32.30634 |  Validation Accuracy: 4.86776 | Validation Metric (MAE)): 4.86776\n",
      "Load Model from best epoch 134\n",
      "Training Stage ==> Epoch: 135 / 99999 | Training loss: 29.88881 |  Training Accuracy: 4.85311 | Training Metric (MAE): 4.85311\n",
      "Validation Stage ==> Epoch: 135 / 99999 | Validation loss: 32.30288 |  Validation Accuracy: 4.86741 | Validation Metric (MAE)): 4.86741\n",
      "Load Model from best epoch 135\n",
      "Training Stage ==> Epoch: 136 / 99999 | Training loss: 29.87351 |  Training Accuracy: 4.83407 | Training Metric (MAE): 4.83407\n",
      "Validation Stage ==> Epoch: 136 / 99999 | Validation loss: 32.29942 |  Validation Accuracy: 4.86706 | Validation Metric (MAE)): 4.86706\n",
      "Load Model from best epoch 136\n",
      "Training Stage ==> Epoch: 137 / 99999 | Training loss: 32.38958 |  Training Accuracy: 4.84195 | Training Metric (MAE): 4.84195\n",
      "Validation Stage ==> Epoch: 137 / 99999 | Validation loss: 32.29596 |  Validation Accuracy: 4.86671 | Validation Metric (MAE)): 4.86671\n",
      "Load Model from best epoch 137\n",
      "Training Stage ==> Epoch: 138 / 99999 | Training loss: 33.78810 |  Training Accuracy: 4.84131 | Training Metric (MAE): 4.84131\n",
      "Validation Stage ==> Epoch: 138 / 99999 | Validation loss: 32.29250 |  Validation Accuracy: 4.86635 | Validation Metric (MAE)): 4.86635\n",
      "Load Model from best epoch 138\n",
      "Training Stage ==> Epoch: 139 / 99999 | Training loss: 31.29312 |  Training Accuracy: 4.84531 | Training Metric (MAE): 4.84531\n",
      "Validation Stage ==> Epoch: 139 / 99999 | Validation loss: 32.28904 |  Validation Accuracy: 4.86600 | Validation Metric (MAE)): 4.86600\n",
      "Load Model from best epoch 139\n",
      "Training Stage ==> Epoch: 140 / 99999 | Training loss: 32.41850 |  Training Accuracy: 4.84752 | Training Metric (MAE): 4.84752\n",
      "Validation Stage ==> Epoch: 140 / 99999 | Validation loss: 32.28559 |  Validation Accuracy: 4.86565 | Validation Metric (MAE)): 4.86565\n",
      "Load Model from best epoch 140\n",
      "Training Stage ==> Epoch: 141 / 99999 | Training loss: 31.69758 |  Training Accuracy: 4.83717 | Training Metric (MAE): 4.83717\n",
      "Validation Stage ==> Epoch: 141 / 99999 | Validation loss: 32.28214 |  Validation Accuracy: 4.86529 | Validation Metric (MAE)): 4.86529\n",
      "Load Model from best epoch 141\n",
      "Training Stage ==> Epoch: 142 / 99999 | Training loss: 31.17052 |  Training Accuracy: 4.84042 | Training Metric (MAE): 4.84042\n",
      "Validation Stage ==> Epoch: 142 / 99999 | Validation loss: 32.27868 |  Validation Accuracy: 4.86494 | Validation Metric (MAE)): 4.86494\n",
      "Load Model from best epoch 142\n",
      "Training Stage ==> Epoch: 143 / 99999 | Training loss: 32.23793 |  Training Accuracy: 4.83452 | Training Metric (MAE): 4.83452\n",
      "Validation Stage ==> Epoch: 143 / 99999 | Validation loss: 32.27523 |  Validation Accuracy: 4.86459 | Validation Metric (MAE)): 4.86459\n",
      "Load Model from best epoch 143\n",
      "Training Stage ==> Epoch: 144 / 99999 | Training loss: 30.83818 |  Training Accuracy: 4.84104 | Training Metric (MAE): 4.84104\n",
      "Validation Stage ==> Epoch: 144 / 99999 | Validation loss: 32.27177 |  Validation Accuracy: 4.86424 | Validation Metric (MAE)): 4.86424\n",
      "Load Model from best epoch 144\n",
      "Training Stage ==> Epoch: 145 / 99999 | Training loss: 34.23528 |  Training Accuracy: 4.85234 | Training Metric (MAE): 4.85234\n",
      "Validation Stage ==> Epoch: 145 / 99999 | Validation loss: 32.26831 |  Validation Accuracy: 4.86388 | Validation Metric (MAE)): 4.86388\n",
      "Load Model from best epoch 145\n",
      "Training Stage ==> Epoch: 146 / 99999 | Training loss: 32.00153 |  Training Accuracy: 4.85217 | Training Metric (MAE): 4.85217\n",
      "Validation Stage ==> Epoch: 146 / 99999 | Validation loss: 32.26487 |  Validation Accuracy: 4.86353 | Validation Metric (MAE)): 4.86353\n",
      "Load Model from best epoch 146\n",
      "Training Stage ==> Epoch: 147 / 99999 | Training loss: 31.85972 |  Training Accuracy: 4.83512 | Training Metric (MAE): 4.83512\n",
      "Validation Stage ==> Epoch: 147 / 99999 | Validation loss: 32.26142 |  Validation Accuracy: 4.86318 | Validation Metric (MAE)): 4.86318\n",
      "Load Model from best epoch 147\n",
      "Training Stage ==> Epoch: 148 / 99999 | Training loss: 31.90052 |  Training Accuracy: 4.84004 | Training Metric (MAE): 4.84004\n",
      "Validation Stage ==> Epoch: 148 / 99999 | Validation loss: 32.25797 |  Validation Accuracy: 4.86283 | Validation Metric (MAE)): 4.86283\n",
      "Load Model from best epoch 148\n",
      "Training Stage ==> Epoch: 149 / 99999 | Training loss: 33.02420 |  Training Accuracy: 4.84178 | Training Metric (MAE): 4.84178\n",
      "Validation Stage ==> Epoch: 149 / 99999 | Validation loss: 32.25454 |  Validation Accuracy: 4.86247 | Validation Metric (MAE)): 4.86247\n",
      "Load Model from best epoch 149\n",
      "Training Stage ==> Epoch: 150 / 99999 | Training loss: 33.08780 |  Training Accuracy: 4.84547 | Training Metric (MAE): 4.84547\n",
      "Validation Stage ==> Epoch: 150 / 99999 | Validation loss: 32.25108 |  Validation Accuracy: 4.86212 | Validation Metric (MAE)): 4.86212\n",
      "Load Model from best epoch 150\n",
      "Training Stage ==> Epoch: 151 / 99999 | Training loss: 30.86597 |  Training Accuracy: 4.84218 | Training Metric (MAE): 4.84218\n",
      "Validation Stage ==> Epoch: 151 / 99999 | Validation loss: 32.24763 |  Validation Accuracy: 4.86177 | Validation Metric (MAE)): 4.86177\n",
      "Load Model from best epoch 151\n",
      "Training Stage ==> Epoch: 152 / 99999 | Training loss: 32.73938 |  Training Accuracy: 4.83460 | Training Metric (MAE): 4.83460\n",
      "Validation Stage ==> Epoch: 152 / 99999 | Validation loss: 32.24417 |  Validation Accuracy: 4.86142 | Validation Metric (MAE)): 4.86142\n",
      "Load Model from best epoch 152\n",
      "Training Stage ==> Epoch: 153 / 99999 | Training loss: 32.85089 |  Training Accuracy: 4.83187 | Training Metric (MAE): 4.83187\n",
      "Validation Stage ==> Epoch: 153 / 99999 | Validation loss: 32.24072 |  Validation Accuracy: 4.86106 | Validation Metric (MAE)): 4.86106\n",
      "Load Model from best epoch 153\n",
      "Training Stage ==> Epoch: 154 / 99999 | Training loss: 30.86748 |  Training Accuracy: 4.84005 | Training Metric (MAE): 4.84005\n",
      "Validation Stage ==> Epoch: 154 / 99999 | Validation loss: 32.23728 |  Validation Accuracy: 4.86071 | Validation Metric (MAE)): 4.86071\n",
      "Load Model from best epoch 154\n",
      "Training Stage ==> Epoch: 155 / 99999 | Training loss: 33.32765 |  Training Accuracy: 4.84858 | Training Metric (MAE): 4.84858\n",
      "Validation Stage ==> Epoch: 155 / 99999 | Validation loss: 32.23383 |  Validation Accuracy: 4.86036 | Validation Metric (MAE)): 4.86036\n",
      "Load Model from best epoch 155\n",
      "Training Stage ==> Epoch: 156 / 99999 | Training loss: 29.70116 |  Training Accuracy: 4.83003 | Training Metric (MAE): 4.83003\n",
      "Validation Stage ==> Epoch: 156 / 99999 | Validation loss: 32.23039 |  Validation Accuracy: 4.86001 | Validation Metric (MAE)): 4.86001\n",
      "Load Model from best epoch 156\n",
      "Training Stage ==> Epoch: 157 / 99999 | Training loss: 31.06996 |  Training Accuracy: 4.83349 | Training Metric (MAE): 4.83349\n",
      "Validation Stage ==> Epoch: 157 / 99999 | Validation loss: 32.22694 |  Validation Accuracy: 4.85965 | Validation Metric (MAE)): 4.85965\n",
      "Load Model from best epoch 157\n",
      "Training Stage ==> Epoch: 158 / 99999 | Training loss: 29.61530 |  Training Accuracy: 4.84125 | Training Metric (MAE): 4.84125\n",
      "Validation Stage ==> Epoch: 158 / 99999 | Validation loss: 32.22351 |  Validation Accuracy: 4.85930 | Validation Metric (MAE)): 4.85930\n",
      "Load Model from best epoch 158\n",
      "Training Stage ==> Epoch: 159 / 99999 | Training loss: 31.62142 |  Training Accuracy: 4.83348 | Training Metric (MAE): 4.83348\n",
      "Validation Stage ==> Epoch: 159 / 99999 | Validation loss: 32.22006 |  Validation Accuracy: 4.85895 | Validation Metric (MAE)): 4.85895\n",
      "Load Model from best epoch 159\n",
      "Training Stage ==> Epoch: 160 / 99999 | Training loss: 30.78467 |  Training Accuracy: 4.83108 | Training Metric (MAE): 4.83108\n",
      "Validation Stage ==> Epoch: 160 / 99999 | Validation loss: 32.21662 |  Validation Accuracy: 4.85860 | Validation Metric (MAE)): 4.85860\n",
      "Load Model from best epoch 160\n",
      "Training Stage ==> Epoch: 161 / 99999 | Training loss: 30.91065 |  Training Accuracy: 4.83713 | Training Metric (MAE): 4.83713\n",
      "Validation Stage ==> Epoch: 161 / 99999 | Validation loss: 32.21318 |  Validation Accuracy: 4.85825 | Validation Metric (MAE)): 4.85825\n",
      "Load Model from best epoch 161\n",
      "Training Stage ==> Epoch: 162 / 99999 | Training loss: 30.34071 |  Training Accuracy: 4.83684 | Training Metric (MAE): 4.83684\n",
      "Validation Stage ==> Epoch: 162 / 99999 | Validation loss: 32.20974 |  Validation Accuracy: 4.85789 | Validation Metric (MAE)): 4.85789\n",
      "Load Model from best epoch 162\n",
      "Training Stage ==> Epoch: 163 / 99999 | Training loss: 30.73266 |  Training Accuracy: 4.83489 | Training Metric (MAE): 4.83489\n",
      "Validation Stage ==> Epoch: 163 / 99999 | Validation loss: 32.20631 |  Validation Accuracy: 4.85754 | Validation Metric (MAE)): 4.85754\n",
      "Load Model from best epoch 163\n",
      "Training Stage ==> Epoch: 164 / 99999 | Training loss: 31.69564 |  Training Accuracy: 4.84950 | Training Metric (MAE): 4.84950\n",
      "Validation Stage ==> Epoch: 164 / 99999 | Validation loss: 32.20288 |  Validation Accuracy: 4.85719 | Validation Metric (MAE)): 4.85719\n",
      "Load Model from best epoch 164\n",
      "Training Stage ==> Epoch: 165 / 99999 | Training loss: 30.24735 |  Training Accuracy: 4.84681 | Training Metric (MAE): 4.84681\n",
      "Validation Stage ==> Epoch: 165 / 99999 | Validation loss: 32.19945 |  Validation Accuracy: 4.85684 | Validation Metric (MAE)): 4.85684\n",
      "Load Model from best epoch 165\n",
      "Training Stage ==> Epoch: 166 / 99999 | Training loss: 29.70353 |  Training Accuracy: 4.82891 | Training Metric (MAE): 4.82891\n",
      "Validation Stage ==> Epoch: 166 / 99999 | Validation loss: 32.19602 |  Validation Accuracy: 4.85649 | Validation Metric (MAE)): 4.85649\n",
      "Load Model from best epoch 166\n",
      "Training Stage ==> Epoch: 167 / 99999 | Training loss: 30.08786 |  Training Accuracy: 4.83235 | Training Metric (MAE): 4.83235\n",
      "Validation Stage ==> Epoch: 167 / 99999 | Validation loss: 32.19259 |  Validation Accuracy: 4.85614 | Validation Metric (MAE)): 4.85614\n",
      "Load Model from best epoch 167\n",
      "Training Stage ==> Epoch: 168 / 99999 | Training loss: 30.58417 |  Training Accuracy: 4.83072 | Training Metric (MAE): 4.83072\n",
      "Validation Stage ==> Epoch: 168 / 99999 | Validation loss: 32.18916 |  Validation Accuracy: 4.85579 | Validation Metric (MAE)): 4.85579\n",
      "Load Model from best epoch 168\n",
      "Training Stage ==> Epoch: 169 / 99999 | Training loss: 31.02836 |  Training Accuracy: 4.83723 | Training Metric (MAE): 4.83723\n",
      "Validation Stage ==> Epoch: 169 / 99999 | Validation loss: 32.18573 |  Validation Accuracy: 4.85544 | Validation Metric (MAE)): 4.85544\n",
      "Load Model from best epoch 169\n",
      "Training Stage ==> Epoch: 170 / 99999 | Training loss: 33.18830 |  Training Accuracy: 4.83323 | Training Metric (MAE): 4.83323\n",
      "Validation Stage ==> Epoch: 170 / 99999 | Validation loss: 32.18230 |  Validation Accuracy: 4.85509 | Validation Metric (MAE)): 4.85509\n",
      "Load Model from best epoch 170\n",
      "Training Stage ==> Epoch: 171 / 99999 | Training loss: 32.18823 |  Training Accuracy: 4.84016 | Training Metric (MAE): 4.84016\n",
      "Validation Stage ==> Epoch: 171 / 99999 | Validation loss: 32.17886 |  Validation Accuracy: 4.85474 | Validation Metric (MAE)): 4.85474\n",
      "Load Model from best epoch 171\n",
      "Training Stage ==> Epoch: 172 / 99999 | Training loss: 33.64737 |  Training Accuracy: 4.84232 | Training Metric (MAE): 4.84232\n",
      "Validation Stage ==> Epoch: 172 / 99999 | Validation loss: 32.17543 |  Validation Accuracy: 4.85438 | Validation Metric (MAE)): 4.85438\n",
      "Load Model from best epoch 172\n",
      "Training Stage ==> Epoch: 173 / 99999 | Training loss: 31.63520 |  Training Accuracy: 4.83643 | Training Metric (MAE): 4.83643\n",
      "Validation Stage ==> Epoch: 173 / 99999 | Validation loss: 32.17200 |  Validation Accuracy: 4.85403 | Validation Metric (MAE)): 4.85403\n",
      "Load Model from best epoch 173\n",
      "Training Stage ==> Epoch: 174 / 99999 | Training loss: 33.28827 |  Training Accuracy: 4.83590 | Training Metric (MAE): 4.83590\n",
      "Validation Stage ==> Epoch: 174 / 99999 | Validation loss: 32.16857 |  Validation Accuracy: 4.85368 | Validation Metric (MAE)): 4.85368\n",
      "Load Model from best epoch 174\n",
      "Training Stage ==> Epoch: 175 / 99999 | Training loss: 31.82875 |  Training Accuracy: 4.83796 | Training Metric (MAE): 4.83796\n",
      "Validation Stage ==> Epoch: 175 / 99999 | Validation loss: 32.16513 |  Validation Accuracy: 4.85333 | Validation Metric (MAE)): 4.85333\n",
      "Load Model from best epoch 175\n",
      "Training Stage ==> Epoch: 176 / 99999 | Training loss: 32.18040 |  Training Accuracy: 4.83474 | Training Metric (MAE): 4.83474\n",
      "Validation Stage ==> Epoch: 176 / 99999 | Validation loss: 32.16171 |  Validation Accuracy: 4.85298 | Validation Metric (MAE)): 4.85298\n",
      "Load Model from best epoch 176\n",
      "Training Stage ==> Epoch: 177 / 99999 | Training loss: 31.52119 |  Training Accuracy: 4.83475 | Training Metric (MAE): 4.83475\n",
      "Validation Stage ==> Epoch: 177 / 99999 | Validation loss: 32.15828 |  Validation Accuracy: 4.85263 | Validation Metric (MAE)): 4.85263\n",
      "Load Model from best epoch 177\n",
      "Training Stage ==> Epoch: 178 / 99999 | Training loss: 31.41343 |  Training Accuracy: 4.82870 | Training Metric (MAE): 4.82870\n",
      "Validation Stage ==> Epoch: 178 / 99999 | Validation loss: 32.15485 |  Validation Accuracy: 4.85228 | Validation Metric (MAE)): 4.85228\n",
      "Load Model from best epoch 178\n",
      "Training Stage ==> Epoch: 179 / 99999 | Training loss: 30.70577 |  Training Accuracy: 4.82991 | Training Metric (MAE): 4.82991\n",
      "Validation Stage ==> Epoch: 179 / 99999 | Validation loss: 32.15143 |  Validation Accuracy: 4.85193 | Validation Metric (MAE)): 4.85193\n",
      "Load Model from best epoch 179\n",
      "Training Stage ==> Epoch: 180 / 99999 | Training loss: 31.19940 |  Training Accuracy: 4.82568 | Training Metric (MAE): 4.82568\n",
      "Validation Stage ==> Epoch: 180 / 99999 | Validation loss: 32.14801 |  Validation Accuracy: 4.85158 | Validation Metric (MAE)): 4.85158\n",
      "Load Model from best epoch 180\n",
      "Training Stage ==> Epoch: 181 / 99999 | Training loss: 31.81264 |  Training Accuracy: 4.83481 | Training Metric (MAE): 4.83481\n",
      "Validation Stage ==> Epoch: 181 / 99999 | Validation loss: 32.14459 |  Validation Accuracy: 4.85123 | Validation Metric (MAE)): 4.85123\n",
      "Load Model from best epoch 181\n",
      "Training Stage ==> Epoch: 182 / 99999 | Training loss: 32.89453 |  Training Accuracy: 4.83223 | Training Metric (MAE): 4.83223\n",
      "Validation Stage ==> Epoch: 182 / 99999 | Validation loss: 32.14116 |  Validation Accuracy: 4.85088 | Validation Metric (MAE)): 4.85088\n",
      "Load Model from best epoch 182\n",
      "Training Stage ==> Epoch: 183 / 99999 | Training loss: 30.27773 |  Training Accuracy: 4.83725 | Training Metric (MAE): 4.83725\n",
      "Validation Stage ==> Epoch: 183 / 99999 | Validation loss: 32.13774 |  Validation Accuracy: 4.85052 | Validation Metric (MAE)): 4.85052\n",
      "Load Model from best epoch 183\n",
      "Training Stage ==> Epoch: 184 / 99999 | Training loss: 33.27160 |  Training Accuracy: 4.84406 | Training Metric (MAE): 4.84406\n",
      "Validation Stage ==> Epoch: 184 / 99999 | Validation loss: 32.13432 |  Validation Accuracy: 4.85017 | Validation Metric (MAE)): 4.85017\n",
      "Load Model from best epoch 184\n",
      "Training Stage ==> Epoch: 185 / 99999 | Training loss: 32.30644 |  Training Accuracy: 4.81808 | Training Metric (MAE): 4.81808\n",
      "Validation Stage ==> Epoch: 185 / 99999 | Validation loss: 32.13090 |  Validation Accuracy: 4.84982 | Validation Metric (MAE)): 4.84982\n",
      "Load Model from best epoch 185\n",
      "Training Stage ==> Epoch: 186 / 99999 | Training loss: 31.05129 |  Training Accuracy: 4.83713 | Training Metric (MAE): 4.83713\n",
      "Validation Stage ==> Epoch: 186 / 99999 | Validation loss: 32.12747 |  Validation Accuracy: 4.84947 | Validation Metric (MAE)): 4.84947\n",
      "Load Model from best epoch 186\n",
      "Training Stage ==> Epoch: 187 / 99999 | Training loss: 31.26580 |  Training Accuracy: 4.83173 | Training Metric (MAE): 4.83173\n",
      "Validation Stage ==> Epoch: 187 / 99999 | Validation loss: 32.12406 |  Validation Accuracy: 4.84912 | Validation Metric (MAE)): 4.84912\n",
      "Load Model from best epoch 187\n",
      "Training Stage ==> Epoch: 188 / 99999 | Training loss: 31.40006 |  Training Accuracy: 4.82816 | Training Metric (MAE): 4.82816\n",
      "Validation Stage ==> Epoch: 188 / 99999 | Validation loss: 32.12065 |  Validation Accuracy: 4.84877 | Validation Metric (MAE)): 4.84877\n",
      "Load Model from best epoch 188\n",
      "Training Stage ==> Epoch: 189 / 99999 | Training loss: 30.02981 |  Training Accuracy: 4.82948 | Training Metric (MAE): 4.82948\n",
      "Validation Stage ==> Epoch: 189 / 99999 | Validation loss: 32.11723 |  Validation Accuracy: 4.84842 | Validation Metric (MAE)): 4.84842\n",
      "Load Model from best epoch 189\n",
      "Training Stage ==> Epoch: 190 / 99999 | Training loss: 32.59163 |  Training Accuracy: 4.82592 | Training Metric (MAE): 4.82592\n",
      "Validation Stage ==> Epoch: 190 / 99999 | Validation loss: 32.11382 |  Validation Accuracy: 4.84807 | Validation Metric (MAE)): 4.84807\n",
      "Load Model from best epoch 190\n",
      "Training Stage ==> Epoch: 191 / 99999 | Training loss: 29.86866 |  Training Accuracy: 4.83451 | Training Metric (MAE): 4.83451\n",
      "Validation Stage ==> Epoch: 191 / 99999 | Validation loss: 32.11040 |  Validation Accuracy: 4.84772 | Validation Metric (MAE)): 4.84772\n",
      "Load Model from best epoch 191\n",
      "Training Stage ==> Epoch: 192 / 99999 | Training loss: 31.01227 |  Training Accuracy: 4.83514 | Training Metric (MAE): 4.83514\n",
      "Validation Stage ==> Epoch: 192 / 99999 | Validation loss: 32.10698 |  Validation Accuracy: 4.84737 | Validation Metric (MAE)): 4.84737\n",
      "Load Model from best epoch 192\n",
      "Training Stage ==> Epoch: 193 / 99999 | Training loss: 31.62256 |  Training Accuracy: 4.83266 | Training Metric (MAE): 4.83266\n",
      "Validation Stage ==> Epoch: 193 / 99999 | Validation loss: 32.10357 |  Validation Accuracy: 4.84702 | Validation Metric (MAE)): 4.84702\n",
      "Load Model from best epoch 193\n",
      "Training Stage ==> Epoch: 194 / 99999 | Training loss: 33.58321 |  Training Accuracy: 4.84308 | Training Metric (MAE): 4.84308\n",
      "Validation Stage ==> Epoch: 194 / 99999 | Validation loss: 32.10016 |  Validation Accuracy: 4.84667 | Validation Metric (MAE)): 4.84667\n",
      "Load Model from best epoch 194\n",
      "Training Stage ==> Epoch: 195 / 99999 | Training loss: 30.59413 |  Training Accuracy: 4.82776 | Training Metric (MAE): 4.82776\n",
      "Validation Stage ==> Epoch: 195 / 99999 | Validation loss: 32.09675 |  Validation Accuracy: 4.84632 | Validation Metric (MAE)): 4.84632\n",
      "Load Model from best epoch 195\n",
      "Training Stage ==> Epoch: 196 / 99999 | Training loss: 30.43472 |  Training Accuracy: 4.81243 | Training Metric (MAE): 4.81243\n",
      "Validation Stage ==> Epoch: 196 / 99999 | Validation loss: 32.09335 |  Validation Accuracy: 4.84598 | Validation Metric (MAE)): 4.84598\n",
      "Load Model from best epoch 196\n",
      "Training Stage ==> Epoch: 197 / 99999 | Training loss: 30.28848 |  Training Accuracy: 4.82349 | Training Metric (MAE): 4.82349\n",
      "Validation Stage ==> Epoch: 197 / 99999 | Validation loss: 32.08995 |  Validation Accuracy: 4.84563 | Validation Metric (MAE)): 4.84563\n",
      "Load Model from best epoch 197\n",
      "Training Stage ==> Epoch: 198 / 99999 | Training loss: 30.00303 |  Training Accuracy: 4.82313 | Training Metric (MAE): 4.82313\n",
      "Validation Stage ==> Epoch: 198 / 99999 | Validation loss: 32.08654 |  Validation Accuracy: 4.84528 | Validation Metric (MAE)): 4.84528\n",
      "Load Model from best epoch 198\n",
      "Training Stage ==> Epoch: 199 / 99999 | Training loss: 31.01340 |  Training Accuracy: 4.82164 | Training Metric (MAE): 4.82164\n",
      "Validation Stage ==> Epoch: 199 / 99999 | Validation loss: 32.08313 |  Validation Accuracy: 4.84493 | Validation Metric (MAE)): 4.84493\n",
      "Load Model from best epoch 199\n",
      "Training Stage ==> Epoch: 200 / 99999 | Training loss: 31.31721 |  Training Accuracy: 4.83269 | Training Metric (MAE): 4.83269\n",
      "Validation Stage ==> Epoch: 200 / 99999 | Validation loss: 32.07973 |  Validation Accuracy: 4.84458 | Validation Metric (MAE)): 4.84458\n",
      "Load Model from best epoch 200\n",
      "Training Stage ==> Epoch: 201 / 99999 | Training loss: 32.84073 |  Training Accuracy: 4.82106 | Training Metric (MAE): 4.82106\n",
      "Validation Stage ==> Epoch: 201 / 99999 | Validation loss: 32.07632 |  Validation Accuracy: 4.84423 | Validation Metric (MAE)): 4.84423\n",
      "Load Model from best epoch 201\n",
      "Training Stage ==> Epoch: 202 / 99999 | Training loss: 31.28344 |  Training Accuracy: 4.81001 | Training Metric (MAE): 4.81001\n",
      "Validation Stage ==> Epoch: 202 / 99999 | Validation loss: 32.07292 |  Validation Accuracy: 4.84388 | Validation Metric (MAE)): 4.84388\n",
      "Load Model from best epoch 202\n",
      "Training Stage ==> Epoch: 203 / 99999 | Training loss: 31.02459 |  Training Accuracy: 4.80743 | Training Metric (MAE): 4.80743\n",
      "Validation Stage ==> Epoch: 203 / 99999 | Validation loss: 32.06952 |  Validation Accuracy: 4.84353 | Validation Metric (MAE)): 4.84353\n",
      "Load Model from best epoch 203\n",
      "Training Stage ==> Epoch: 204 / 99999 | Training loss: 30.84176 |  Training Accuracy: 4.82559 | Training Metric (MAE): 4.82559\n",
      "Validation Stage ==> Epoch: 204 / 99999 | Validation loss: 32.06611 |  Validation Accuracy: 4.84318 | Validation Metric (MAE)): 4.84318\n",
      "Load Model from best epoch 204\n",
      "Training Stage ==> Epoch: 205 / 99999 | Training loss: 32.15475 |  Training Accuracy: 4.82659 | Training Metric (MAE): 4.82659\n",
      "Validation Stage ==> Epoch: 205 / 99999 | Validation loss: 32.06270 |  Validation Accuracy: 4.84283 | Validation Metric (MAE)): 4.84283\n",
      "Load Model from best epoch 205\n",
      "Training Stage ==> Epoch: 206 / 99999 | Training loss: 32.08102 |  Training Accuracy: 4.82831 | Training Metric (MAE): 4.82831\n",
      "Validation Stage ==> Epoch: 206 / 99999 | Validation loss: 32.05929 |  Validation Accuracy: 4.84248 | Validation Metric (MAE)): 4.84248\n",
      "Load Model from best epoch 206\n",
      "Training Stage ==> Epoch: 207 / 99999 | Training loss: 32.85670 |  Training Accuracy: 4.81400 | Training Metric (MAE): 4.81400\n",
      "Validation Stage ==> Epoch: 207 / 99999 | Validation loss: 32.05589 |  Validation Accuracy: 4.84213 | Validation Metric (MAE)): 4.84213\n",
      "Load Model from best epoch 207\n",
      "Training Stage ==> Epoch: 208 / 99999 | Training loss: 32.20195 |  Training Accuracy: 4.81695 | Training Metric (MAE): 4.81695\n",
      "Validation Stage ==> Epoch: 208 / 99999 | Validation loss: 32.05248 |  Validation Accuracy: 4.84178 | Validation Metric (MAE)): 4.84178\n",
      "Load Model from best epoch 208\n",
      "Training Stage ==> Epoch: 209 / 99999 | Training loss: 29.35141 |  Training Accuracy: 4.82175 | Training Metric (MAE): 4.82175\n",
      "Validation Stage ==> Epoch: 209 / 99999 | Validation loss: 32.04908 |  Validation Accuracy: 4.84143 | Validation Metric (MAE)): 4.84143\n",
      "Load Model from best epoch 209\n",
      "Training Stage ==> Epoch: 210 / 99999 | Training loss: 31.61344 |  Training Accuracy: 4.82066 | Training Metric (MAE): 4.82066\n",
      "Validation Stage ==> Epoch: 210 / 99999 | Validation loss: 32.04568 |  Validation Accuracy: 4.84109 | Validation Metric (MAE)): 4.84109\n",
      "Load Model from best epoch 210\n",
      "Training Stage ==> Epoch: 211 / 99999 | Training loss: 29.40620 |  Training Accuracy: 4.81449 | Training Metric (MAE): 4.81449\n",
      "Validation Stage ==> Epoch: 211 / 99999 | Validation loss: 32.04229 |  Validation Accuracy: 4.84074 | Validation Metric (MAE)): 4.84074\n",
      "Load Model from best epoch 211\n",
      "Training Stage ==> Epoch: 212 / 99999 | Training loss: 30.53784 |  Training Accuracy: 4.81789 | Training Metric (MAE): 4.81789\n",
      "Validation Stage ==> Epoch: 212 / 99999 | Validation loss: 32.03890 |  Validation Accuracy: 4.84039 | Validation Metric (MAE)): 4.84039\n",
      "Load Model from best epoch 212\n",
      "Training Stage ==> Epoch: 213 / 99999 | Training loss: 31.56282 |  Training Accuracy: 4.81465 | Training Metric (MAE): 4.81465\n",
      "Validation Stage ==> Epoch: 213 / 99999 | Validation loss: 32.03550 |  Validation Accuracy: 4.84004 | Validation Metric (MAE)): 4.84004\n",
      "Load Model from best epoch 213\n",
      "Training Stage ==> Epoch: 214 / 99999 | Training loss: 32.01440 |  Training Accuracy: 4.82193 | Training Metric (MAE): 4.82193\n",
      "Validation Stage ==> Epoch: 214 / 99999 | Validation loss: 32.03211 |  Validation Accuracy: 4.83969 | Validation Metric (MAE)): 4.83969\n",
      "Load Model from best epoch 214\n",
      "Training Stage ==> Epoch: 215 / 99999 | Training loss: 31.53652 |  Training Accuracy: 4.81164 | Training Metric (MAE): 4.81164\n",
      "Validation Stage ==> Epoch: 215 / 99999 | Validation loss: 32.02870 |  Validation Accuracy: 4.83934 | Validation Metric (MAE)): 4.83934\n",
      "Load Model from best epoch 215\n",
      "Training Stage ==> Epoch: 216 / 99999 | Training loss: 31.16999 |  Training Accuracy: 4.81967 | Training Metric (MAE): 4.81967\n",
      "Validation Stage ==> Epoch: 216 / 99999 | Validation loss: 32.02531 |  Validation Accuracy: 4.83899 | Validation Metric (MAE)): 4.83899\n",
      "Load Model from best epoch 216\n",
      "Training Stage ==> Epoch: 217 / 99999 | Training loss: 31.96026 |  Training Accuracy: 4.81412 | Training Metric (MAE): 4.81412\n",
      "Validation Stage ==> Epoch: 217 / 99999 | Validation loss: 32.02192 |  Validation Accuracy: 4.83865 | Validation Metric (MAE)): 4.83865\n",
      "Load Model from best epoch 217\n",
      "Training Stage ==> Epoch: 218 / 99999 | Training loss: 30.81750 |  Training Accuracy: 4.82213 | Training Metric (MAE): 4.82213\n",
      "Validation Stage ==> Epoch: 218 / 99999 | Validation loss: 32.01852 |  Validation Accuracy: 4.83830 | Validation Metric (MAE)): 4.83830\n",
      "Load Model from best epoch 218\n",
      "Training Stage ==> Epoch: 219 / 99999 | Training loss: 31.10272 |  Training Accuracy: 4.81722 | Training Metric (MAE): 4.81722\n",
      "Validation Stage ==> Epoch: 219 / 99999 | Validation loss: 32.01514 |  Validation Accuracy: 4.83795 | Validation Metric (MAE)): 4.83795\n",
      "Load Model from best epoch 219\n",
      "Training Stage ==> Epoch: 220 / 99999 | Training loss: 32.18701 |  Training Accuracy: 4.82421 | Training Metric (MAE): 4.82421\n",
      "Validation Stage ==> Epoch: 220 / 99999 | Validation loss: 32.01175 |  Validation Accuracy: 4.83760 | Validation Metric (MAE)): 4.83760\n",
      "Load Model from best epoch 220\n",
      "Training Stage ==> Epoch: 221 / 99999 | Training loss: 30.41284 |  Training Accuracy: 4.81474 | Training Metric (MAE): 4.81474\n",
      "Validation Stage ==> Epoch: 221 / 99999 | Validation loss: 32.00836 |  Validation Accuracy: 4.83725 | Validation Metric (MAE)): 4.83725\n",
      "Load Model from best epoch 221\n",
      "Training Stage ==> Epoch: 222 / 99999 | Training loss: 29.67260 |  Training Accuracy: 4.81239 | Training Metric (MAE): 4.81239\n",
      "Validation Stage ==> Epoch: 222 / 99999 | Validation loss: 32.00497 |  Validation Accuracy: 4.83691 | Validation Metric (MAE)): 4.83691\n",
      "Load Model from best epoch 222\n",
      "Training Stage ==> Epoch: 223 / 99999 | Training loss: 31.10720 |  Training Accuracy: 4.80659 | Training Metric (MAE): 4.80659\n",
      "Validation Stage ==> Epoch: 223 / 99999 | Validation loss: 32.00159 |  Validation Accuracy: 4.83656 | Validation Metric (MAE)): 4.83656\n",
      "Load Model from best epoch 223\n",
      "Training Stage ==> Epoch: 224 / 99999 | Training loss: 30.46811 |  Training Accuracy: 4.81584 | Training Metric (MAE): 4.81584\n",
      "Validation Stage ==> Epoch: 224 / 99999 | Validation loss: 31.99820 |  Validation Accuracy: 4.83621 | Validation Metric (MAE)): 4.83621\n",
      "Load Model from best epoch 224\n",
      "Training Stage ==> Epoch: 225 / 99999 | Training loss: 31.46170 |  Training Accuracy: 4.81006 | Training Metric (MAE): 4.81006\n",
      "Validation Stage ==> Epoch: 225 / 99999 | Validation loss: 31.99481 |  Validation Accuracy: 4.83586 | Validation Metric (MAE)): 4.83586\n",
      "Load Model from best epoch 225\n",
      "Training Stage ==> Epoch: 226 / 99999 | Training loss: 31.21138 |  Training Accuracy: 4.81550 | Training Metric (MAE): 4.81550\n",
      "Validation Stage ==> Epoch: 226 / 99999 | Validation loss: 31.99142 |  Validation Accuracy: 4.83551 | Validation Metric (MAE)): 4.83551\n",
      "Load Model from best epoch 226\n",
      "Training Stage ==> Epoch: 227 / 99999 | Training loss: 29.13074 |  Training Accuracy: 4.82454 | Training Metric (MAE): 4.82454\n",
      "Validation Stage ==> Epoch: 227 / 99999 | Validation loss: 31.98806 |  Validation Accuracy: 4.83517 | Validation Metric (MAE)): 4.83517\n",
      "Load Model from best epoch 227\n",
      "Training Stage ==> Epoch: 228 / 99999 | Training loss: 30.47298 |  Training Accuracy: 4.81710 | Training Metric (MAE): 4.81710\n",
      "Validation Stage ==> Epoch: 228 / 99999 | Validation loss: 31.98467 |  Validation Accuracy: 4.83482 | Validation Metric (MAE)): 4.83482\n",
      "Load Model from best epoch 228\n",
      "Training Stage ==> Epoch: 229 / 99999 | Training loss: 32.64401 |  Training Accuracy: 4.81939 | Training Metric (MAE): 4.81939\n",
      "Validation Stage ==> Epoch: 229 / 99999 | Validation loss: 31.98128 |  Validation Accuracy: 4.83447 | Validation Metric (MAE)): 4.83447\n",
      "Load Model from best epoch 229\n",
      "Training Stage ==> Epoch: 230 / 99999 | Training loss: 31.04163 |  Training Accuracy: 4.79901 | Training Metric (MAE): 4.79901\n",
      "Validation Stage ==> Epoch: 230 / 99999 | Validation loss: 31.97791 |  Validation Accuracy: 4.83412 | Validation Metric (MAE)): 4.83412\n",
      "Load Model from best epoch 230\n",
      "Training Stage ==> Epoch: 231 / 99999 | Training loss: 30.92989 |  Training Accuracy: 4.81661 | Training Metric (MAE): 4.81661\n",
      "Validation Stage ==> Epoch: 231 / 99999 | Validation loss: 31.97452 |  Validation Accuracy: 4.83378 | Validation Metric (MAE)): 4.83378\n",
      "Load Model from best epoch 231\n",
      "Training Stage ==> Epoch: 232 / 99999 | Training loss: 31.39680 |  Training Accuracy: 4.82063 | Training Metric (MAE): 4.82063\n",
      "Validation Stage ==> Epoch: 232 / 99999 | Validation loss: 31.97115 |  Validation Accuracy: 4.83343 | Validation Metric (MAE)): 4.83343\n",
      "Load Model from best epoch 232\n",
      "Training Stage ==> Epoch: 233 / 99999 | Training loss: 31.93404 |  Training Accuracy: 4.81239 | Training Metric (MAE): 4.81239\n",
      "Validation Stage ==> Epoch: 233 / 99999 | Validation loss: 31.96777 |  Validation Accuracy: 4.83308 | Validation Metric (MAE)): 4.83308\n",
      "Load Model from best epoch 233\n",
      "Training Stage ==> Epoch: 234 / 99999 | Training loss: 29.21737 |  Training Accuracy: 4.82014 | Training Metric (MAE): 4.82014\n",
      "Validation Stage ==> Epoch: 234 / 99999 | Validation loss: 31.96440 |  Validation Accuracy: 4.83274 | Validation Metric (MAE)): 4.83274\n",
      "Load Model from best epoch 234\n",
      "Training Stage ==> Epoch: 235 / 99999 | Training loss: 29.05861 |  Training Accuracy: 4.80426 | Training Metric (MAE): 4.80426\n",
      "Validation Stage ==> Epoch: 235 / 99999 | Validation loss: 31.96102 |  Validation Accuracy: 4.83239 | Validation Metric (MAE)): 4.83239\n",
      "Load Model from best epoch 235\n",
      "Training Stage ==> Epoch: 236 / 99999 | Training loss: 29.97266 |  Training Accuracy: 4.80817 | Training Metric (MAE): 4.80817\n",
      "Validation Stage ==> Epoch: 236 / 99999 | Validation loss: 31.95765 |  Validation Accuracy: 4.83204 | Validation Metric (MAE)): 4.83204\n",
      "Load Model from best epoch 236\n",
      "Training Stage ==> Epoch: 237 / 99999 | Training loss: 33.87825 |  Training Accuracy: 4.80570 | Training Metric (MAE): 4.80570\n",
      "Validation Stage ==> Epoch: 237 / 99999 | Validation loss: 31.95428 |  Validation Accuracy: 4.83170 | Validation Metric (MAE)): 4.83170\n",
      "Load Model from best epoch 237\n",
      "Training Stage ==> Epoch: 238 / 99999 | Training loss: 31.08143 |  Training Accuracy: 4.79514 | Training Metric (MAE): 4.79514\n",
      "Validation Stage ==> Epoch: 238 / 99999 | Validation loss: 31.95089 |  Validation Accuracy: 4.83135 | Validation Metric (MAE)): 4.83135\n",
      "Load Model from best epoch 238\n",
      "Training Stage ==> Epoch: 239 / 99999 | Training loss: 30.03555 |  Training Accuracy: 4.81690 | Training Metric (MAE): 4.81690\n",
      "Validation Stage ==> Epoch: 239 / 99999 | Validation loss: 31.94752 |  Validation Accuracy: 4.83100 | Validation Metric (MAE)): 4.83100\n",
      "Load Model from best epoch 239\n",
      "Training Stage ==> Epoch: 240 / 99999 | Training loss: 32.19634 |  Training Accuracy: 4.80605 | Training Metric (MAE): 4.80605\n",
      "Validation Stage ==> Epoch: 240 / 99999 | Validation loss: 31.94415 |  Validation Accuracy: 4.83065 | Validation Metric (MAE)): 4.83065\n",
      "Load Model from best epoch 240\n",
      "Training Stage ==> Epoch: 241 / 99999 | Training loss: 29.70306 |  Training Accuracy: 4.80746 | Training Metric (MAE): 4.80746\n",
      "Validation Stage ==> Epoch: 241 / 99999 | Validation loss: 31.94077 |  Validation Accuracy: 4.83031 | Validation Metric (MAE)): 4.83031\n",
      "Load Model from best epoch 241\n",
      "Training Stage ==> Epoch: 242 / 99999 | Training loss: 31.56265 |  Training Accuracy: 4.81452 | Training Metric (MAE): 4.81452\n",
      "Validation Stage ==> Epoch: 242 / 99999 | Validation loss: 31.93740 |  Validation Accuracy: 4.82996 | Validation Metric (MAE)): 4.82996\n",
      "Load Model from best epoch 242\n",
      "Training Stage ==> Epoch: 243 / 99999 | Training loss: 30.25182 |  Training Accuracy: 4.82500 | Training Metric (MAE): 4.82500\n",
      "Validation Stage ==> Epoch: 243 / 99999 | Validation loss: 31.93403 |  Validation Accuracy: 4.82961 | Validation Metric (MAE)): 4.82961\n",
      "Load Model from best epoch 243\n",
      "Training Stage ==> Epoch: 244 / 99999 | Training loss: 29.12391 |  Training Accuracy: 4.80514 | Training Metric (MAE): 4.80514\n",
      "Validation Stage ==> Epoch: 244 / 99999 | Validation loss: 31.93067 |  Validation Accuracy: 4.82927 | Validation Metric (MAE)): 4.82927\n",
      "Load Model from best epoch 244\n",
      "Training Stage ==> Epoch: 245 / 99999 | Training loss: 32.63518 |  Training Accuracy: 4.81730 | Training Metric (MAE): 4.81730\n",
      "Validation Stage ==> Epoch: 245 / 99999 | Validation loss: 31.92730 |  Validation Accuracy: 4.82892 | Validation Metric (MAE)): 4.82892\n",
      "Load Model from best epoch 245\n",
      "Training Stage ==> Epoch: 246 / 99999 | Training loss: 30.18869 |  Training Accuracy: 4.80830 | Training Metric (MAE): 4.80830\n",
      "Validation Stage ==> Epoch: 246 / 99999 | Validation loss: 31.92394 |  Validation Accuracy: 4.82857 | Validation Metric (MAE)): 4.82857\n",
      "Load Model from best epoch 246\n",
      "Training Stage ==> Epoch: 247 / 99999 | Training loss: 31.40845 |  Training Accuracy: 4.80124 | Training Metric (MAE): 4.80124\n",
      "Validation Stage ==> Epoch: 247 / 99999 | Validation loss: 31.92057 |  Validation Accuracy: 4.82823 | Validation Metric (MAE)): 4.82823\n",
      "Load Model from best epoch 247\n",
      "Training Stage ==> Epoch: 248 / 99999 | Training loss: 32.30858 |  Training Accuracy: 4.80819 | Training Metric (MAE): 4.80819\n",
      "Validation Stage ==> Epoch: 248 / 99999 | Validation loss: 31.91720 |  Validation Accuracy: 4.82788 | Validation Metric (MAE)): 4.82788\n",
      "Load Model from best epoch 248\n",
      "Training Stage ==> Epoch: 249 / 99999 | Training loss: 32.52148 |  Training Accuracy: 4.81393 | Training Metric (MAE): 4.81393\n",
      "Validation Stage ==> Epoch: 249 / 99999 | Validation loss: 31.91383 |  Validation Accuracy: 4.82753 | Validation Metric (MAE)): 4.82753\n",
      "Load Model from best epoch 249\n",
      "Training Stage ==> Epoch: 250 / 99999 | Training loss: 31.42258 |  Training Accuracy: 4.82471 | Training Metric (MAE): 4.82471\n",
      "Validation Stage ==> Epoch: 250 / 99999 | Validation loss: 31.91046 |  Validation Accuracy: 4.82719 | Validation Metric (MAE)): 4.82719\n",
      "Load Model from best epoch 250\n",
      "Training Stage ==> Epoch: 251 / 99999 | Training loss: 31.49967 |  Training Accuracy: 4.80249 | Training Metric (MAE): 4.80249\n",
      "Validation Stage ==> Epoch: 251 / 99999 | Validation loss: 31.90710 |  Validation Accuracy: 4.82684 | Validation Metric (MAE)): 4.82684\n",
      "Load Model from best epoch 251\n",
      "Training Stage ==> Epoch: 252 / 99999 | Training loss: 31.19821 |  Training Accuracy: 4.79775 | Training Metric (MAE): 4.79775\n",
      "Validation Stage ==> Epoch: 252 / 99999 | Validation loss: 31.90374 |  Validation Accuracy: 4.82650 | Validation Metric (MAE)): 4.82650\n",
      "Load Model from best epoch 252\n",
      "Training Stage ==> Epoch: 253 / 99999 | Training loss: 31.98871 |  Training Accuracy: 4.82077 | Training Metric (MAE): 4.82077\n",
      "Validation Stage ==> Epoch: 253 / 99999 | Validation loss: 31.90038 |  Validation Accuracy: 4.82615 | Validation Metric (MAE)): 4.82615\n",
      "Load Model from best epoch 253\n",
      "Training Stage ==> Epoch: 254 / 99999 | Training loss: 31.50452 |  Training Accuracy: 4.80122 | Training Metric (MAE): 4.80122\n",
      "Validation Stage ==> Epoch: 254 / 99999 | Validation loss: 31.89701 |  Validation Accuracy: 4.82580 | Validation Metric (MAE)): 4.82580\n",
      "Load Model from best epoch 254\n",
      "Training Stage ==> Epoch: 255 / 99999 | Training loss: 31.38298 |  Training Accuracy: 4.81025 | Training Metric (MAE): 4.81025\n",
      "Validation Stage ==> Epoch: 255 / 99999 | Validation loss: 31.89366 |  Validation Accuracy: 4.82546 | Validation Metric (MAE)): 4.82546\n",
      "Load Model from best epoch 255\n",
      "Training Stage ==> Epoch: 256 / 99999 | Training loss: 30.18533 |  Training Accuracy: 4.80478 | Training Metric (MAE): 4.80478\n",
      "Validation Stage ==> Epoch: 256 / 99999 | Validation loss: 31.89030 |  Validation Accuracy: 4.82511 | Validation Metric (MAE)): 4.82511\n",
      "Load Model from best epoch 256\n",
      "Training Stage ==> Epoch: 257 / 99999 | Training loss: 30.30358 |  Training Accuracy: 4.80672 | Training Metric (MAE): 4.80672\n",
      "Validation Stage ==> Epoch: 257 / 99999 | Validation loss: 31.88693 |  Validation Accuracy: 4.82477 | Validation Metric (MAE)): 4.82477\n",
      "Load Model from best epoch 257\n",
      "Training Stage ==> Epoch: 258 / 99999 | Training loss: 31.26928 |  Training Accuracy: 4.80507 | Training Metric (MAE): 4.80507\n",
      "Validation Stage ==> Epoch: 258 / 99999 | Validation loss: 31.88357 |  Validation Accuracy: 4.82442 | Validation Metric (MAE)): 4.82442\n",
      "Load Model from best epoch 258\n",
      "Training Stage ==> Epoch: 259 / 99999 | Training loss: 31.42252 |  Training Accuracy: 4.80236 | Training Metric (MAE): 4.80236\n",
      "Validation Stage ==> Epoch: 259 / 99999 | Validation loss: 31.88021 |  Validation Accuracy: 4.82407 | Validation Metric (MAE)): 4.82407\n",
      "Load Model from best epoch 259\n",
      "Training Stage ==> Epoch: 260 / 99999 | Training loss: 32.66420 |  Training Accuracy: 4.80178 | Training Metric (MAE): 4.80178\n",
      "Validation Stage ==> Epoch: 260 / 99999 | Validation loss: 31.87686 |  Validation Accuracy: 4.82373 | Validation Metric (MAE)): 4.82373\n",
      "Load Model from best epoch 260\n",
      "Training Stage ==> Epoch: 261 / 99999 | Training loss: 31.50928 |  Training Accuracy: 4.80594 | Training Metric (MAE): 4.80594\n",
      "Validation Stage ==> Epoch: 261 / 99999 | Validation loss: 31.87350 |  Validation Accuracy: 4.82338 | Validation Metric (MAE)): 4.82338\n",
      "Load Model from best epoch 261\n",
      "Training Stage ==> Epoch: 262 / 99999 | Training loss: 32.09836 |  Training Accuracy: 4.79878 | Training Metric (MAE): 4.79878\n",
      "Validation Stage ==> Epoch: 262 / 99999 | Validation loss: 31.87013 |  Validation Accuracy: 4.82303 | Validation Metric (MAE)): 4.82303\n",
      "Load Model from best epoch 262\n",
      "Training Stage ==> Epoch: 263 / 99999 | Training loss: 32.78825 |  Training Accuracy: 4.81421 | Training Metric (MAE): 4.81421\n",
      "Validation Stage ==> Epoch: 263 / 99999 | Validation loss: 31.86677 |  Validation Accuracy: 4.82269 | Validation Metric (MAE)): 4.82269\n",
      "Load Model from best epoch 263\n",
      "Training Stage ==> Epoch: 264 / 99999 | Training loss: 30.04167 |  Training Accuracy: 4.79648 | Training Metric (MAE): 4.79648\n",
      "Validation Stage ==> Epoch: 264 / 99999 | Validation loss: 31.86342 |  Validation Accuracy: 4.82234 | Validation Metric (MAE)): 4.82234\n",
      "Load Model from best epoch 264\n",
      "Training Stage ==> Epoch: 265 / 99999 | Training loss: 31.53410 |  Training Accuracy: 4.79198 | Training Metric (MAE): 4.79198\n",
      "Validation Stage ==> Epoch: 265 / 99999 | Validation loss: 31.86006 |  Validation Accuracy: 4.82200 | Validation Metric (MAE)): 4.82200\n",
      "Load Model from best epoch 265\n",
      "Training Stage ==> Epoch: 266 / 99999 | Training loss: 30.77793 |  Training Accuracy: 4.79970 | Training Metric (MAE): 4.79970\n",
      "Validation Stage ==> Epoch: 266 / 99999 | Validation loss: 31.85671 |  Validation Accuracy: 4.82165 | Validation Metric (MAE)): 4.82165\n",
      "Load Model from best epoch 266\n",
      "Training Stage ==> Epoch: 267 / 99999 | Training loss: 30.60324 |  Training Accuracy: 4.80643 | Training Metric (MAE): 4.80643\n",
      "Validation Stage ==> Epoch: 267 / 99999 | Validation loss: 31.85336 |  Validation Accuracy: 4.82131 | Validation Metric (MAE)): 4.82131\n",
      "Load Model from best epoch 267\n",
      "Training Stage ==> Epoch: 268 / 99999 | Training loss: 29.70675 |  Training Accuracy: 4.79935 | Training Metric (MAE): 4.79935\n",
      "Validation Stage ==> Epoch: 268 / 99999 | Validation loss: 31.85001 |  Validation Accuracy: 4.82096 | Validation Metric (MAE)): 4.82096\n",
      "Load Model from best epoch 268\n",
      "Training Stage ==> Epoch: 269 / 99999 | Training loss: 32.21489 |  Training Accuracy: 4.79069 | Training Metric (MAE): 4.79069\n",
      "Validation Stage ==> Epoch: 269 / 99999 | Validation loss: 31.84666 |  Validation Accuracy: 4.82062 | Validation Metric (MAE)): 4.82062\n",
      "Load Model from best epoch 269\n",
      "Training Stage ==> Epoch: 270 / 99999 | Training loss: 30.32437 |  Training Accuracy: 4.79577 | Training Metric (MAE): 4.79577\n",
      "Validation Stage ==> Epoch: 270 / 99999 | Validation loss: 31.84330 |  Validation Accuracy: 4.82027 | Validation Metric (MAE)): 4.82027\n",
      "Load Model from best epoch 270\n",
      "Training Stage ==> Epoch: 271 / 99999 | Training loss: 31.21458 |  Training Accuracy: 4.80687 | Training Metric (MAE): 4.80687\n",
      "Validation Stage ==> Epoch: 271 / 99999 | Validation loss: 31.83995 |  Validation Accuracy: 4.81992 | Validation Metric (MAE)): 4.81992\n",
      "Load Model from best epoch 271\n",
      "Training Stage ==> Epoch: 272 / 99999 | Training loss: 29.96257 |  Training Accuracy: 4.79265 | Training Metric (MAE): 4.79265\n",
      "Validation Stage ==> Epoch: 272 / 99999 | Validation loss: 31.83660 |  Validation Accuracy: 4.81958 | Validation Metric (MAE)): 4.81958\n",
      "Load Model from best epoch 272\n",
      "Training Stage ==> Epoch: 273 / 99999 | Training loss: 31.73295 |  Training Accuracy: 4.79716 | Training Metric (MAE): 4.79716\n",
      "Validation Stage ==> Epoch: 273 / 99999 | Validation loss: 31.83325 |  Validation Accuracy: 4.81923 | Validation Metric (MAE)): 4.81923\n",
      "Load Model from best epoch 273\n",
      "Training Stage ==> Epoch: 274 / 99999 | Training loss: 31.95013 |  Training Accuracy: 4.80584 | Training Metric (MAE): 4.80584\n",
      "Validation Stage ==> Epoch: 274 / 99999 | Validation loss: 31.82990 |  Validation Accuracy: 4.81889 | Validation Metric (MAE)): 4.81889\n",
      "Load Model from best epoch 274\n",
      "Training Stage ==> Epoch: 275 / 99999 | Training loss: 33.01675 |  Training Accuracy: 4.79504 | Training Metric (MAE): 4.79504\n",
      "Validation Stage ==> Epoch: 275 / 99999 | Validation loss: 31.82655 |  Validation Accuracy: 4.81854 | Validation Metric (MAE)): 4.81854\n",
      "Load Model from best epoch 275\n",
      "Training Stage ==> Epoch: 276 / 99999 | Training loss: 30.84243 |  Training Accuracy: 4.80837 | Training Metric (MAE): 4.80837\n",
      "Validation Stage ==> Epoch: 276 / 99999 | Validation loss: 31.82320 |  Validation Accuracy: 4.81820 | Validation Metric (MAE)): 4.81820\n",
      "Load Model from best epoch 276\n",
      "Training Stage ==> Epoch: 277 / 99999 | Training loss: 29.67610 |  Training Accuracy: 4.78745 | Training Metric (MAE): 4.78745\n",
      "Validation Stage ==> Epoch: 277 / 99999 | Validation loss: 31.81985 |  Validation Accuracy: 4.81785 | Validation Metric (MAE)): 4.81785\n",
      "Load Model from best epoch 277\n",
      "Training Stage ==> Epoch: 278 / 99999 | Training loss: 30.48136 |  Training Accuracy: 4.79775 | Training Metric (MAE): 4.79775\n",
      "Validation Stage ==> Epoch: 278 / 99999 | Validation loss: 31.81651 |  Validation Accuracy: 4.81751 | Validation Metric (MAE)): 4.81751\n",
      "Load Model from best epoch 278\n",
      "Training Stage ==> Epoch: 279 / 99999 | Training loss: 29.45415 |  Training Accuracy: 4.80355 | Training Metric (MAE): 4.80355\n",
      "Validation Stage ==> Epoch: 279 / 99999 | Validation loss: 31.81317 |  Validation Accuracy: 4.81716 | Validation Metric (MAE)): 4.81716\n",
      "Load Model from best epoch 279\n",
      "Training Stage ==> Epoch: 280 / 99999 | Training loss: 31.00403 |  Training Accuracy: 4.78809 | Training Metric (MAE): 4.78809\n",
      "Validation Stage ==> Epoch: 280 / 99999 | Validation loss: 31.80984 |  Validation Accuracy: 4.81682 | Validation Metric (MAE)): 4.81682\n",
      "Load Model from best epoch 280\n",
      "Training Stage ==> Epoch: 281 / 99999 | Training loss: 32.13326 |  Training Accuracy: 4.78810 | Training Metric (MAE): 4.78810\n",
      "Validation Stage ==> Epoch: 281 / 99999 | Validation loss: 31.80650 |  Validation Accuracy: 4.81647 | Validation Metric (MAE)): 4.81647\n",
      "Load Model from best epoch 281\n",
      "Training Stage ==> Epoch: 282 / 99999 | Training loss: 31.07048 |  Training Accuracy: 4.79597 | Training Metric (MAE): 4.79597\n",
      "Validation Stage ==> Epoch: 282 / 99999 | Validation loss: 31.80316 |  Validation Accuracy: 4.81613 | Validation Metric (MAE)): 4.81613\n",
      "Load Model from best epoch 282\n",
      "Training Stage ==> Epoch: 283 / 99999 | Training loss: 30.89757 |  Training Accuracy: 4.81475 | Training Metric (MAE): 4.81475\n",
      "Validation Stage ==> Epoch: 283 / 99999 | Validation loss: 31.79981 |  Validation Accuracy: 4.81578 | Validation Metric (MAE)): 4.81578\n",
      "Load Model from best epoch 283\n",
      "Training Stage ==> Epoch: 284 / 99999 | Training loss: 29.59994 |  Training Accuracy: 4.78881 | Training Metric (MAE): 4.78881\n",
      "Validation Stage ==> Epoch: 284 / 99999 | Validation loss: 31.79648 |  Validation Accuracy: 4.81544 | Validation Metric (MAE)): 4.81544\n",
      "Load Model from best epoch 284\n",
      "Training Stage ==> Epoch: 285 / 99999 | Training loss: 31.08603 |  Training Accuracy: 4.80304 | Training Metric (MAE): 4.80304\n",
      "Validation Stage ==> Epoch: 285 / 99999 | Validation loss: 31.79314 |  Validation Accuracy: 4.81510 | Validation Metric (MAE)): 4.81510\n",
      "Load Model from best epoch 285\n",
      "Training Stage ==> Epoch: 286 / 99999 | Training loss: 29.14803 |  Training Accuracy: 4.78464 | Training Metric (MAE): 4.78464\n",
      "Validation Stage ==> Epoch: 286 / 99999 | Validation loss: 31.78981 |  Validation Accuracy: 4.81475 | Validation Metric (MAE)): 4.81475\n",
      "Load Model from best epoch 286\n",
      "Training Stage ==> Epoch: 287 / 99999 | Training loss: 30.59924 |  Training Accuracy: 4.79561 | Training Metric (MAE): 4.79561\n",
      "Validation Stage ==> Epoch: 287 / 99999 | Validation loss: 31.78648 |  Validation Accuracy: 4.81441 | Validation Metric (MAE)): 4.81441\n",
      "Load Model from best epoch 287\n",
      "Training Stage ==> Epoch: 288 / 99999 | Training loss: 32.36835 |  Training Accuracy: 4.78970 | Training Metric (MAE): 4.78970\n",
      "Validation Stage ==> Epoch: 288 / 99999 | Validation loss: 31.78314 |  Validation Accuracy: 4.81406 | Validation Metric (MAE)): 4.81406\n",
      "Load Model from best epoch 288\n",
      "Training Stage ==> Epoch: 289 / 99999 | Training loss: 30.94925 |  Training Accuracy: 4.78722 | Training Metric (MAE): 4.78722\n",
      "Validation Stage ==> Epoch: 289 / 99999 | Validation loss: 31.77980 |  Validation Accuracy: 4.81372 | Validation Metric (MAE)): 4.81372\n",
      "Load Model from best epoch 289\n",
      "Training Stage ==> Epoch: 290 / 99999 | Training loss: 31.30301 |  Training Accuracy: 4.79783 | Training Metric (MAE): 4.79783\n",
      "Validation Stage ==> Epoch: 290 / 99999 | Validation loss: 31.77647 |  Validation Accuracy: 4.81338 | Validation Metric (MAE)): 4.81338\n",
      "Load Model from best epoch 290\n",
      "Training Stage ==> Epoch: 291 / 99999 | Training loss: 31.68730 |  Training Accuracy: 4.79583 | Training Metric (MAE): 4.79583\n",
      "Validation Stage ==> Epoch: 291 / 99999 | Validation loss: 31.77314 |  Validation Accuracy: 4.81303 | Validation Metric (MAE)): 4.81303\n",
      "Load Model from best epoch 291\n",
      "Training Stage ==> Epoch: 292 / 99999 | Training loss: 30.61541 |  Training Accuracy: 4.77443 | Training Metric (MAE): 4.77443\n",
      "Validation Stage ==> Epoch: 292 / 99999 | Validation loss: 31.76981 |  Validation Accuracy: 4.81269 | Validation Metric (MAE)): 4.81269\n",
      "Load Model from best epoch 292\n",
      "Training Stage ==> Epoch: 293 / 99999 | Training loss: 32.12493 |  Training Accuracy: 4.78663 | Training Metric (MAE): 4.78663\n",
      "Validation Stage ==> Epoch: 293 / 99999 | Validation loss: 31.76648 |  Validation Accuracy: 4.81235 | Validation Metric (MAE)): 4.81235\n",
      "Load Model from best epoch 293\n",
      "Training Stage ==> Epoch: 294 / 99999 | Training loss: 30.34694 |  Training Accuracy: 4.79280 | Training Metric (MAE): 4.79280\n",
      "Validation Stage ==> Epoch: 294 / 99999 | Validation loss: 31.76315 |  Validation Accuracy: 4.81200 | Validation Metric (MAE)): 4.81200\n",
      "Load Model from best epoch 294\n",
      "Training Stage ==> Epoch: 295 / 99999 | Training loss: 31.58979 |  Training Accuracy: 4.77198 | Training Metric (MAE): 4.77198\n",
      "Validation Stage ==> Epoch: 295 / 99999 | Validation loss: 31.75981 |  Validation Accuracy: 4.81166 | Validation Metric (MAE)): 4.81166\n",
      "Load Model from best epoch 295\n",
      "Training Stage ==> Epoch: 296 / 99999 | Training loss: 30.78296 |  Training Accuracy: 4.78506 | Training Metric (MAE): 4.78506\n",
      "Validation Stage ==> Epoch: 296 / 99999 | Validation loss: 31.75647 |  Validation Accuracy: 4.81131 | Validation Metric (MAE)): 4.81131\n",
      "Load Model from best epoch 296\n",
      "Training Stage ==> Epoch: 297 / 99999 | Training loss: 30.52494 |  Training Accuracy: 4.78989 | Training Metric (MAE): 4.78989\n",
      "Validation Stage ==> Epoch: 297 / 99999 | Validation loss: 31.75315 |  Validation Accuracy: 4.81097 | Validation Metric (MAE)): 4.81097\n",
      "Load Model from best epoch 297\n",
      "Training Stage ==> Epoch: 298 / 99999 | Training loss: 30.65868 |  Training Accuracy: 4.79426 | Training Metric (MAE): 4.79426\n",
      "Validation Stage ==> Epoch: 298 / 99999 | Validation loss: 31.74983 |  Validation Accuracy: 4.81063 | Validation Metric (MAE)): 4.81063\n",
      "Load Model from best epoch 298\n",
      "Training Stage ==> Epoch: 299 / 99999 | Training loss: 30.22246 |  Training Accuracy: 4.80198 | Training Metric (MAE): 4.80198\n",
      "Validation Stage ==> Epoch: 299 / 99999 | Validation loss: 31.74650 |  Validation Accuracy: 4.81028 | Validation Metric (MAE)): 4.81028\n",
      "Load Model from best epoch 299\n",
      "Training Stage ==> Epoch: 300 / 99999 | Training loss: 31.00369 |  Training Accuracy: 4.79155 | Training Metric (MAE): 4.79155\n",
      "Validation Stage ==> Epoch: 300 / 99999 | Validation loss: 31.74317 |  Validation Accuracy: 4.80994 | Validation Metric (MAE)): 4.80994\n",
      "Load Model from best epoch 300\n",
      "Training Stage ==> Epoch: 301 / 99999 | Training loss: 30.58513 |  Training Accuracy: 4.77614 | Training Metric (MAE): 4.77614\n",
      "Validation Stage ==> Epoch: 301 / 99999 | Validation loss: 31.73985 |  Validation Accuracy: 4.80959 | Validation Metric (MAE)): 4.80959\n",
      "Load Model from best epoch 301\n",
      "Training Stage ==> Epoch: 302 / 99999 | Training loss: 32.27075 |  Training Accuracy: 4.79504 | Training Metric (MAE): 4.79504\n",
      "Validation Stage ==> Epoch: 302 / 99999 | Validation loss: 31.73651 |  Validation Accuracy: 4.80925 | Validation Metric (MAE)): 4.80925\n",
      "Load Model from best epoch 302\n",
      "Training Stage ==> Epoch: 303 / 99999 | Training loss: 32.11535 |  Training Accuracy: 4.77947 | Training Metric (MAE): 4.77947\n",
      "Validation Stage ==> Epoch: 303 / 99999 | Validation loss: 31.73318 |  Validation Accuracy: 4.80891 | Validation Metric (MAE)): 4.80891\n",
      "Load Model from best epoch 303\n",
      "Training Stage ==> Epoch: 304 / 99999 | Training loss: 31.86902 |  Training Accuracy: 4.77893 | Training Metric (MAE): 4.77893\n",
      "Validation Stage ==> Epoch: 304 / 99999 | Validation loss: 31.72986 |  Validation Accuracy: 4.80856 | Validation Metric (MAE)): 4.80856\n",
      "Load Model from best epoch 304\n",
      "Training Stage ==> Epoch: 305 / 99999 | Training loss: 31.57976 |  Training Accuracy: 4.78485 | Training Metric (MAE): 4.78485\n",
      "Validation Stage ==> Epoch: 305 / 99999 | Validation loss: 31.72653 |  Validation Accuracy: 4.80822 | Validation Metric (MAE)): 4.80822\n",
      "Load Model from best epoch 305\n",
      "Training Stage ==> Epoch: 306 / 99999 | Training loss: 32.04592 |  Training Accuracy: 4.79042 | Training Metric (MAE): 4.79042\n",
      "Validation Stage ==> Epoch: 306 / 99999 | Validation loss: 31.72321 |  Validation Accuracy: 4.80788 | Validation Metric (MAE)): 4.80788\n",
      "Load Model from best epoch 306\n",
      "Training Stage ==> Epoch: 307 / 99999 | Training loss: 29.57512 |  Training Accuracy: 4.78993 | Training Metric (MAE): 4.78993\n",
      "Validation Stage ==> Epoch: 307 / 99999 | Validation loss: 31.71988 |  Validation Accuracy: 4.80753 | Validation Metric (MAE)): 4.80753\n",
      "Load Model from best epoch 307\n",
      "Training Stage ==> Epoch: 308 / 99999 | Training loss: 31.64689 |  Training Accuracy: 4.77203 | Training Metric (MAE): 4.77203\n",
      "Validation Stage ==> Epoch: 308 / 99999 | Validation loss: 31.71655 |  Validation Accuracy: 4.80719 | Validation Metric (MAE)): 4.80719\n",
      "Load Model from best epoch 308\n",
      "Training Stage ==> Epoch: 309 / 99999 | Training loss: 31.68678 |  Training Accuracy: 4.79206 | Training Metric (MAE): 4.79206\n",
      "Validation Stage ==> Epoch: 309 / 99999 | Validation loss: 31.71322 |  Validation Accuracy: 4.80684 | Validation Metric (MAE)): 4.80684\n",
      "Load Model from best epoch 309\n",
      "Training Stage ==> Epoch: 310 / 99999 | Training loss: 30.83175 |  Training Accuracy: 4.78159 | Training Metric (MAE): 4.78159\n",
      "Validation Stage ==> Epoch: 310 / 99999 | Validation loss: 31.70990 |  Validation Accuracy: 4.80650 | Validation Metric (MAE)): 4.80650\n",
      "Load Model from best epoch 310\n",
      "Training Stage ==> Epoch: 311 / 99999 | Training loss: 32.85696 |  Training Accuracy: 4.78334 | Training Metric (MAE): 4.78334\n",
      "Validation Stage ==> Epoch: 311 / 99999 | Validation loss: 31.70659 |  Validation Accuracy: 4.80616 | Validation Metric (MAE)): 4.80616\n",
      "Load Model from best epoch 311\n",
      "Training Stage ==> Epoch: 312 / 99999 | Training loss: 30.88515 |  Training Accuracy: 4.78565 | Training Metric (MAE): 4.78565\n",
      "Validation Stage ==> Epoch: 312 / 99999 | Validation loss: 31.70327 |  Validation Accuracy: 4.80581 | Validation Metric (MAE)): 4.80581\n",
      "Load Model from best epoch 312\n",
      "Training Stage ==> Epoch: 313 / 99999 | Training loss: 32.01387 |  Training Accuracy: 4.79223 | Training Metric (MAE): 4.79223\n",
      "Validation Stage ==> Epoch: 313 / 99999 | Validation loss: 31.69996 |  Validation Accuracy: 4.80547 | Validation Metric (MAE)): 4.80547\n",
      "Load Model from best epoch 313\n",
      "Training Stage ==> Epoch: 314 / 99999 | Training loss: 31.57190 |  Training Accuracy: 4.78364 | Training Metric (MAE): 4.78364\n",
      "Validation Stage ==> Epoch: 314 / 99999 | Validation loss: 31.69663 |  Validation Accuracy: 4.80513 | Validation Metric (MAE)): 4.80513\n",
      "Load Model from best epoch 314\n",
      "Training Stage ==> Epoch: 315 / 99999 | Training loss: 31.85913 |  Training Accuracy: 4.78917 | Training Metric (MAE): 4.78917\n",
      "Validation Stage ==> Epoch: 315 / 99999 | Validation loss: 31.69332 |  Validation Accuracy: 4.80479 | Validation Metric (MAE)): 4.80479\n",
      "Load Model from best epoch 315\n",
      "Training Stage ==> Epoch: 316 / 99999 | Training loss: 30.26191 |  Training Accuracy: 4.77449 | Training Metric (MAE): 4.77449\n",
      "Validation Stage ==> Epoch: 316 / 99999 | Validation loss: 31.69000 |  Validation Accuracy: 4.80444 | Validation Metric (MAE)): 4.80444\n",
      "Load Model from best epoch 316\n",
      "Training Stage ==> Epoch: 317 / 99999 | Training loss: 31.54670 |  Training Accuracy: 4.78144 | Training Metric (MAE): 4.78144\n",
      "Validation Stage ==> Epoch: 317 / 99999 | Validation loss: 31.68669 |  Validation Accuracy: 4.80410 | Validation Metric (MAE)): 4.80410\n",
      "Load Model from best epoch 317\n",
      "Training Stage ==> Epoch: 318 / 99999 | Training loss: 29.53019 |  Training Accuracy: 4.78103 | Training Metric (MAE): 4.78103\n",
      "Validation Stage ==> Epoch: 318 / 99999 | Validation loss: 31.68337 |  Validation Accuracy: 4.80376 | Validation Metric (MAE)): 4.80376\n",
      "Load Model from best epoch 318\n",
      "Training Stage ==> Epoch: 319 / 99999 | Training loss: 31.83001 |  Training Accuracy: 4.79432 | Training Metric (MAE): 4.79432\n",
      "Validation Stage ==> Epoch: 319 / 99999 | Validation loss: 31.68004 |  Validation Accuracy: 4.80341 | Validation Metric (MAE)): 4.80341\n",
      "Load Model from best epoch 319\n",
      "Training Stage ==> Epoch: 320 / 99999 | Training loss: 32.88510 |  Training Accuracy: 4.79269 | Training Metric (MAE): 4.79269\n",
      "Validation Stage ==> Epoch: 320 / 99999 | Validation loss: 31.67673 |  Validation Accuracy: 4.80307 | Validation Metric (MAE)): 4.80307\n",
      "Load Model from best epoch 320\n",
      "Training Stage ==> Epoch: 321 / 99999 | Training loss: 29.97540 |  Training Accuracy: 4.77838 | Training Metric (MAE): 4.77838\n",
      "Validation Stage ==> Epoch: 321 / 99999 | Validation loss: 31.67341 |  Validation Accuracy: 4.80273 | Validation Metric (MAE)): 4.80273\n",
      "Load Model from best epoch 321\n",
      "Training Stage ==> Epoch: 322 / 99999 | Training loss: 30.68869 |  Training Accuracy: 4.76991 | Training Metric (MAE): 4.76991\n",
      "Validation Stage ==> Epoch: 322 / 99999 | Validation loss: 31.67010 |  Validation Accuracy: 4.80238 | Validation Metric (MAE)): 4.80238\n",
      "Load Model from best epoch 322\n",
      "Training Stage ==> Epoch: 323 / 99999 | Training loss: 30.97971 |  Training Accuracy: 4.77621 | Training Metric (MAE): 4.77621\n",
      "Validation Stage ==> Epoch: 323 / 99999 | Validation loss: 31.66680 |  Validation Accuracy: 4.80204 | Validation Metric (MAE)): 4.80204\n",
      "Load Model from best epoch 323\n",
      "Training Stage ==> Epoch: 324 / 99999 | Training loss: 30.59778 |  Training Accuracy: 4.77579 | Training Metric (MAE): 4.77579\n",
      "Validation Stage ==> Epoch: 324 / 99999 | Validation loss: 31.66348 |  Validation Accuracy: 4.80170 | Validation Metric (MAE)): 4.80170\n",
      "Load Model from best epoch 324\n",
      "Training Stage ==> Epoch: 325 / 99999 | Training loss: 30.89840 |  Training Accuracy: 4.77606 | Training Metric (MAE): 4.77606\n",
      "Validation Stage ==> Epoch: 325 / 99999 | Validation loss: 31.66018 |  Validation Accuracy: 4.80136 | Validation Metric (MAE)): 4.80136\n",
      "Load Model from best epoch 325\n",
      "Training Stage ==> Epoch: 326 / 99999 | Training loss: 29.67507 |  Training Accuracy: 4.78398 | Training Metric (MAE): 4.78398\n",
      "Validation Stage ==> Epoch: 326 / 99999 | Validation loss: 31.65686 |  Validation Accuracy: 4.80102 | Validation Metric (MAE)): 4.80102\n",
      "Load Model from best epoch 326\n",
      "Training Stage ==> Epoch: 327 / 99999 | Training loss: 31.52959 |  Training Accuracy: 4.78136 | Training Metric (MAE): 4.78136\n",
      "Validation Stage ==> Epoch: 327 / 99999 | Validation loss: 31.65356 |  Validation Accuracy: 4.80067 | Validation Metric (MAE)): 4.80067\n",
      "Load Model from best epoch 327\n",
      "Training Stage ==> Epoch: 328 / 99999 | Training loss: 31.83938 |  Training Accuracy: 4.78743 | Training Metric (MAE): 4.78743\n",
      "Validation Stage ==> Epoch: 328 / 99999 | Validation loss: 31.65025 |  Validation Accuracy: 4.80033 | Validation Metric (MAE)): 4.80033\n",
      "Load Model from best epoch 328\n",
      "Training Stage ==> Epoch: 329 / 99999 | Training loss: 30.64392 |  Training Accuracy: 4.78220 | Training Metric (MAE): 4.78220\n",
      "Validation Stage ==> Epoch: 329 / 99999 | Validation loss: 31.64694 |  Validation Accuracy: 4.79999 | Validation Metric (MAE)): 4.79999\n",
      "Load Model from best epoch 329\n",
      "Training Stage ==> Epoch: 330 / 99999 | Training loss: 30.58364 |  Training Accuracy: 4.78961 | Training Metric (MAE): 4.78961\n",
      "Validation Stage ==> Epoch: 330 / 99999 | Validation loss: 31.64364 |  Validation Accuracy: 4.79965 | Validation Metric (MAE)): 4.79965\n",
      "Load Model from best epoch 330\n",
      "Training Stage ==> Epoch: 331 / 99999 | Training loss: 30.04036 |  Training Accuracy: 4.77713 | Training Metric (MAE): 4.77713\n",
      "Validation Stage ==> Epoch: 331 / 99999 | Validation loss: 31.64033 |  Validation Accuracy: 4.79930 | Validation Metric (MAE)): 4.79930\n",
      "Load Model from best epoch 331\n",
      "Training Stage ==> Epoch: 332 / 99999 | Training loss: 29.13666 |  Training Accuracy: 4.77579 | Training Metric (MAE): 4.77579\n",
      "Validation Stage ==> Epoch: 332 / 99999 | Validation loss: 31.63703 |  Validation Accuracy: 4.79896 | Validation Metric (MAE)): 4.79896\n",
      "Load Model from best epoch 332\n",
      "Training Stage ==> Epoch: 333 / 99999 | Training loss: 30.45486 |  Training Accuracy: 4.76561 | Training Metric (MAE): 4.76561\n",
      "Validation Stage ==> Epoch: 333 / 99999 | Validation loss: 31.63373 |  Validation Accuracy: 4.79862 | Validation Metric (MAE)): 4.79862\n",
      "Load Model from best epoch 333\n",
      "Training Stage ==> Epoch: 334 / 99999 | Training loss: 30.32428 |  Training Accuracy: 4.77948 | Training Metric (MAE): 4.77948\n",
      "Validation Stage ==> Epoch: 334 / 99999 | Validation loss: 31.63043 |  Validation Accuracy: 4.79828 | Validation Metric (MAE)): 4.79828\n",
      "Load Model from best epoch 334\n",
      "Training Stage ==> Epoch: 335 / 99999 | Training loss: 30.93598 |  Training Accuracy: 4.76737 | Training Metric (MAE): 4.76737\n",
      "Validation Stage ==> Epoch: 335 / 99999 | Validation loss: 31.62713 |  Validation Accuracy: 4.79794 | Validation Metric (MAE)): 4.79794\n",
      "Load Model from best epoch 335\n",
      "Training Stage ==> Epoch: 336 / 99999 | Training loss: 30.53226 |  Training Accuracy: 4.79083 | Training Metric (MAE): 4.79083\n",
      "Validation Stage ==> Epoch: 336 / 99999 | Validation loss: 31.62383 |  Validation Accuracy: 4.79759 | Validation Metric (MAE)): 4.79759\n",
      "Load Model from best epoch 336\n",
      "Training Stage ==> Epoch: 337 / 99999 | Training loss: 32.12532 |  Training Accuracy: 4.77381 | Training Metric (MAE): 4.77381\n",
      "Validation Stage ==> Epoch: 337 / 99999 | Validation loss: 31.62053 |  Validation Accuracy: 4.79725 | Validation Metric (MAE)): 4.79725\n",
      "Load Model from best epoch 337\n",
      "Training Stage ==> Epoch: 338 / 99999 | Training loss: 30.12205 |  Training Accuracy: 4.77217 | Training Metric (MAE): 4.77217\n",
      "Validation Stage ==> Epoch: 338 / 99999 | Validation loss: 31.61722 |  Validation Accuracy: 4.79691 | Validation Metric (MAE)): 4.79691\n",
      "Load Model from best epoch 338\n",
      "Training Stage ==> Epoch: 339 / 99999 | Training loss: 30.10992 |  Training Accuracy: 4.77455 | Training Metric (MAE): 4.77455\n",
      "Validation Stage ==> Epoch: 339 / 99999 | Validation loss: 31.61393 |  Validation Accuracy: 4.79657 | Validation Metric (MAE)): 4.79657\n",
      "Load Model from best epoch 339\n",
      "Training Stage ==> Epoch: 340 / 99999 | Training loss: 31.71515 |  Training Accuracy: 4.78280 | Training Metric (MAE): 4.78280\n",
      "Validation Stage ==> Epoch: 340 / 99999 | Validation loss: 31.61063 |  Validation Accuracy: 4.79623 | Validation Metric (MAE)): 4.79623\n",
      "Load Model from best epoch 340\n",
      "Training Stage ==> Epoch: 341 / 99999 | Training loss: 31.55486 |  Training Accuracy: 4.77121 | Training Metric (MAE): 4.77121\n",
      "Validation Stage ==> Epoch: 341 / 99999 | Validation loss: 31.60734 |  Validation Accuracy: 4.79589 | Validation Metric (MAE)): 4.79589\n",
      "Load Model from best epoch 341\n",
      "Training Stage ==> Epoch: 342 / 99999 | Training loss: 30.29443 |  Training Accuracy: 4.78198 | Training Metric (MAE): 4.78198\n",
      "Validation Stage ==> Epoch: 342 / 99999 | Validation loss: 31.60404 |  Validation Accuracy: 4.79555 | Validation Metric (MAE)): 4.79555\n",
      "Load Model from best epoch 342\n",
      "Training Stage ==> Epoch: 343 / 99999 | Training loss: 31.45268 |  Training Accuracy: 4.78062 | Training Metric (MAE): 4.78062\n",
      "Validation Stage ==> Epoch: 343 / 99999 | Validation loss: 31.60075 |  Validation Accuracy: 4.79520 | Validation Metric (MAE)): 4.79520\n",
      "Load Model from best epoch 343\n",
      "Training Stage ==> Epoch: 344 / 99999 | Training loss: 29.26851 |  Training Accuracy: 4.77204 | Training Metric (MAE): 4.77204\n",
      "Validation Stage ==> Epoch: 344 / 99999 | Validation loss: 31.59746 |  Validation Accuracy: 4.79486 | Validation Metric (MAE)): 4.79486\n",
      "Load Model from best epoch 344\n",
      "Training Stage ==> Epoch: 345 / 99999 | Training loss: 31.97693 |  Training Accuracy: 4.77307 | Training Metric (MAE): 4.77307\n",
      "Validation Stage ==> Epoch: 345 / 99999 | Validation loss: 31.59416 |  Validation Accuracy: 4.79452 | Validation Metric (MAE)): 4.79452\n",
      "Load Model from best epoch 345\n",
      "Training Stage ==> Epoch: 346 / 99999 | Training loss: 32.55672 |  Training Accuracy: 4.77531 | Training Metric (MAE): 4.77531\n",
      "Validation Stage ==> Epoch: 346 / 99999 | Validation loss: 31.59086 |  Validation Accuracy: 4.79418 | Validation Metric (MAE)): 4.79418\n",
      "Load Model from best epoch 346\n",
      "Training Stage ==> Epoch: 347 / 99999 | Training loss: 28.17870 |  Training Accuracy: 4.77116 | Training Metric (MAE): 4.77116\n",
      "Validation Stage ==> Epoch: 347 / 99999 | Validation loss: 31.58758 |  Validation Accuracy: 4.79384 | Validation Metric (MAE)): 4.79384\n",
      "Load Model from best epoch 347\n",
      "Training Stage ==> Epoch: 348 / 99999 | Training loss: 29.96933 |  Training Accuracy: 4.76870 | Training Metric (MAE): 4.76870\n",
      "Validation Stage ==> Epoch: 348 / 99999 | Validation loss: 31.58429 |  Validation Accuracy: 4.79350 | Validation Metric (MAE)): 4.79350\n",
      "Load Model from best epoch 348\n",
      "Training Stage ==> Epoch: 349 / 99999 | Training loss: 32.97953 |  Training Accuracy: 4.76081 | Training Metric (MAE): 4.76081\n",
      "Validation Stage ==> Epoch: 349 / 99999 | Validation loss: 31.58099 |  Validation Accuracy: 4.79316 | Validation Metric (MAE)): 4.79316\n",
      "Load Model from best epoch 349\n",
      "Training Stage ==> Epoch: 350 / 99999 | Training loss: 31.50938 |  Training Accuracy: 4.78671 | Training Metric (MAE): 4.78671\n",
      "Validation Stage ==> Epoch: 350 / 99999 | Validation loss: 31.57770 |  Validation Accuracy: 4.79282 | Validation Metric (MAE)): 4.79282\n",
      "Load Model from best epoch 350\n",
      "Training Stage ==> Epoch: 351 / 99999 | Training loss: 31.83355 |  Training Accuracy: 4.77773 | Training Metric (MAE): 4.77773\n",
      "Validation Stage ==> Epoch: 351 / 99999 | Validation loss: 31.57441 |  Validation Accuracy: 4.79247 | Validation Metric (MAE)): 4.79247\n",
      "Load Model from best epoch 351\n",
      "Training Stage ==> Epoch: 352 / 99999 | Training loss: 31.81876 |  Training Accuracy: 4.76910 | Training Metric (MAE): 4.76910\n",
      "Validation Stage ==> Epoch: 352 / 99999 | Validation loss: 31.57112 |  Validation Accuracy: 4.79213 | Validation Metric (MAE)): 4.79213\n",
      "Load Model from best epoch 352\n",
      "Training Stage ==> Epoch: 353 / 99999 | Training loss: 31.53330 |  Training Accuracy: 4.76110 | Training Metric (MAE): 4.76110\n",
      "Validation Stage ==> Epoch: 353 / 99999 | Validation loss: 31.56784 |  Validation Accuracy: 4.79179 | Validation Metric (MAE)): 4.79179\n",
      "Load Model from best epoch 353\n",
      "Training Stage ==> Epoch: 354 / 99999 | Training loss: 29.83668 |  Training Accuracy: 4.76946 | Training Metric (MAE): 4.76946\n",
      "Validation Stage ==> Epoch: 354 / 99999 | Validation loss: 31.56456 |  Validation Accuracy: 4.79145 | Validation Metric (MAE)): 4.79145\n",
      "Load Model from best epoch 354\n",
      "Training Stage ==> Epoch: 355 / 99999 | Training loss: 31.25580 |  Training Accuracy: 4.77358 | Training Metric (MAE): 4.77358\n",
      "Validation Stage ==> Epoch: 355 / 99999 | Validation loss: 31.56126 |  Validation Accuracy: 4.79111 | Validation Metric (MAE)): 4.79111\n",
      "Load Model from best epoch 355\n",
      "Training Stage ==> Epoch: 356 / 99999 | Training loss: 32.42662 |  Training Accuracy: 4.77894 | Training Metric (MAE): 4.77894\n",
      "Validation Stage ==> Epoch: 356 / 99999 | Validation loss: 31.55798 |  Validation Accuracy: 4.79077 | Validation Metric (MAE)): 4.79077\n",
      "Load Model from best epoch 356\n",
      "Training Stage ==> Epoch: 357 / 99999 | Training loss: 33.54046 |  Training Accuracy: 4.77910 | Training Metric (MAE): 4.77910\n",
      "Validation Stage ==> Epoch: 357 / 99999 | Validation loss: 31.55469 |  Validation Accuracy: 4.79043 | Validation Metric (MAE)): 4.79043\n",
      "Load Model from best epoch 357\n",
      "Training Stage ==> Epoch: 358 / 99999 | Training loss: 31.45774 |  Training Accuracy: 4.76398 | Training Metric (MAE): 4.76398\n",
      "Validation Stage ==> Epoch: 358 / 99999 | Validation loss: 31.55140 |  Validation Accuracy: 4.79009 | Validation Metric (MAE)): 4.79009\n",
      "Load Model from best epoch 358\n",
      "Training Stage ==> Epoch: 359 / 99999 | Training loss: 31.36739 |  Training Accuracy: 4.77573 | Training Metric (MAE): 4.77573\n",
      "Validation Stage ==> Epoch: 359 / 99999 | Validation loss: 31.54811 |  Validation Accuracy: 4.78975 | Validation Metric (MAE)): 4.78975\n",
      "Load Model from best epoch 359\n",
      "Training Stage ==> Epoch: 360 / 99999 | Training loss: 31.40984 |  Training Accuracy: 4.77387 | Training Metric (MAE): 4.77387\n",
      "Validation Stage ==> Epoch: 360 / 99999 | Validation loss: 31.54483 |  Validation Accuracy: 4.78941 | Validation Metric (MAE)): 4.78941\n",
      "Load Model from best epoch 360\n",
      "Training Stage ==> Epoch: 361 / 99999 | Training loss: 30.20944 |  Training Accuracy: 4.75586 | Training Metric (MAE): 4.75586\n",
      "Validation Stage ==> Epoch: 361 / 99999 | Validation loss: 31.54155 |  Validation Accuracy: 4.78907 | Validation Metric (MAE)): 4.78907\n",
      "Load Model from best epoch 361\n",
      "Training Stage ==> Epoch: 362 / 99999 | Training loss: 30.36451 |  Training Accuracy: 4.76099 | Training Metric (MAE): 4.76099\n",
      "Validation Stage ==> Epoch: 362 / 99999 | Validation loss: 31.53826 |  Validation Accuracy: 4.78873 | Validation Metric (MAE)): 4.78873\n",
      "Load Model from best epoch 362\n",
      "Training Stage ==> Epoch: 363 / 99999 | Training loss: 31.91175 |  Training Accuracy: 4.76112 | Training Metric (MAE): 4.76112\n",
      "Validation Stage ==> Epoch: 363 / 99999 | Validation loss: 31.53498 |  Validation Accuracy: 4.78839 | Validation Metric (MAE)): 4.78839\n",
      "Load Model from best epoch 363\n",
      "Training Stage ==> Epoch: 364 / 99999 | Training loss: 30.55235 |  Training Accuracy: 4.76467 | Training Metric (MAE): 4.76467\n",
      "Validation Stage ==> Epoch: 364 / 99999 | Validation loss: 31.53171 |  Validation Accuracy: 4.78805 | Validation Metric (MAE)): 4.78805\n",
      "Load Model from best epoch 364\n",
      "Training Stage ==> Epoch: 365 / 99999 | Training loss: 31.54680 |  Training Accuracy: 4.76331 | Training Metric (MAE): 4.76331\n",
      "Validation Stage ==> Epoch: 365 / 99999 | Validation loss: 31.52843 |  Validation Accuracy: 4.78770 | Validation Metric (MAE)): 4.78770\n",
      "Load Model from best epoch 365\n",
      "Training Stage ==> Epoch: 366 / 99999 | Training loss: 30.47285 |  Training Accuracy: 4.76832 | Training Metric (MAE): 4.76832\n",
      "Validation Stage ==> Epoch: 366 / 99999 | Validation loss: 31.52515 |  Validation Accuracy: 4.78737 | Validation Metric (MAE)): 4.78737\n",
      "Load Model from best epoch 366\n",
      "Training Stage ==> Epoch: 367 / 99999 | Training loss: 30.55371 |  Training Accuracy: 4.76072 | Training Metric (MAE): 4.76072\n",
      "Validation Stage ==> Epoch: 367 / 99999 | Validation loss: 31.52187 |  Validation Accuracy: 4.78702 | Validation Metric (MAE)): 4.78702\n",
      "Load Model from best epoch 367\n",
      "Training Stage ==> Epoch: 368 / 99999 | Training loss: 29.31993 |  Training Accuracy: 4.77705 | Training Metric (MAE): 4.77705\n",
      "Validation Stage ==> Epoch: 368 / 99999 | Validation loss: 31.51860 |  Validation Accuracy: 4.78669 | Validation Metric (MAE)): 4.78669\n",
      "Load Model from best epoch 368\n",
      "Training Stage ==> Epoch: 369 / 99999 | Training loss: 30.52277 |  Training Accuracy: 4.77590 | Training Metric (MAE): 4.77590\n",
      "Validation Stage ==> Epoch: 369 / 99999 | Validation loss: 31.51533 |  Validation Accuracy: 4.78635 | Validation Metric (MAE)): 4.78635\n",
      "Load Model from best epoch 369\n",
      "Training Stage ==> Epoch: 370 / 99999 | Training loss: 30.30440 |  Training Accuracy: 4.76285 | Training Metric (MAE): 4.76285\n",
      "Validation Stage ==> Epoch: 370 / 99999 | Validation loss: 31.51205 |  Validation Accuracy: 4.78601 | Validation Metric (MAE)): 4.78601\n",
      "Load Model from best epoch 370\n",
      "Training Stage ==> Epoch: 371 / 99999 | Training loss: 31.11624 |  Training Accuracy: 4.76147 | Training Metric (MAE): 4.76147\n",
      "Validation Stage ==> Epoch: 371 / 99999 | Validation loss: 31.50877 |  Validation Accuracy: 4.78567 | Validation Metric (MAE)): 4.78567\n",
      "Load Model from best epoch 371\n",
      "Training Stage ==> Epoch: 372 / 99999 | Training loss: 30.79493 |  Training Accuracy: 4.76863 | Training Metric (MAE): 4.76863\n",
      "Validation Stage ==> Epoch: 372 / 99999 | Validation loss: 31.50549 |  Validation Accuracy: 4.78532 | Validation Metric (MAE)): 4.78532\n",
      "Load Model from best epoch 372\n",
      "Training Stage ==> Epoch: 373 / 99999 | Training loss: 31.92011 |  Training Accuracy: 4.76584 | Training Metric (MAE): 4.76584\n",
      "Validation Stage ==> Epoch: 373 / 99999 | Validation loss: 31.50222 |  Validation Accuracy: 4.78498 | Validation Metric (MAE)): 4.78498\n",
      "Load Model from best epoch 373\n",
      "Training Stage ==> Epoch: 374 / 99999 | Training loss: 31.13150 |  Training Accuracy: 4.76808 | Training Metric (MAE): 4.76808\n",
      "Validation Stage ==> Epoch: 374 / 99999 | Validation loss: 31.49895 |  Validation Accuracy: 4.78464 | Validation Metric (MAE)): 4.78464\n",
      "Load Model from best epoch 374\n",
      "Training Stage ==> Epoch: 375 / 99999 | Training loss: 29.99431 |  Training Accuracy: 4.75657 | Training Metric (MAE): 4.75657\n",
      "Validation Stage ==> Epoch: 375 / 99999 | Validation loss: 31.49568 |  Validation Accuracy: 4.78431 | Validation Metric (MAE)): 4.78431\n",
      "Load Model from best epoch 375\n",
      "Training Stage ==> Epoch: 376 / 99999 | Training loss: 30.78222 |  Training Accuracy: 4.76831 | Training Metric (MAE): 4.76831\n",
      "Validation Stage ==> Epoch: 376 / 99999 | Validation loss: 31.49241 |  Validation Accuracy: 4.78397 | Validation Metric (MAE)): 4.78397\n",
      "Load Model from best epoch 376\n",
      "Training Stage ==> Epoch: 377 / 99999 | Training loss: 29.66502 |  Training Accuracy: 4.76987 | Training Metric (MAE): 4.76987\n",
      "Validation Stage ==> Epoch: 377 / 99999 | Validation loss: 31.48914 |  Validation Accuracy: 4.78363 | Validation Metric (MAE)): 4.78363\n",
      "Load Model from best epoch 377\n",
      "Training Stage ==> Epoch: 378 / 99999 | Training loss: 31.04016 |  Training Accuracy: 4.76565 | Training Metric (MAE): 4.76565\n",
      "Validation Stage ==> Epoch: 378 / 99999 | Validation loss: 31.48586 |  Validation Accuracy: 4.78329 | Validation Metric (MAE)): 4.78329\n",
      "Load Model from best epoch 378\n",
      "Training Stage ==> Epoch: 379 / 99999 | Training loss: 29.35945 |  Training Accuracy: 4.76247 | Training Metric (MAE): 4.76247\n",
      "Validation Stage ==> Epoch: 379 / 99999 | Validation loss: 31.48260 |  Validation Accuracy: 4.78295 | Validation Metric (MAE)): 4.78295\n",
      "Load Model from best epoch 379\n",
      "Training Stage ==> Epoch: 380 / 99999 | Training loss: 30.20918 |  Training Accuracy: 4.76681 | Training Metric (MAE): 4.76681\n",
      "Validation Stage ==> Epoch: 380 / 99999 | Validation loss: 31.47933 |  Validation Accuracy: 4.78261 | Validation Metric (MAE)): 4.78261\n",
      "Load Model from best epoch 380\n",
      "Training Stage ==> Epoch: 381 / 99999 | Training loss: 31.13715 |  Training Accuracy: 4.77490 | Training Metric (MAE): 4.77490\n",
      "Validation Stage ==> Epoch: 381 / 99999 | Validation loss: 31.47606 |  Validation Accuracy: 4.78227 | Validation Metric (MAE)): 4.78227\n",
      "Load Model from best epoch 381\n",
      "Training Stage ==> Epoch: 382 / 99999 | Training loss: 30.33586 |  Training Accuracy: 4.76033 | Training Metric (MAE): 4.76033\n",
      "Validation Stage ==> Epoch: 382 / 99999 | Validation loss: 31.47280 |  Validation Accuracy: 4.78193 | Validation Metric (MAE)): 4.78193\n",
      "Load Model from best epoch 382\n",
      "Training Stage ==> Epoch: 383 / 99999 | Training loss: 30.60844 |  Training Accuracy: 4.77017 | Training Metric (MAE): 4.77017\n",
      "Validation Stage ==> Epoch: 383 / 99999 | Validation loss: 31.46954 |  Validation Accuracy: 4.78159 | Validation Metric (MAE)): 4.78159\n",
      "Load Model from best epoch 383\n",
      "Training Stage ==> Epoch: 384 / 99999 | Training loss: 30.22475 |  Training Accuracy: 4.75827 | Training Metric (MAE): 4.75827\n",
      "Validation Stage ==> Epoch: 384 / 99999 | Validation loss: 31.46627 |  Validation Accuracy: 4.78125 | Validation Metric (MAE)): 4.78125\n",
      "Load Model from best epoch 384\n",
      "Training Stage ==> Epoch: 385 / 99999 | Training loss: 28.93348 |  Training Accuracy: 4.74910 | Training Metric (MAE): 4.74910\n",
      "Validation Stage ==> Epoch: 385 / 99999 | Validation loss: 31.46301 |  Validation Accuracy: 4.78091 | Validation Metric (MAE)): 4.78091\n",
      "Load Model from best epoch 385\n",
      "Training Stage ==> Epoch: 386 / 99999 | Training loss: 29.34387 |  Training Accuracy: 4.75190 | Training Metric (MAE): 4.75190\n",
      "Validation Stage ==> Epoch: 386 / 99999 | Validation loss: 31.45975 |  Validation Accuracy: 4.78057 | Validation Metric (MAE)): 4.78057\n",
      "Load Model from best epoch 386\n",
      "Training Stage ==> Epoch: 387 / 99999 | Training loss: 30.24275 |  Training Accuracy: 4.76143 | Training Metric (MAE): 4.76143\n",
      "Validation Stage ==> Epoch: 387 / 99999 | Validation loss: 31.45649 |  Validation Accuracy: 4.78023 | Validation Metric (MAE)): 4.78023\n",
      "Load Model from best epoch 387\n",
      "Training Stage ==> Epoch: 388 / 99999 | Training loss: 32.00156 |  Training Accuracy: 4.76578 | Training Metric (MAE): 4.76578\n",
      "Validation Stage ==> Epoch: 388 / 99999 | Validation loss: 31.45323 |  Validation Accuracy: 4.77989 | Validation Metric (MAE)): 4.77989\n",
      "Load Model from best epoch 388\n",
      "Training Stage ==> Epoch: 389 / 99999 | Training loss: 29.35089 |  Training Accuracy: 4.76551 | Training Metric (MAE): 4.76551\n",
      "Validation Stage ==> Epoch: 389 / 99999 | Validation loss: 31.44996 |  Validation Accuracy: 4.77956 | Validation Metric (MAE)): 4.77956\n",
      "Load Model from best epoch 389\n",
      "Training Stage ==> Epoch: 390 / 99999 | Training loss: 31.02153 |  Training Accuracy: 4.75352 | Training Metric (MAE): 4.75352\n",
      "Validation Stage ==> Epoch: 390 / 99999 | Validation loss: 31.44670 |  Validation Accuracy: 4.77922 | Validation Metric (MAE)): 4.77922\n",
      "Load Model from best epoch 390\n",
      "Training Stage ==> Epoch: 391 / 99999 | Training loss: 30.45838 |  Training Accuracy: 4.75156 | Training Metric (MAE): 4.75156\n",
      "Validation Stage ==> Epoch: 391 / 99999 | Validation loss: 31.44344 |  Validation Accuracy: 4.77888 | Validation Metric (MAE)): 4.77888\n",
      "Load Model from best epoch 391\n",
      "Training Stage ==> Epoch: 392 / 99999 | Training loss: 30.24428 |  Training Accuracy: 4.75568 | Training Metric (MAE): 4.75568\n",
      "Validation Stage ==> Epoch: 392 / 99999 | Validation loss: 31.44018 |  Validation Accuracy: 4.77854 | Validation Metric (MAE)): 4.77854\n",
      "Load Model from best epoch 392\n",
      "Training Stage ==> Epoch: 393 / 99999 | Training loss: 29.94272 |  Training Accuracy: 4.75082 | Training Metric (MAE): 4.75082\n",
      "Validation Stage ==> Epoch: 393 / 99999 | Validation loss: 31.43692 |  Validation Accuracy: 4.77820 | Validation Metric (MAE)): 4.77820\n",
      "Load Model from best epoch 393\n",
      "Training Stage ==> Epoch: 394 / 99999 | Training loss: 32.84681 |  Training Accuracy: 4.76381 | Training Metric (MAE): 4.76381\n",
      "Validation Stage ==> Epoch: 394 / 99999 | Validation loss: 31.43366 |  Validation Accuracy: 4.77786 | Validation Metric (MAE)): 4.77786\n",
      "Load Model from best epoch 394\n",
      "Training Stage ==> Epoch: 395 / 99999 | Training loss: 28.72077 |  Training Accuracy: 4.76577 | Training Metric (MAE): 4.76577\n",
      "Validation Stage ==> Epoch: 395 / 99999 | Validation loss: 31.43041 |  Validation Accuracy: 4.77752 | Validation Metric (MAE)): 4.77752\n",
      "Load Model from best epoch 395\n",
      "Training Stage ==> Epoch: 396 / 99999 | Training loss: 30.58154 |  Training Accuracy: 4.76363 | Training Metric (MAE): 4.76363\n",
      "Validation Stage ==> Epoch: 396 / 99999 | Validation loss: 31.42716 |  Validation Accuracy: 4.77718 | Validation Metric (MAE)): 4.77718\n",
      "Load Model from best epoch 396\n",
      "Training Stage ==> Epoch: 397 / 99999 | Training loss: 31.93291 |  Training Accuracy: 4.75149 | Training Metric (MAE): 4.75149\n",
      "Validation Stage ==> Epoch: 397 / 99999 | Validation loss: 31.42390 |  Validation Accuracy: 4.77684 | Validation Metric (MAE)): 4.77684\n",
      "Load Model from best epoch 397\n",
      "Training Stage ==> Epoch: 398 / 99999 | Training loss: 28.23777 |  Training Accuracy: 4.74419 | Training Metric (MAE): 4.74419\n",
      "Validation Stage ==> Epoch: 398 / 99999 | Validation loss: 31.42064 |  Validation Accuracy: 4.77651 | Validation Metric (MAE)): 4.77651\n",
      "Load Model from best epoch 398\n",
      "Training Stage ==> Epoch: 399 / 99999 | Training loss: 31.30982 |  Training Accuracy: 4.74546 | Training Metric (MAE): 4.74546\n",
      "Validation Stage ==> Epoch: 399 / 99999 | Validation loss: 31.41738 |  Validation Accuracy: 4.77617 | Validation Metric (MAE)): 4.77617\n",
      "Load Model from best epoch 399\n",
      "Training Stage ==> Epoch: 400 / 99999 | Training loss: 30.29239 |  Training Accuracy: 4.75501 | Training Metric (MAE): 4.75501\n",
      "Validation Stage ==> Epoch: 400 / 99999 | Validation loss: 31.41413 |  Validation Accuracy: 4.77583 | Validation Metric (MAE)): 4.77583\n",
      "Load Model from best epoch 400\n",
      "Training Stage ==> Epoch: 401 / 99999 | Training loss: 31.45572 |  Training Accuracy: 4.75256 | Training Metric (MAE): 4.75256\n",
      "Validation Stage ==> Epoch: 401 / 99999 | Validation loss: 31.41087 |  Validation Accuracy: 4.77549 | Validation Metric (MAE)): 4.77549\n",
      "Load Model from best epoch 401\n",
      "Training Stage ==> Epoch: 402 / 99999 | Training loss: 30.08217 |  Training Accuracy: 4.75193 | Training Metric (MAE): 4.75193\n",
      "Validation Stage ==> Epoch: 402 / 99999 | Validation loss: 31.40762 |  Validation Accuracy: 4.77515 | Validation Metric (MAE)): 4.77515\n",
      "Load Model from best epoch 402\n",
      "Training Stage ==> Epoch: 403 / 99999 | Training loss: 30.13629 |  Training Accuracy: 4.76914 | Training Metric (MAE): 4.76914\n",
      "Validation Stage ==> Epoch: 403 / 99999 | Validation loss: 31.40436 |  Validation Accuracy: 4.77481 | Validation Metric (MAE)): 4.77481\n",
      "Load Model from best epoch 403\n",
      "Training Stage ==> Epoch: 404 / 99999 | Training loss: 30.78806 |  Training Accuracy: 4.75481 | Training Metric (MAE): 4.75481\n",
      "Validation Stage ==> Epoch: 404 / 99999 | Validation loss: 31.40111 |  Validation Accuracy: 4.77448 | Validation Metric (MAE)): 4.77448\n",
      "Load Model from best epoch 404\n",
      "Training Stage ==> Epoch: 405 / 99999 | Training loss: 31.33309 |  Training Accuracy: 4.75628 | Training Metric (MAE): 4.75628\n",
      "Validation Stage ==> Epoch: 405 / 99999 | Validation loss: 31.39785 |  Validation Accuracy: 4.77414 | Validation Metric (MAE)): 4.77414\n",
      "Load Model from best epoch 405\n",
      "Training Stage ==> Epoch: 406 / 99999 | Training loss: 30.78129 |  Training Accuracy: 4.75130 | Training Metric (MAE): 4.75130\n",
      "Validation Stage ==> Epoch: 406 / 99999 | Validation loss: 31.39460 |  Validation Accuracy: 4.77380 | Validation Metric (MAE)): 4.77380\n",
      "Load Model from best epoch 406\n",
      "Training Stage ==> Epoch: 407 / 99999 | Training loss: 30.31046 |  Training Accuracy: 4.74192 | Training Metric (MAE): 4.74192\n",
      "Validation Stage ==> Epoch: 407 / 99999 | Validation loss: 31.39135 |  Validation Accuracy: 4.77346 | Validation Metric (MAE)): 4.77346\n",
      "Load Model from best epoch 407\n",
      "Training Stage ==> Epoch: 408 / 99999 | Training loss: 32.18050 |  Training Accuracy: 4.74481 | Training Metric (MAE): 4.74481\n",
      "Validation Stage ==> Epoch: 408 / 99999 | Validation loss: 31.38810 |  Validation Accuracy: 4.77312 | Validation Metric (MAE)): 4.77312\n",
      "Load Model from best epoch 408\n",
      "Training Stage ==> Epoch: 409 / 99999 | Training loss: 31.98462 |  Training Accuracy: 4.75720 | Training Metric (MAE): 4.75720\n",
      "Validation Stage ==> Epoch: 409 / 99999 | Validation loss: 31.38486 |  Validation Accuracy: 4.77278 | Validation Metric (MAE)): 4.77278\n",
      "Load Model from best epoch 409\n",
      "Training Stage ==> Epoch: 410 / 99999 | Training loss: 30.91461 |  Training Accuracy: 4.74219 | Training Metric (MAE): 4.74219\n",
      "Validation Stage ==> Epoch: 410 / 99999 | Validation loss: 31.38161 |  Validation Accuracy: 4.77245 | Validation Metric (MAE)): 4.77245\n",
      "Load Model from best epoch 410\n",
      "Training Stage ==> Epoch: 411 / 99999 | Training loss: 30.64034 |  Training Accuracy: 4.75207 | Training Metric (MAE): 4.75207\n",
      "Validation Stage ==> Epoch: 411 / 99999 | Validation loss: 31.37835 |  Validation Accuracy: 4.77211 | Validation Metric (MAE)): 4.77211\n",
      "Load Model from best epoch 411\n",
      "Training Stage ==> Epoch: 412 / 99999 | Training loss: 29.08520 |  Training Accuracy: 4.75160 | Training Metric (MAE): 4.75160\n",
      "Validation Stage ==> Epoch: 412 / 99999 | Validation loss: 31.37511 |  Validation Accuracy: 4.77177 | Validation Metric (MAE)): 4.77177\n",
      "Load Model from best epoch 412\n",
      "Training Stage ==> Epoch: 413 / 99999 | Training loss: 31.94600 |  Training Accuracy: 4.75054 | Training Metric (MAE): 4.75054\n",
      "Validation Stage ==> Epoch: 413 / 99999 | Validation loss: 31.37186 |  Validation Accuracy: 4.77143 | Validation Metric (MAE)): 4.77143\n",
      "Load Model from best epoch 413\n",
      "Training Stage ==> Epoch: 414 / 99999 | Training loss: 29.54019 |  Training Accuracy: 4.75556 | Training Metric (MAE): 4.75556\n",
      "Validation Stage ==> Epoch: 414 / 99999 | Validation loss: 31.36861 |  Validation Accuracy: 4.77109 | Validation Metric (MAE)): 4.77109\n",
      "Load Model from best epoch 414\n",
      "Training Stage ==> Epoch: 415 / 99999 | Training loss: 29.69908 |  Training Accuracy: 4.74427 | Training Metric (MAE): 4.74427\n",
      "Validation Stage ==> Epoch: 415 / 99999 | Validation loss: 31.36537 |  Validation Accuracy: 4.77075 | Validation Metric (MAE)): 4.77075\n",
      "Load Model from best epoch 415\n",
      "Training Stage ==> Epoch: 416 / 99999 | Training loss: 31.06006 |  Training Accuracy: 4.74858 | Training Metric (MAE): 4.74858\n",
      "Validation Stage ==> Epoch: 416 / 99999 | Validation loss: 31.36212 |  Validation Accuracy: 4.77042 | Validation Metric (MAE)): 4.77042\n",
      "Load Model from best epoch 416\n",
      "Training Stage ==> Epoch: 417 / 99999 | Training loss: 28.82274 |  Training Accuracy: 4.75608 | Training Metric (MAE): 4.75608\n",
      "Validation Stage ==> Epoch: 417 / 99999 | Validation loss: 31.35889 |  Validation Accuracy: 4.77008 | Validation Metric (MAE)): 4.77008\n",
      "Load Model from best epoch 417\n",
      "Training Stage ==> Epoch: 418 / 99999 | Training loss: 30.54255 |  Training Accuracy: 4.76684 | Training Metric (MAE): 4.76684\n",
      "Validation Stage ==> Epoch: 418 / 99999 | Validation loss: 31.35564 |  Validation Accuracy: 4.76974 | Validation Metric (MAE)): 4.76974\n",
      "Load Model from best epoch 418\n",
      "Training Stage ==> Epoch: 419 / 99999 | Training loss: 31.06564 |  Training Accuracy: 4.75436 | Training Metric (MAE): 4.75436\n",
      "Validation Stage ==> Epoch: 419 / 99999 | Validation loss: 31.35241 |  Validation Accuracy: 4.76940 | Validation Metric (MAE)): 4.76940\n",
      "Load Model from best epoch 419\n",
      "Training Stage ==> Epoch: 420 / 99999 | Training loss: 30.19388 |  Training Accuracy: 4.74767 | Training Metric (MAE): 4.74767\n",
      "Validation Stage ==> Epoch: 420 / 99999 | Validation loss: 31.34917 |  Validation Accuracy: 4.76907 | Validation Metric (MAE)): 4.76907\n",
      "Load Model from best epoch 420\n",
      "Training Stage ==> Epoch: 421 / 99999 | Training loss: 30.03616 |  Training Accuracy: 4.74426 | Training Metric (MAE): 4.74426\n",
      "Validation Stage ==> Epoch: 421 / 99999 | Validation loss: 31.34593 |  Validation Accuracy: 4.76873 | Validation Metric (MAE)): 4.76873\n",
      "Load Model from best epoch 421\n",
      "Training Stage ==> Epoch: 422 / 99999 | Training loss: 28.10055 |  Training Accuracy: 4.74990 | Training Metric (MAE): 4.74990\n",
      "Validation Stage ==> Epoch: 422 / 99999 | Validation loss: 31.34269 |  Validation Accuracy: 4.76839 | Validation Metric (MAE)): 4.76839\n",
      "Load Model from best epoch 422\n",
      "Training Stage ==> Epoch: 423 / 99999 | Training loss: 32.54358 |  Training Accuracy: 4.74304 | Training Metric (MAE): 4.74304\n",
      "Validation Stage ==> Epoch: 423 / 99999 | Validation loss: 31.33945 |  Validation Accuracy: 4.76805 | Validation Metric (MAE)): 4.76805\n",
      "Load Model from best epoch 423\n",
      "Training Stage ==> Epoch: 424 / 99999 | Training loss: 31.30435 |  Training Accuracy: 4.75766 | Training Metric (MAE): 4.75766\n",
      "Validation Stage ==> Epoch: 424 / 99999 | Validation loss: 31.33622 |  Validation Accuracy: 4.76772 | Validation Metric (MAE)): 4.76772\n",
      "Load Model from best epoch 424\n",
      "Training Stage ==> Epoch: 425 / 99999 | Training loss: 30.97767 |  Training Accuracy: 4.74588 | Training Metric (MAE): 4.74588\n",
      "Validation Stage ==> Epoch: 425 / 99999 | Validation loss: 31.33298 |  Validation Accuracy: 4.76738 | Validation Metric (MAE)): 4.76738\n",
      "Load Model from best epoch 425\n",
      "Training Stage ==> Epoch: 426 / 99999 | Training loss: 30.39979 |  Training Accuracy: 4.74035 | Training Metric (MAE): 4.74035\n",
      "Validation Stage ==> Epoch: 426 / 99999 | Validation loss: 31.32974 |  Validation Accuracy: 4.76704 | Validation Metric (MAE)): 4.76704\n",
      "Load Model from best epoch 426\n",
      "Training Stage ==> Epoch: 427 / 99999 | Training loss: 30.57369 |  Training Accuracy: 4.74507 | Training Metric (MAE): 4.74507\n",
      "Validation Stage ==> Epoch: 427 / 99999 | Validation loss: 31.32650 |  Validation Accuracy: 4.76670 | Validation Metric (MAE)): 4.76670\n",
      "Load Model from best epoch 427\n",
      "Training Stage ==> Epoch: 428 / 99999 | Training loss: 30.43054 |  Training Accuracy: 4.73650 | Training Metric (MAE): 4.73650\n",
      "Validation Stage ==> Epoch: 428 / 99999 | Validation loss: 31.32326 |  Validation Accuracy: 4.76637 | Validation Metric (MAE)): 4.76637\n",
      "Load Model from best epoch 428\n",
      "Training Stage ==> Epoch: 429 / 99999 | Training loss: 31.90360 |  Training Accuracy: 4.73765 | Training Metric (MAE): 4.73765\n",
      "Validation Stage ==> Epoch: 429 / 99999 | Validation loss: 31.32002 |  Validation Accuracy: 4.76603 | Validation Metric (MAE)): 4.76603\n",
      "Load Model from best epoch 429\n",
      "Training Stage ==> Epoch: 430 / 99999 | Training loss: 31.54522 |  Training Accuracy: 4.74227 | Training Metric (MAE): 4.74227\n",
      "Validation Stage ==> Epoch: 430 / 99999 | Validation loss: 31.31679 |  Validation Accuracy: 4.76569 | Validation Metric (MAE)): 4.76569\n",
      "Load Model from best epoch 430\n",
      "Training Stage ==> Epoch: 431 / 99999 | Training loss: 29.54567 |  Training Accuracy: 4.73850 | Training Metric (MAE): 4.73850\n",
      "Validation Stage ==> Epoch: 431 / 99999 | Validation loss: 31.31355 |  Validation Accuracy: 4.76536 | Validation Metric (MAE)): 4.76536\n",
      "Load Model from best epoch 431\n",
      "Training Stage ==> Epoch: 432 / 99999 | Training loss: 31.95322 |  Training Accuracy: 4.74705 | Training Metric (MAE): 4.74705\n",
      "Validation Stage ==> Epoch: 432 / 99999 | Validation loss: 31.31033 |  Validation Accuracy: 4.76502 | Validation Metric (MAE)): 4.76502\n",
      "Load Model from best epoch 432\n",
      "Training Stage ==> Epoch: 433 / 99999 | Training loss: 30.48927 |  Training Accuracy: 4.74695 | Training Metric (MAE): 4.74695\n",
      "Validation Stage ==> Epoch: 433 / 99999 | Validation loss: 31.30709 |  Validation Accuracy: 4.76468 | Validation Metric (MAE)): 4.76468\n",
      "Load Model from best epoch 433\n",
      "Training Stage ==> Epoch: 434 / 99999 | Training loss: 31.01205 |  Training Accuracy: 4.73833 | Training Metric (MAE): 4.73833\n",
      "Validation Stage ==> Epoch: 434 / 99999 | Validation loss: 31.30386 |  Validation Accuracy: 4.76434 | Validation Metric (MAE)): 4.76434\n",
      "Load Model from best epoch 434\n",
      "Training Stage ==> Epoch: 435 / 99999 | Training loss: 32.03929 |  Training Accuracy: 4.74470 | Training Metric (MAE): 4.74470\n",
      "Validation Stage ==> Epoch: 435 / 99999 | Validation loss: 31.30064 |  Validation Accuracy: 4.76401 | Validation Metric (MAE)): 4.76401\n",
      "Load Model from best epoch 435\n",
      "Training Stage ==> Epoch: 436 / 99999 | Training loss: 30.07416 |  Training Accuracy: 4.74486 | Training Metric (MAE): 4.74486\n",
      "Validation Stage ==> Epoch: 436 / 99999 | Validation loss: 31.29740 |  Validation Accuracy: 4.76367 | Validation Metric (MAE)): 4.76367\n",
      "Load Model from best epoch 436\n",
      "Training Stage ==> Epoch: 437 / 99999 | Training loss: 30.92768 |  Training Accuracy: 4.74421 | Training Metric (MAE): 4.74421\n",
      "Validation Stage ==> Epoch: 437 / 99999 | Validation loss: 31.29417 |  Validation Accuracy: 4.76333 | Validation Metric (MAE)): 4.76333\n",
      "Load Model from best epoch 437\n",
      "Training Stage ==> Epoch: 438 / 99999 | Training loss: 28.93611 |  Training Accuracy: 4.74329 | Training Metric (MAE): 4.74329\n",
      "Validation Stage ==> Epoch: 438 / 99999 | Validation loss: 31.29094 |  Validation Accuracy: 4.76300 | Validation Metric (MAE)): 4.76300\n",
      "Load Model from best epoch 438\n",
      "Training Stage ==> Epoch: 439 / 99999 | Training loss: 28.95900 |  Training Accuracy: 4.75296 | Training Metric (MAE): 4.75296\n",
      "Validation Stage ==> Epoch: 439 / 99999 | Validation loss: 31.28772 |  Validation Accuracy: 4.76266 | Validation Metric (MAE)): 4.76266\n",
      "Load Model from best epoch 439\n",
      "Training Stage ==> Epoch: 440 / 99999 | Training loss: 31.37469 |  Training Accuracy: 4.73575 | Training Metric (MAE): 4.73575\n",
      "Validation Stage ==> Epoch: 440 / 99999 | Validation loss: 31.28448 |  Validation Accuracy: 4.76232 | Validation Metric (MAE)): 4.76232\n",
      "Load Model from best epoch 440\n",
      "Training Stage ==> Epoch: 441 / 99999 | Training loss: 30.34481 |  Training Accuracy: 4.73012 | Training Metric (MAE): 4.73012\n",
      "Validation Stage ==> Epoch: 441 / 99999 | Validation loss: 31.28126 |  Validation Accuracy: 4.76199 | Validation Metric (MAE)): 4.76199\n",
      "Load Model from best epoch 441\n",
      "Training Stage ==> Epoch: 442 / 99999 | Training loss: 29.80331 |  Training Accuracy: 4.74612 | Training Metric (MAE): 4.74612\n",
      "Validation Stage ==> Epoch: 442 / 99999 | Validation loss: 31.27803 |  Validation Accuracy: 4.76165 | Validation Metric (MAE)): 4.76165\n",
      "Load Model from best epoch 442\n",
      "Training Stage ==> Epoch: 443 / 99999 | Training loss: 30.48351 |  Training Accuracy: 4.74195 | Training Metric (MAE): 4.74195\n",
      "Validation Stage ==> Epoch: 443 / 99999 | Validation loss: 31.27481 |  Validation Accuracy: 4.76131 | Validation Metric (MAE)): 4.76131\n",
      "Load Model from best epoch 443\n",
      "Training Stage ==> Epoch: 444 / 99999 | Training loss: 31.55957 |  Training Accuracy: 4.75084 | Training Metric (MAE): 4.75084\n",
      "Validation Stage ==> Epoch: 444 / 99999 | Validation loss: 31.27158 |  Validation Accuracy: 4.76098 | Validation Metric (MAE)): 4.76098\n",
      "Load Model from best epoch 444\n",
      "Training Stage ==> Epoch: 445 / 99999 | Training loss: 32.74731 |  Training Accuracy: 4.73807 | Training Metric (MAE): 4.73807\n",
      "Validation Stage ==> Epoch: 445 / 99999 | Validation loss: 31.26835 |  Validation Accuracy: 4.76064 | Validation Metric (MAE)): 4.76064\n",
      "Load Model from best epoch 445\n",
      "Training Stage ==> Epoch: 446 / 99999 | Training loss: 30.71577 |  Training Accuracy: 4.74064 | Training Metric (MAE): 4.74064\n",
      "Validation Stage ==> Epoch: 446 / 99999 | Validation loss: 31.26514 |  Validation Accuracy: 4.76030 | Validation Metric (MAE)): 4.76030\n",
      "Load Model from best epoch 446\n",
      "Training Stage ==> Epoch: 447 / 99999 | Training loss: 30.63685 |  Training Accuracy: 4.72511 | Training Metric (MAE): 4.72511\n",
      "Validation Stage ==> Epoch: 447 / 99999 | Validation loss: 31.26192 |  Validation Accuracy: 4.75997 | Validation Metric (MAE)): 4.75997\n",
      "Load Model from best epoch 447\n",
      "Training Stage ==> Epoch: 448 / 99999 | Training loss: 29.63296 |  Training Accuracy: 4.74363 | Training Metric (MAE): 4.74363\n",
      "Validation Stage ==> Epoch: 448 / 99999 | Validation loss: 31.25870 |  Validation Accuracy: 4.75963 | Validation Metric (MAE)): 4.75963\n",
      "Load Model from best epoch 448\n",
      "Training Stage ==> Epoch: 449 / 99999 | Training loss: 29.76787 |  Training Accuracy: 4.74003 | Training Metric (MAE): 4.74003\n",
      "Validation Stage ==> Epoch: 449 / 99999 | Validation loss: 31.25547 |  Validation Accuracy: 4.75930 | Validation Metric (MAE)): 4.75930\n",
      "Load Model from best epoch 449\n",
      "Training Stage ==> Epoch: 450 / 99999 | Training loss: 30.59678 |  Training Accuracy: 4.73981 | Training Metric (MAE): 4.73981\n",
      "Validation Stage ==> Epoch: 450 / 99999 | Validation loss: 31.25226 |  Validation Accuracy: 4.75896 | Validation Metric (MAE)): 4.75896\n",
      "Load Model from best epoch 450\n",
      "Training Stage ==> Epoch: 451 / 99999 | Training loss: 30.67073 |  Training Accuracy: 4.73601 | Training Metric (MAE): 4.73601\n",
      "Validation Stage ==> Epoch: 451 / 99999 | Validation loss: 31.24905 |  Validation Accuracy: 4.75862 | Validation Metric (MAE)): 4.75862\n",
      "Load Model from best epoch 451\n",
      "Training Stage ==> Epoch: 452 / 99999 | Training loss: 30.51958 |  Training Accuracy: 4.72631 | Training Metric (MAE): 4.72631\n",
      "Validation Stage ==> Epoch: 452 / 99999 | Validation loss: 31.24583 |  Validation Accuracy: 4.75829 | Validation Metric (MAE)): 4.75829\n",
      "Load Model from best epoch 452\n",
      "Training Stage ==> Epoch: 453 / 99999 | Training loss: 31.11087 |  Training Accuracy: 4.73813 | Training Metric (MAE): 4.73813\n",
      "Validation Stage ==> Epoch: 453 / 99999 | Validation loss: 31.24260 |  Validation Accuracy: 4.75795 | Validation Metric (MAE)): 4.75795\n",
      "Load Model from best epoch 453\n",
      "Training Stage ==> Epoch: 454 / 99999 | Training loss: 30.56484 |  Training Accuracy: 4.74256 | Training Metric (MAE): 4.74256\n",
      "Validation Stage ==> Epoch: 454 / 99999 | Validation loss: 31.23938 |  Validation Accuracy: 4.75762 | Validation Metric (MAE)): 4.75762\n",
      "Load Model from best epoch 454\n",
      "Training Stage ==> Epoch: 455 / 99999 | Training loss: 29.86454 |  Training Accuracy: 4.73776 | Training Metric (MAE): 4.73776\n",
      "Validation Stage ==> Epoch: 455 / 99999 | Validation loss: 31.23617 |  Validation Accuracy: 4.75728 | Validation Metric (MAE)): 4.75728\n",
      "Load Model from best epoch 455\n",
      "Training Stage ==> Epoch: 456 / 99999 | Training loss: 28.41909 |  Training Accuracy: 4.73788 | Training Metric (MAE): 4.73788\n",
      "Validation Stage ==> Epoch: 456 / 99999 | Validation loss: 31.23295 |  Validation Accuracy: 4.75695 | Validation Metric (MAE)): 4.75695\n",
      "Load Model from best epoch 456\n",
      "Training Stage ==> Epoch: 457 / 99999 | Training loss: 30.42534 |  Training Accuracy: 4.74044 | Training Metric (MAE): 4.74044\n",
      "Validation Stage ==> Epoch: 457 / 99999 | Validation loss: 31.22974 |  Validation Accuracy: 4.75661 | Validation Metric (MAE)): 4.75661\n",
      "Load Model from best epoch 457\n",
      "Training Stage ==> Epoch: 458 / 99999 | Training loss: 31.09404 |  Training Accuracy: 4.72565 | Training Metric (MAE): 4.72565\n",
      "Validation Stage ==> Epoch: 458 / 99999 | Validation loss: 31.22653 |  Validation Accuracy: 4.75627 | Validation Metric (MAE)): 4.75627\n",
      "Load Model from best epoch 458\n",
      "Training Stage ==> Epoch: 459 / 99999 | Training loss: 29.85300 |  Training Accuracy: 4.72973 | Training Metric (MAE): 4.72973\n",
      "Validation Stage ==> Epoch: 459 / 99999 | Validation loss: 31.22331 |  Validation Accuracy: 4.75594 | Validation Metric (MAE)): 4.75594\n",
      "Load Model from best epoch 459\n",
      "Training Stage ==> Epoch: 460 / 99999 | Training loss: 29.18303 |  Training Accuracy: 4.74069 | Training Metric (MAE): 4.74069\n",
      "Validation Stage ==> Epoch: 460 / 99999 | Validation loss: 31.22010 |  Validation Accuracy: 4.75560 | Validation Metric (MAE)): 4.75560\n",
      "Load Model from best epoch 460\n",
      "Training Stage ==> Epoch: 461 / 99999 | Training loss: 29.89009 |  Training Accuracy: 4.74011 | Training Metric (MAE): 4.74011\n",
      "Validation Stage ==> Epoch: 461 / 99999 | Validation loss: 31.21689 |  Validation Accuracy: 4.75527 | Validation Metric (MAE)): 4.75527\n",
      "Load Model from best epoch 461\n",
      "Training Stage ==> Epoch: 462 / 99999 | Training loss: 29.56394 |  Training Accuracy: 4.72022 | Training Metric (MAE): 4.72022\n",
      "Validation Stage ==> Epoch: 462 / 99999 | Validation loss: 31.21368 |  Validation Accuracy: 4.75493 | Validation Metric (MAE)): 4.75493\n",
      "Load Model from best epoch 462\n",
      "Training Stage ==> Epoch: 463 / 99999 | Training loss: 31.17066 |  Training Accuracy: 4.74299 | Training Metric (MAE): 4.74299\n",
      "Validation Stage ==> Epoch: 463 / 99999 | Validation loss: 31.21046 |  Validation Accuracy: 4.75460 | Validation Metric (MAE)): 4.75460\n",
      "Load Model from best epoch 463\n",
      "Training Stage ==> Epoch: 464 / 99999 | Training loss: 29.79898 |  Training Accuracy: 4.72107 | Training Metric (MAE): 4.72107\n",
      "Validation Stage ==> Epoch: 464 / 99999 | Validation loss: 31.20726 |  Validation Accuracy: 4.75426 | Validation Metric (MAE)): 4.75426\n",
      "Load Model from best epoch 464\n",
      "Training Stage ==> Epoch: 465 / 99999 | Training loss: 30.29230 |  Training Accuracy: 4.73789 | Training Metric (MAE): 4.73789\n",
      "Validation Stage ==> Epoch: 465 / 99999 | Validation loss: 31.20404 |  Validation Accuracy: 4.75392 | Validation Metric (MAE)): 4.75392\n",
      "Load Model from best epoch 465\n",
      "Training Stage ==> Epoch: 466 / 99999 | Training loss: 30.98331 |  Training Accuracy: 4.73224 | Training Metric (MAE): 4.73224\n",
      "Validation Stage ==> Epoch: 466 / 99999 | Validation loss: 31.20083 |  Validation Accuracy: 4.75359 | Validation Metric (MAE)): 4.75359\n",
      "Load Model from best epoch 466\n",
      "Training Stage ==> Epoch: 467 / 99999 | Training loss: 31.80781 |  Training Accuracy: 4.72418 | Training Metric (MAE): 4.72418\n",
      "Validation Stage ==> Epoch: 467 / 99999 | Validation loss: 31.19762 |  Validation Accuracy: 4.75325 | Validation Metric (MAE)): 4.75325\n",
      "Load Model from best epoch 467\n",
      "Training Stage ==> Epoch: 468 / 99999 | Training loss: 30.75570 |  Training Accuracy: 4.74357 | Training Metric (MAE): 4.74357\n",
      "Validation Stage ==> Epoch: 468 / 99999 | Validation loss: 31.19441 |  Validation Accuracy: 4.75292 | Validation Metric (MAE)): 4.75292\n",
      "Load Model from best epoch 468\n",
      "Training Stage ==> Epoch: 469 / 99999 | Training loss: 29.81366 |  Training Accuracy: 4.73616 | Training Metric (MAE): 4.73616\n",
      "Validation Stage ==> Epoch: 469 / 99999 | Validation loss: 31.19120 |  Validation Accuracy: 4.75258 | Validation Metric (MAE)): 4.75258\n",
      "Load Model from best epoch 469\n",
      "Training Stage ==> Epoch: 470 / 99999 | Training loss: 28.08125 |  Training Accuracy: 4.73312 | Training Metric (MAE): 4.73312\n",
      "Validation Stage ==> Epoch: 470 / 99999 | Validation loss: 31.18800 |  Validation Accuracy: 4.75225 | Validation Metric (MAE)): 4.75225\n",
      "Load Model from best epoch 470\n",
      "Training Stage ==> Epoch: 471 / 99999 | Training loss: 31.89082 |  Training Accuracy: 4.72828 | Training Metric (MAE): 4.72828\n",
      "Validation Stage ==> Epoch: 471 / 99999 | Validation loss: 31.18479 |  Validation Accuracy: 4.75191 | Validation Metric (MAE)): 4.75191\n",
      "Load Model from best epoch 471\n",
      "Training Stage ==> Epoch: 472 / 99999 | Training loss: 31.06161 |  Training Accuracy: 4.74966 | Training Metric (MAE): 4.74966\n",
      "Validation Stage ==> Epoch: 472 / 99999 | Validation loss: 31.18158 |  Validation Accuracy: 4.75158 | Validation Metric (MAE)): 4.75158\n",
      "Load Model from best epoch 472\n",
      "Training Stage ==> Epoch: 473 / 99999 | Training loss: 29.00008 |  Training Accuracy: 4.73748 | Training Metric (MAE): 4.73748\n",
      "Validation Stage ==> Epoch: 473 / 99999 | Validation loss: 31.17837 |  Validation Accuracy: 4.75124 | Validation Metric (MAE)): 4.75124\n",
      "Load Model from best epoch 473\n",
      "Training Stage ==> Epoch: 474 / 99999 | Training loss: 30.67422 |  Training Accuracy: 4.73042 | Training Metric (MAE): 4.73042\n",
      "Validation Stage ==> Epoch: 474 / 99999 | Validation loss: 31.17517 |  Validation Accuracy: 4.75091 | Validation Metric (MAE)): 4.75091\n",
      "Load Model from best epoch 474\n",
      "Training Stage ==> Epoch: 475 / 99999 | Training loss: 30.16660 |  Training Accuracy: 4.73789 | Training Metric (MAE): 4.73789\n",
      "Validation Stage ==> Epoch: 475 / 99999 | Validation loss: 31.17196 |  Validation Accuracy: 4.75057 | Validation Metric (MAE)): 4.75057\n",
      "Load Model from best epoch 475\n",
      "Training Stage ==> Epoch: 476 / 99999 | Training loss: 29.87860 |  Training Accuracy: 4.72907 | Training Metric (MAE): 4.72907\n",
      "Validation Stage ==> Epoch: 476 / 99999 | Validation loss: 31.16877 |  Validation Accuracy: 4.75024 | Validation Metric (MAE)): 4.75024\n",
      "Load Model from best epoch 476\n",
      "Training Stage ==> Epoch: 477 / 99999 | Training loss: 29.50246 |  Training Accuracy: 4.72615 | Training Metric (MAE): 4.72615\n",
      "Validation Stage ==> Epoch: 477 / 99999 | Validation loss: 31.16557 |  Validation Accuracy: 4.74990 | Validation Metric (MAE)): 4.74990\n",
      "Load Model from best epoch 477\n",
      "Training Stage ==> Epoch: 478 / 99999 | Training loss: 30.51105 |  Training Accuracy: 4.73220 | Training Metric (MAE): 4.73220\n",
      "Validation Stage ==> Epoch: 478 / 99999 | Validation loss: 31.16236 |  Validation Accuracy: 4.74957 | Validation Metric (MAE)): 4.74957\n",
      "Load Model from best epoch 478\n",
      "Training Stage ==> Epoch: 479 / 99999 | Training loss: 30.73894 |  Training Accuracy: 4.72963 | Training Metric (MAE): 4.72963\n",
      "Validation Stage ==> Epoch: 479 / 99999 | Validation loss: 31.15916 |  Validation Accuracy: 4.74923 | Validation Metric (MAE)): 4.74923\n",
      "Load Model from best epoch 479\n",
      "Training Stage ==> Epoch: 480 / 99999 | Training loss: 30.64916 |  Training Accuracy: 4.72956 | Training Metric (MAE): 4.72956\n",
      "Validation Stage ==> Epoch: 480 / 99999 | Validation loss: 31.15596 |  Validation Accuracy: 4.74890 | Validation Metric (MAE)): 4.74890\n",
      "Load Model from best epoch 480\n",
      "Training Stage ==> Epoch: 481 / 99999 | Training loss: 30.24929 |  Training Accuracy: 4.73321 | Training Metric (MAE): 4.73321\n",
      "Validation Stage ==> Epoch: 481 / 99999 | Validation loss: 31.15276 |  Validation Accuracy: 4.74856 | Validation Metric (MAE)): 4.74856\n",
      "Load Model from best epoch 481\n",
      "Training Stage ==> Epoch: 482 / 99999 | Training loss: 30.11435 |  Training Accuracy: 4.73015 | Training Metric (MAE): 4.73015\n",
      "Validation Stage ==> Epoch: 482 / 99999 | Validation loss: 31.14957 |  Validation Accuracy: 4.74823 | Validation Metric (MAE)): 4.74823\n",
      "Load Model from best epoch 482\n",
      "Training Stage ==> Epoch: 483 / 99999 | Training loss: 30.40970 |  Training Accuracy: 4.71953 | Training Metric (MAE): 4.71953\n",
      "Validation Stage ==> Epoch: 483 / 99999 | Validation loss: 31.14637 |  Validation Accuracy: 4.74789 | Validation Metric (MAE)): 4.74789\n",
      "Load Model from best epoch 483\n",
      "Training Stage ==> Epoch: 484 / 99999 | Training loss: 32.23986 |  Training Accuracy: 4.71742 | Training Metric (MAE): 4.71742\n",
      "Validation Stage ==> Epoch: 484 / 99999 | Validation loss: 31.14318 |  Validation Accuracy: 4.74756 | Validation Metric (MAE)): 4.74756\n",
      "Load Model from best epoch 484\n",
      "Training Stage ==> Epoch: 485 / 99999 | Training loss: 30.92368 |  Training Accuracy: 4.72728 | Training Metric (MAE): 4.72728\n",
      "Validation Stage ==> Epoch: 485 / 99999 | Validation loss: 31.13997 |  Validation Accuracy: 4.74722 | Validation Metric (MAE)): 4.74722\n",
      "Load Model from best epoch 485\n",
      "Training Stage ==> Epoch: 486 / 99999 | Training loss: 30.58078 |  Training Accuracy: 4.72723 | Training Metric (MAE): 4.72723\n",
      "Validation Stage ==> Epoch: 486 / 99999 | Validation loss: 31.13677 |  Validation Accuracy: 4.74689 | Validation Metric (MAE)): 4.74689\n",
      "Load Model from best epoch 486\n",
      "Training Stage ==> Epoch: 487 / 99999 | Training loss: 30.57351 |  Training Accuracy: 4.72721 | Training Metric (MAE): 4.72721\n",
      "Validation Stage ==> Epoch: 487 / 99999 | Validation loss: 31.13357 |  Validation Accuracy: 4.74655 | Validation Metric (MAE)): 4.74655\n",
      "Load Model from best epoch 487\n",
      "Training Stage ==> Epoch: 488 / 99999 | Training loss: 31.31663 |  Training Accuracy: 4.72783 | Training Metric (MAE): 4.72783\n",
      "Validation Stage ==> Epoch: 488 / 99999 | Validation loss: 31.13038 |  Validation Accuracy: 4.74622 | Validation Metric (MAE)): 4.74622\n",
      "Load Model from best epoch 488\n",
      "Training Stage ==> Epoch: 489 / 99999 | Training loss: 31.19981 |  Training Accuracy: 4.71135 | Training Metric (MAE): 4.71135\n",
      "Validation Stage ==> Epoch: 489 / 99999 | Validation loss: 31.12718 |  Validation Accuracy: 4.74589 | Validation Metric (MAE)): 4.74589\n",
      "Load Model from best epoch 489\n",
      "Training Stage ==> Epoch: 490 / 99999 | Training loss: 29.79083 |  Training Accuracy: 4.73002 | Training Metric (MAE): 4.73002\n",
      "Validation Stage ==> Epoch: 490 / 99999 | Validation loss: 31.12399 |  Validation Accuracy: 4.74555 | Validation Metric (MAE)): 4.74555\n",
      "Load Model from best epoch 490\n",
      "Training Stage ==> Epoch: 491 / 99999 | Training loss: 29.85715 |  Training Accuracy: 4.72795 | Training Metric (MAE): 4.72795\n",
      "Validation Stage ==> Epoch: 491 / 99999 | Validation loss: 31.12080 |  Validation Accuracy: 4.74522 | Validation Metric (MAE)): 4.74522\n",
      "Load Model from best epoch 491\n",
      "Training Stage ==> Epoch: 492 / 99999 | Training loss: 30.81330 |  Training Accuracy: 4.73380 | Training Metric (MAE): 4.73380\n",
      "Validation Stage ==> Epoch: 492 / 99999 | Validation loss: 31.11760 |  Validation Accuracy: 4.74488 | Validation Metric (MAE)): 4.74488\n",
      "Load Model from best epoch 492\n",
      "Training Stage ==> Epoch: 493 / 99999 | Training loss: 30.82951 |  Training Accuracy: 4.72225 | Training Metric (MAE): 4.72225\n",
      "Validation Stage ==> Epoch: 493 / 99999 | Validation loss: 31.11440 |  Validation Accuracy: 4.74455 | Validation Metric (MAE)): 4.74455\n",
      "Load Model from best epoch 493\n",
      "Training Stage ==> Epoch: 494 / 99999 | Training loss: 30.13863 |  Training Accuracy: 4.72082 | Training Metric (MAE): 4.72082\n",
      "Validation Stage ==> Epoch: 494 / 99999 | Validation loss: 31.11120 |  Validation Accuracy: 4.74421 | Validation Metric (MAE)): 4.74421\n",
      "Load Model from best epoch 494\n",
      "Training Stage ==> Epoch: 495 / 99999 | Training loss: 30.52087 |  Training Accuracy: 4.73583 | Training Metric (MAE): 4.73583\n",
      "Validation Stage ==> Epoch: 495 / 99999 | Validation loss: 31.10802 |  Validation Accuracy: 4.74388 | Validation Metric (MAE)): 4.74388\n",
      "Load Model from best epoch 495\n",
      "Training Stage ==> Epoch: 496 / 99999 | Training loss: 29.45366 |  Training Accuracy: 4.71789 | Training Metric (MAE): 4.71789\n",
      "Validation Stage ==> Epoch: 496 / 99999 | Validation loss: 31.10483 |  Validation Accuracy: 4.74354 | Validation Metric (MAE)): 4.74354\n",
      "Load Model from best epoch 496\n",
      "Training Stage ==> Epoch: 497 / 99999 | Training loss: 29.31640 |  Training Accuracy: 4.71917 | Training Metric (MAE): 4.71917\n",
      "Validation Stage ==> Epoch: 497 / 99999 | Validation loss: 31.10165 |  Validation Accuracy: 4.74321 | Validation Metric (MAE)): 4.74321\n",
      "Load Model from best epoch 497\n",
      "Training Stage ==> Epoch: 498 / 99999 | Training loss: 29.90120 |  Training Accuracy: 4.73085 | Training Metric (MAE): 4.73085\n",
      "Validation Stage ==> Epoch: 498 / 99999 | Validation loss: 31.09846 |  Validation Accuracy: 4.74288 | Validation Metric (MAE)): 4.74288\n",
      "Load Model from best epoch 498\n",
      "Training Stage ==> Epoch: 499 / 99999 | Training loss: 29.66220 |  Training Accuracy: 4.72595 | Training Metric (MAE): 4.72595\n",
      "Validation Stage ==> Epoch: 499 / 99999 | Validation loss: 31.09527 |  Validation Accuracy: 4.74254 | Validation Metric (MAE)): 4.74254\n",
      "Load Model from best epoch 499\n",
      "Training Stage ==> Epoch: 500 / 99999 | Training loss: 29.01325 |  Training Accuracy: 4.72723 | Training Metric (MAE): 4.72723\n",
      "Validation Stage ==> Epoch: 500 / 99999 | Validation loss: 31.09209 |  Validation Accuracy: 4.74221 | Validation Metric (MAE)): 4.74221\n",
      "Load Model from best epoch 500\n",
      "Training Stage ==> Epoch: 501 / 99999 | Training loss: 30.55156 |  Training Accuracy: 4.72395 | Training Metric (MAE): 4.72395\n",
      "Validation Stage ==> Epoch: 501 / 99999 | Validation loss: 31.08890 |  Validation Accuracy: 4.74188 | Validation Metric (MAE)): 4.74188\n",
      "Load Model from best epoch 501\n",
      "Training Stage ==> Epoch: 502 / 99999 | Training loss: 30.38218 |  Training Accuracy: 4.72218 | Training Metric (MAE): 4.72218\n",
      "Validation Stage ==> Epoch: 502 / 99999 | Validation loss: 31.08572 |  Validation Accuracy: 4.74154 | Validation Metric (MAE)): 4.74154\n",
      "Load Model from best epoch 502\n",
      "Training Stage ==> Epoch: 503 / 99999 | Training loss: 29.34300 |  Training Accuracy: 4.71855 | Training Metric (MAE): 4.71855\n",
      "Validation Stage ==> Epoch: 503 / 99999 | Validation loss: 31.08254 |  Validation Accuracy: 4.74121 | Validation Metric (MAE)): 4.74121\n",
      "Load Model from best epoch 503\n",
      "Training Stage ==> Epoch: 504 / 99999 | Training loss: 28.78748 |  Training Accuracy: 4.72890 | Training Metric (MAE): 4.72890\n",
      "Validation Stage ==> Epoch: 504 / 99999 | Validation loss: 31.07936 |  Validation Accuracy: 4.74088 | Validation Metric (MAE)): 4.74088\n",
      "Load Model from best epoch 504\n",
      "Training Stage ==> Epoch: 505 / 99999 | Training loss: 29.87025 |  Training Accuracy: 4.72754 | Training Metric (MAE): 4.72754\n",
      "Validation Stage ==> Epoch: 505 / 99999 | Validation loss: 31.07618 |  Validation Accuracy: 4.74054 | Validation Metric (MAE)): 4.74054\n",
      "Load Model from best epoch 505\n",
      "Training Stage ==> Epoch: 506 / 99999 | Training loss: 30.30999 |  Training Accuracy: 4.71975 | Training Metric (MAE): 4.71975\n",
      "Validation Stage ==> Epoch: 506 / 99999 | Validation loss: 31.07299 |  Validation Accuracy: 4.74021 | Validation Metric (MAE)): 4.74021\n",
      "Load Model from best epoch 506\n",
      "Training Stage ==> Epoch: 507 / 99999 | Training loss: 31.73323 |  Training Accuracy: 4.71524 | Training Metric (MAE): 4.71524\n",
      "Validation Stage ==> Epoch: 507 / 99999 | Validation loss: 31.06981 |  Validation Accuracy: 4.73988 | Validation Metric (MAE)): 4.73988\n",
      "Load Model from best epoch 507\n",
      "Training Stage ==> Epoch: 508 / 99999 | Training loss: 30.30082 |  Training Accuracy: 4.70671 | Training Metric (MAE): 4.70671\n",
      "Validation Stage ==> Epoch: 508 / 99999 | Validation loss: 31.06663 |  Validation Accuracy: 4.73954 | Validation Metric (MAE)): 4.73954\n",
      "Load Model from best epoch 508\n",
      "Training Stage ==> Epoch: 509 / 99999 | Training loss: 31.61870 |  Training Accuracy: 4.71813 | Training Metric (MAE): 4.71813\n",
      "Validation Stage ==> Epoch: 509 / 99999 | Validation loss: 31.06345 |  Validation Accuracy: 4.73921 | Validation Metric (MAE)): 4.73921\n",
      "Load Model from best epoch 509\n",
      "Training Stage ==> Epoch: 510 / 99999 | Training loss: 31.63673 |  Training Accuracy: 4.71301 | Training Metric (MAE): 4.71301\n",
      "Validation Stage ==> Epoch: 510 / 99999 | Validation loss: 31.06027 |  Validation Accuracy: 4.73888 | Validation Metric (MAE)): 4.73888\n",
      "Load Model from best epoch 510\n",
      "Training Stage ==> Epoch: 511 / 99999 | Training loss: 30.17057 |  Training Accuracy: 4.71435 | Training Metric (MAE): 4.71435\n",
      "Validation Stage ==> Epoch: 511 / 99999 | Validation loss: 31.05709 |  Validation Accuracy: 4.73854 | Validation Metric (MAE)): 4.73854\n",
      "Load Model from best epoch 511\n",
      "Training Stage ==> Epoch: 512 / 99999 | Training loss: 29.85120 |  Training Accuracy: 4.72228 | Training Metric (MAE): 4.72228\n",
      "Validation Stage ==> Epoch: 512 / 99999 | Validation loss: 31.05391 |  Validation Accuracy: 4.73821 | Validation Metric (MAE)): 4.73821\n",
      "Load Model from best epoch 512\n",
      "Training Stage ==> Epoch: 513 / 99999 | Training loss: 30.51620 |  Training Accuracy: 4.71388 | Training Metric (MAE): 4.71388\n",
      "Validation Stage ==> Epoch: 513 / 99999 | Validation loss: 31.05073 |  Validation Accuracy: 4.73788 | Validation Metric (MAE)): 4.73788\n",
      "Load Model from best epoch 513\n",
      "Training Stage ==> Epoch: 514 / 99999 | Training loss: 31.42148 |  Training Accuracy: 4.70683 | Training Metric (MAE): 4.70683\n",
      "Validation Stage ==> Epoch: 514 / 99999 | Validation loss: 31.04754 |  Validation Accuracy: 4.73754 | Validation Metric (MAE)): 4.73754\n",
      "Load Model from best epoch 514\n",
      "Training Stage ==> Epoch: 515 / 99999 | Training loss: 30.40260 |  Training Accuracy: 4.72265 | Training Metric (MAE): 4.72265\n",
      "Validation Stage ==> Epoch: 515 / 99999 | Validation loss: 31.04437 |  Validation Accuracy: 4.73721 | Validation Metric (MAE)): 4.73721\n",
      "Load Model from best epoch 515\n",
      "Training Stage ==> Epoch: 516 / 99999 | Training loss: 30.14563 |  Training Accuracy: 4.72157 | Training Metric (MAE): 4.72157\n",
      "Validation Stage ==> Epoch: 516 / 99999 | Validation loss: 31.04118 |  Validation Accuracy: 4.73687 | Validation Metric (MAE)): 4.73687\n",
      "Load Model from best epoch 516\n",
      "Training Stage ==> Epoch: 517 / 99999 | Training loss: 27.79593 |  Training Accuracy: 4.71381 | Training Metric (MAE): 4.71381\n",
      "Validation Stage ==> Epoch: 517 / 99999 | Validation loss: 31.03802 |  Validation Accuracy: 4.73654 | Validation Metric (MAE)): 4.73654\n",
      "Load Model from best epoch 517\n",
      "Training Stage ==> Epoch: 518 / 99999 | Training loss: 29.45395 |  Training Accuracy: 4.70985 | Training Metric (MAE): 4.70985\n",
      "Validation Stage ==> Epoch: 518 / 99999 | Validation loss: 31.03485 |  Validation Accuracy: 4.73621 | Validation Metric (MAE)): 4.73621\n",
      "Load Model from best epoch 518\n",
      "Training Stage ==> Epoch: 519 / 99999 | Training loss: 28.60241 |  Training Accuracy: 4.71656 | Training Metric (MAE): 4.71656\n",
      "Validation Stage ==> Epoch: 519 / 99999 | Validation loss: 31.03167 |  Validation Accuracy: 4.73588 | Validation Metric (MAE)): 4.73588\n",
      "Load Model from best epoch 519\n",
      "Training Stage ==> Epoch: 520 / 99999 | Training loss: 29.41957 |  Training Accuracy: 4.71633 | Training Metric (MAE): 4.71633\n",
      "Validation Stage ==> Epoch: 520 / 99999 | Validation loss: 31.02850 |  Validation Accuracy: 4.73554 | Validation Metric (MAE)): 4.73554\n",
      "Load Model from best epoch 520\n",
      "Training Stage ==> Epoch: 521 / 99999 | Training loss: 29.25354 |  Training Accuracy: 4.71473 | Training Metric (MAE): 4.71473\n",
      "Validation Stage ==> Epoch: 521 / 99999 | Validation loss: 31.02533 |  Validation Accuracy: 4.73521 | Validation Metric (MAE)): 4.73521\n",
      "Load Model from best epoch 521\n",
      "Training Stage ==> Epoch: 522 / 99999 | Training loss: 30.32549 |  Training Accuracy: 4.70899 | Training Metric (MAE): 4.70899\n",
      "Validation Stage ==> Epoch: 522 / 99999 | Validation loss: 31.02216 |  Validation Accuracy: 4.73488 | Validation Metric (MAE)): 4.73488\n",
      "Load Model from best epoch 522\n",
      "Training Stage ==> Epoch: 523 / 99999 | Training loss: 31.13034 |  Training Accuracy: 4.69903 | Training Metric (MAE): 4.69903\n",
      "Validation Stage ==> Epoch: 523 / 99999 | Validation loss: 31.01899 |  Validation Accuracy: 4.73455 | Validation Metric (MAE)): 4.73455\n",
      "Load Model from best epoch 523\n",
      "Training Stage ==> Epoch: 524 / 99999 | Training loss: 31.74510 |  Training Accuracy: 4.70608 | Training Metric (MAE): 4.70608\n",
      "Validation Stage ==> Epoch: 524 / 99999 | Validation loss: 31.01582 |  Validation Accuracy: 4.73421 | Validation Metric (MAE)): 4.73421\n",
      "Load Model from best epoch 524\n",
      "Training Stage ==> Epoch: 525 / 99999 | Training loss: 30.51494 |  Training Accuracy: 4.72327 | Training Metric (MAE): 4.72327\n",
      "Validation Stage ==> Epoch: 525 / 99999 | Validation loss: 31.01265 |  Validation Accuracy: 4.73388 | Validation Metric (MAE)): 4.73388\n",
      "Load Model from best epoch 525\n",
      "Training Stage ==> Epoch: 526 / 99999 | Training loss: 29.67279 |  Training Accuracy: 4.71444 | Training Metric (MAE): 4.71444\n",
      "Validation Stage ==> Epoch: 526 / 99999 | Validation loss: 31.00948 |  Validation Accuracy: 4.73355 | Validation Metric (MAE)): 4.73355\n",
      "Load Model from best epoch 526\n",
      "Training Stage ==> Epoch: 527 / 99999 | Training loss: 29.93869 |  Training Accuracy: 4.72606 | Training Metric (MAE): 4.72606\n",
      "Validation Stage ==> Epoch: 527 / 99999 | Validation loss: 31.00632 |  Validation Accuracy: 4.73322 | Validation Metric (MAE)): 4.73322\n",
      "Load Model from best epoch 527\n",
      "Training Stage ==> Epoch: 528 / 99999 | Training loss: 31.88862 |  Training Accuracy: 4.71665 | Training Metric (MAE): 4.71665\n",
      "Validation Stage ==> Epoch: 528 / 99999 | Validation loss: 31.00314 |  Validation Accuracy: 4.73288 | Validation Metric (MAE)): 4.73288\n",
      "Load Model from best epoch 528\n",
      "Training Stage ==> Epoch: 529 / 99999 | Training loss: 31.03688 |  Training Accuracy: 4.71203 | Training Metric (MAE): 4.71203\n",
      "Validation Stage ==> Epoch: 529 / 99999 | Validation loss: 30.99997 |  Validation Accuracy: 4.73255 | Validation Metric (MAE)): 4.73255\n",
      "Load Model from best epoch 529\n",
      "Training Stage ==> Epoch: 530 / 99999 | Training loss: 29.93464 |  Training Accuracy: 4.70982 | Training Metric (MAE): 4.70982\n",
      "Validation Stage ==> Epoch: 530 / 99999 | Validation loss: 30.99680 |  Validation Accuracy: 4.73222 | Validation Metric (MAE)): 4.73222\n",
      "Load Model from best epoch 530\n",
      "Training Stage ==> Epoch: 531 / 99999 | Training loss: 30.52584 |  Training Accuracy: 4.69958 | Training Metric (MAE): 4.69958\n",
      "Validation Stage ==> Epoch: 531 / 99999 | Validation loss: 30.99364 |  Validation Accuracy: 4.73189 | Validation Metric (MAE)): 4.73189\n",
      "Load Model from best epoch 531\n",
      "Training Stage ==> Epoch: 532 / 99999 | Training loss: 30.67653 |  Training Accuracy: 4.72529 | Training Metric (MAE): 4.72529\n",
      "Validation Stage ==> Epoch: 532 / 99999 | Validation loss: 30.99047 |  Validation Accuracy: 4.73155 | Validation Metric (MAE)): 4.73155\n",
      "Load Model from best epoch 532\n",
      "Training Stage ==> Epoch: 533 / 99999 | Training loss: 30.66563 |  Training Accuracy: 4.69883 | Training Metric (MAE): 4.69883\n",
      "Validation Stage ==> Epoch: 533 / 99999 | Validation loss: 30.98730 |  Validation Accuracy: 4.73122 | Validation Metric (MAE)): 4.73122\n",
      "Load Model from best epoch 533\n",
      "Training Stage ==> Epoch: 534 / 99999 | Training loss: 27.83395 |  Training Accuracy: 4.70894 | Training Metric (MAE): 4.70894\n",
      "Validation Stage ==> Epoch: 534 / 99999 | Validation loss: 30.98414 |  Validation Accuracy: 4.73089 | Validation Metric (MAE)): 4.73089\n",
      "Load Model from best epoch 534\n",
      "Training Stage ==> Epoch: 535 / 99999 | Training loss: 29.50221 |  Training Accuracy: 4.71051 | Training Metric (MAE): 4.71051\n",
      "Validation Stage ==> Epoch: 535 / 99999 | Validation loss: 30.98098 |  Validation Accuracy: 4.73056 | Validation Metric (MAE)): 4.73056\n",
      "Load Model from best epoch 535\n",
      "Training Stage ==> Epoch: 536 / 99999 | Training loss: 30.86643 |  Training Accuracy: 4.70523 | Training Metric (MAE): 4.70523\n",
      "Validation Stage ==> Epoch: 536 / 99999 | Validation loss: 30.97782 |  Validation Accuracy: 4.73022 | Validation Metric (MAE)): 4.73022\n",
      "Load Model from best epoch 536\n",
      "Training Stage ==> Epoch: 537 / 99999 | Training loss: 30.64276 |  Training Accuracy: 4.69871 | Training Metric (MAE): 4.69871\n",
      "Validation Stage ==> Epoch: 537 / 99999 | Validation loss: 30.97465 |  Validation Accuracy: 4.72989 | Validation Metric (MAE)): 4.72989\n",
      "Load Model from best epoch 537\n",
      "Training Stage ==> Epoch: 538 / 99999 | Training loss: 30.55115 |  Training Accuracy: 4.70888 | Training Metric (MAE): 4.70888\n",
      "Validation Stage ==> Epoch: 538 / 99999 | Validation loss: 30.97150 |  Validation Accuracy: 4.72956 | Validation Metric (MAE)): 4.72956\n",
      "Load Model from best epoch 538\n",
      "Training Stage ==> Epoch: 539 / 99999 | Training loss: 30.43480 |  Training Accuracy: 4.69796 | Training Metric (MAE): 4.69796\n",
      "Validation Stage ==> Epoch: 539 / 99999 | Validation loss: 30.96833 |  Validation Accuracy: 4.72923 | Validation Metric (MAE)): 4.72923\n",
      "Load Model from best epoch 539\n",
      "Training Stage ==> Epoch: 540 / 99999 | Training loss: 30.22816 |  Training Accuracy: 4.70617 | Training Metric (MAE): 4.70617\n",
      "Validation Stage ==> Epoch: 540 / 99999 | Validation loss: 30.96517 |  Validation Accuracy: 4.72890 | Validation Metric (MAE)): 4.72890\n",
      "Load Model from best epoch 540\n",
      "Training Stage ==> Epoch: 541 / 99999 | Training loss: 29.79589 |  Training Accuracy: 4.71650 | Training Metric (MAE): 4.71650\n",
      "Validation Stage ==> Epoch: 541 / 99999 | Validation loss: 30.96202 |  Validation Accuracy: 4.72856 | Validation Metric (MAE)): 4.72856\n",
      "Load Model from best epoch 541\n",
      "Training Stage ==> Epoch: 542 / 99999 | Training loss: 29.75041 |  Training Accuracy: 4.71710 | Training Metric (MAE): 4.71710\n",
      "Validation Stage ==> Epoch: 542 / 99999 | Validation loss: 30.95886 |  Validation Accuracy: 4.72823 | Validation Metric (MAE)): 4.72823\n",
      "Load Model from best epoch 542\n",
      "Training Stage ==> Epoch: 543 / 99999 | Training loss: 28.31594 |  Training Accuracy: 4.71027 | Training Metric (MAE): 4.71027\n",
      "Validation Stage ==> Epoch: 543 / 99999 | Validation loss: 30.95570 |  Validation Accuracy: 4.72790 | Validation Metric (MAE)): 4.72790\n",
      "Load Model from best epoch 543\n",
      "Training Stage ==> Epoch: 544 / 99999 | Training loss: 30.33214 |  Training Accuracy: 4.69943 | Training Metric (MAE): 4.69943\n",
      "Validation Stage ==> Epoch: 544 / 99999 | Validation loss: 30.95254 |  Validation Accuracy: 4.72757 | Validation Metric (MAE)): 4.72757\n",
      "Load Model from best epoch 544\n",
      "Training Stage ==> Epoch: 545 / 99999 | Training loss: 28.38120 |  Training Accuracy: 4.71096 | Training Metric (MAE): 4.71096\n",
      "Validation Stage ==> Epoch: 545 / 99999 | Validation loss: 30.94939 |  Validation Accuracy: 4.72724 | Validation Metric (MAE)): 4.72724\n",
      "Load Model from best epoch 545\n",
      "Training Stage ==> Epoch: 546 / 99999 | Training loss: 29.46803 |  Training Accuracy: 4.69566 | Training Metric (MAE): 4.69566\n",
      "Validation Stage ==> Epoch: 546 / 99999 | Validation loss: 30.94623 |  Validation Accuracy: 4.72690 | Validation Metric (MAE)): 4.72690\n",
      "Load Model from best epoch 546\n",
      "Training Stage ==> Epoch: 547 / 99999 | Training loss: 29.57800 |  Training Accuracy: 4.70598 | Training Metric (MAE): 4.70598\n",
      "Validation Stage ==> Epoch: 547 / 99999 | Validation loss: 30.94307 |  Validation Accuracy: 4.72657 | Validation Metric (MAE)): 4.72657\n",
      "Load Model from best epoch 547\n",
      "Training Stage ==> Epoch: 548 / 99999 | Training loss: 31.54297 |  Training Accuracy: 4.70461 | Training Metric (MAE): 4.70461\n",
      "Validation Stage ==> Epoch: 548 / 99999 | Validation loss: 30.93991 |  Validation Accuracy: 4.72624 | Validation Metric (MAE)): 4.72624\n",
      "Load Model from best epoch 548\n",
      "Training Stage ==> Epoch: 549 / 99999 | Training loss: 29.91428 |  Training Accuracy: 4.70094 | Training Metric (MAE): 4.70094\n",
      "Validation Stage ==> Epoch: 549 / 99999 | Validation loss: 30.93675 |  Validation Accuracy: 4.72591 | Validation Metric (MAE)): 4.72591\n",
      "Load Model from best epoch 549\n",
      "Training Stage ==> Epoch: 550 / 99999 | Training loss: 30.54943 |  Training Accuracy: 4.69431 | Training Metric (MAE): 4.69431\n",
      "Validation Stage ==> Epoch: 550 / 99999 | Validation loss: 30.93359 |  Validation Accuracy: 4.72558 | Validation Metric (MAE)): 4.72558\n",
      "Load Model from best epoch 550\n",
      "Training Stage ==> Epoch: 551 / 99999 | Training loss: 29.86721 |  Training Accuracy: 4.71357 | Training Metric (MAE): 4.71357\n",
      "Validation Stage ==> Epoch: 551 / 99999 | Validation loss: 30.93044 |  Validation Accuracy: 4.72524 | Validation Metric (MAE)): 4.72524\n",
      "Load Model from best epoch 551\n",
      "Training Stage ==> Epoch: 552 / 99999 | Training loss: 30.51658 |  Training Accuracy: 4.70191 | Training Metric (MAE): 4.70191\n",
      "Validation Stage ==> Epoch: 552 / 99999 | Validation loss: 30.92728 |  Validation Accuracy: 4.72491 | Validation Metric (MAE)): 4.72491\n",
      "Load Model from best epoch 552\n",
      "Training Stage ==> Epoch: 553 / 99999 | Training loss: 30.45576 |  Training Accuracy: 4.69942 | Training Metric (MAE): 4.69942\n",
      "Validation Stage ==> Epoch: 553 / 99999 | Validation loss: 30.92413 |  Validation Accuracy: 4.72458 | Validation Metric (MAE)): 4.72458\n",
      "Load Model from best epoch 553\n",
      "Training Stage ==> Epoch: 554 / 99999 | Training loss: 29.32756 |  Training Accuracy: 4.70028 | Training Metric (MAE): 4.70028\n",
      "Validation Stage ==> Epoch: 554 / 99999 | Validation loss: 30.92098 |  Validation Accuracy: 4.72425 | Validation Metric (MAE)): 4.72425\n",
      "Load Model from best epoch 554\n",
      "Training Stage ==> Epoch: 555 / 99999 | Training loss: 29.49195 |  Training Accuracy: 4.70685 | Training Metric (MAE): 4.70685\n",
      "Validation Stage ==> Epoch: 555 / 99999 | Validation loss: 30.91783 |  Validation Accuracy: 4.72392 | Validation Metric (MAE)): 4.72392\n",
      "Load Model from best epoch 555\n",
      "Training Stage ==> Epoch: 556 / 99999 | Training loss: 29.94486 |  Training Accuracy: 4.70400 | Training Metric (MAE): 4.70400\n",
      "Validation Stage ==> Epoch: 556 / 99999 | Validation loss: 30.91467 |  Validation Accuracy: 4.72359 | Validation Metric (MAE)): 4.72359\n",
      "Load Model from best epoch 556\n",
      "Training Stage ==> Epoch: 557 / 99999 | Training loss: 28.59578 |  Training Accuracy: 4.70004 | Training Metric (MAE): 4.70004\n",
      "Validation Stage ==> Epoch: 557 / 99999 | Validation loss: 30.91153 |  Validation Accuracy: 4.72326 | Validation Metric (MAE)): 4.72326\n",
      "Load Model from best epoch 557\n",
      "Training Stage ==> Epoch: 558 / 99999 | Training loss: 30.11850 |  Training Accuracy: 4.70296 | Training Metric (MAE): 4.70296\n",
      "Validation Stage ==> Epoch: 558 / 99999 | Validation loss: 30.90838 |  Validation Accuracy: 4.72293 | Validation Metric (MAE)): 4.72293\n",
      "Load Model from best epoch 558\n",
      "Training Stage ==> Epoch: 559 / 99999 | Training loss: 29.14860 |  Training Accuracy: 4.70406 | Training Metric (MAE): 4.70406\n",
      "Validation Stage ==> Epoch: 559 / 99999 | Validation loss: 30.90523 |  Validation Accuracy: 4.72259 | Validation Metric (MAE)): 4.72259\n",
      "Load Model from best epoch 559\n",
      "Training Stage ==> Epoch: 560 / 99999 | Training loss: 29.26783 |  Training Accuracy: 4.70340 | Training Metric (MAE): 4.70340\n",
      "Validation Stage ==> Epoch: 560 / 99999 | Validation loss: 30.90207 |  Validation Accuracy: 4.72226 | Validation Metric (MAE)): 4.72226\n",
      "Load Model from best epoch 560\n",
      "Training Stage ==> Epoch: 561 / 99999 | Training loss: 30.54279 |  Training Accuracy: 4.70469 | Training Metric (MAE): 4.70469\n",
      "Validation Stage ==> Epoch: 561 / 99999 | Validation loss: 30.89893 |  Validation Accuracy: 4.72193 | Validation Metric (MAE)): 4.72193\n",
      "Load Model from best epoch 561\n",
      "Training Stage ==> Epoch: 562 / 99999 | Training loss: 29.74325 |  Training Accuracy: 4.69823 | Training Metric (MAE): 4.69823\n",
      "Validation Stage ==> Epoch: 562 / 99999 | Validation loss: 30.89579 |  Validation Accuracy: 4.72160 | Validation Metric (MAE)): 4.72160\n",
      "Load Model from best epoch 562\n",
      "Training Stage ==> Epoch: 563 / 99999 | Training loss: 29.49459 |  Training Accuracy: 4.70789 | Training Metric (MAE): 4.70789\n",
      "Validation Stage ==> Epoch: 563 / 99999 | Validation loss: 30.89264 |  Validation Accuracy: 4.72127 | Validation Metric (MAE)): 4.72127\n",
      "Load Model from best epoch 563\n",
      "Training Stage ==> Epoch: 564 / 99999 | Training loss: 31.77626 |  Training Accuracy: 4.69857 | Training Metric (MAE): 4.69857\n",
      "Validation Stage ==> Epoch: 564 / 99999 | Validation loss: 30.88948 |  Validation Accuracy: 4.72094 | Validation Metric (MAE)): 4.72094\n",
      "Load Model from best epoch 564\n",
      "Training Stage ==> Epoch: 565 / 99999 | Training loss: 30.66410 |  Training Accuracy: 4.69813 | Training Metric (MAE): 4.69813\n",
      "Validation Stage ==> Epoch: 565 / 99999 | Validation loss: 30.88634 |  Validation Accuracy: 4.72061 | Validation Metric (MAE)): 4.72061\n",
      "Load Model from best epoch 565\n",
      "Training Stage ==> Epoch: 566 / 99999 | Training loss: 29.88891 |  Training Accuracy: 4.70334 | Training Metric (MAE): 4.70334\n",
      "Validation Stage ==> Epoch: 566 / 99999 | Validation loss: 30.88320 |  Validation Accuracy: 4.72028 | Validation Metric (MAE)): 4.72028\n",
      "Load Model from best epoch 566\n",
      "Training Stage ==> Epoch: 567 / 99999 | Training loss: 30.49640 |  Training Accuracy: 4.69960 | Training Metric (MAE): 4.69960\n",
      "Validation Stage ==> Epoch: 567 / 99999 | Validation loss: 30.88005 |  Validation Accuracy: 4.71994 | Validation Metric (MAE)): 4.71994\n",
      "Load Model from best epoch 567\n",
      "Training Stage ==> Epoch: 568 / 99999 | Training loss: 32.65047 |  Training Accuracy: 4.68609 | Training Metric (MAE): 4.68609\n",
      "Validation Stage ==> Epoch: 568 / 99999 | Validation loss: 30.87690 |  Validation Accuracy: 4.71961 | Validation Metric (MAE)): 4.71961\n",
      "Load Model from best epoch 568\n",
      "Training Stage ==> Epoch: 569 / 99999 | Training loss: 30.40741 |  Training Accuracy: 4.69879 | Training Metric (MAE): 4.69879\n",
      "Validation Stage ==> Epoch: 569 / 99999 | Validation loss: 30.87375 |  Validation Accuracy: 4.71928 | Validation Metric (MAE)): 4.71928\n",
      "Load Model from best epoch 569\n",
      "Training Stage ==> Epoch: 570 / 99999 | Training loss: 30.50204 |  Training Accuracy: 4.69111 | Training Metric (MAE): 4.69111\n",
      "Validation Stage ==> Epoch: 570 / 99999 | Validation loss: 30.87061 |  Validation Accuracy: 4.71895 | Validation Metric (MAE)): 4.71895\n",
      "Load Model from best epoch 570\n",
      "Training Stage ==> Epoch: 571 / 99999 | Training loss: 29.60922 |  Training Accuracy: 4.69985 | Training Metric (MAE): 4.69985\n",
      "Validation Stage ==> Epoch: 571 / 99999 | Validation loss: 30.86747 |  Validation Accuracy: 4.71862 | Validation Metric (MAE)): 4.71862\n",
      "Load Model from best epoch 571\n",
      "Training Stage ==> Epoch: 572 / 99999 | Training loss: 29.87727 |  Training Accuracy: 4.69405 | Training Metric (MAE): 4.69405\n",
      "Validation Stage ==> Epoch: 572 / 99999 | Validation loss: 30.86433 |  Validation Accuracy: 4.71829 | Validation Metric (MAE)): 4.71829\n",
      "Load Model from best epoch 572\n",
      "Training Stage ==> Epoch: 573 / 99999 | Training loss: 28.99106 |  Training Accuracy: 4.69790 | Training Metric (MAE): 4.69790\n",
      "Validation Stage ==> Epoch: 573 / 99999 | Validation loss: 30.86120 |  Validation Accuracy: 4.71796 | Validation Metric (MAE)): 4.71796\n",
      "Load Model from best epoch 573\n",
      "Training Stage ==> Epoch: 574 / 99999 | Training loss: 29.06734 |  Training Accuracy: 4.70676 | Training Metric (MAE): 4.70676\n",
      "Validation Stage ==> Epoch: 574 / 99999 | Validation loss: 30.85805 |  Validation Accuracy: 4.71763 | Validation Metric (MAE)): 4.71763\n",
      "Load Model from best epoch 574\n",
      "Training Stage ==> Epoch: 575 / 99999 | Training loss: 30.89035 |  Training Accuracy: 4.68140 | Training Metric (MAE): 4.68140\n",
      "Validation Stage ==> Epoch: 575 / 99999 | Validation loss: 30.85491 |  Validation Accuracy: 4.71730 | Validation Metric (MAE)): 4.71730\n",
      "Load Model from best epoch 575\n",
      "Training Stage ==> Epoch: 576 / 99999 | Training loss: 32.32558 |  Training Accuracy: 4.68718 | Training Metric (MAE): 4.68718\n",
      "Validation Stage ==> Epoch: 576 / 99999 | Validation loss: 30.85178 |  Validation Accuracy: 4.71697 | Validation Metric (MAE)): 4.71697\n",
      "Load Model from best epoch 576\n",
      "Training Stage ==> Epoch: 577 / 99999 | Training loss: 30.96634 |  Training Accuracy: 4.71352 | Training Metric (MAE): 4.71352\n",
      "Validation Stage ==> Epoch: 577 / 99999 | Validation loss: 30.84864 |  Validation Accuracy: 4.71664 | Validation Metric (MAE)): 4.71664\n",
      "Load Model from best epoch 577\n",
      "Training Stage ==> Epoch: 578 / 99999 | Training loss: 30.54175 |  Training Accuracy: 4.68677 | Training Metric (MAE): 4.68677\n",
      "Validation Stage ==> Epoch: 578 / 99999 | Validation loss: 30.84551 |  Validation Accuracy: 4.71631 | Validation Metric (MAE)): 4.71631\n",
      "Load Model from best epoch 578\n",
      "Training Stage ==> Epoch: 579 / 99999 | Training loss: 29.00045 |  Training Accuracy: 4.68456 | Training Metric (MAE): 4.68456\n",
      "Validation Stage ==> Epoch: 579 / 99999 | Validation loss: 30.84237 |  Validation Accuracy: 4.71598 | Validation Metric (MAE)): 4.71598\n",
      "Load Model from best epoch 579\n",
      "Training Stage ==> Epoch: 580 / 99999 | Training loss: 29.48329 |  Training Accuracy: 4.68915 | Training Metric (MAE): 4.68915\n",
      "Validation Stage ==> Epoch: 580 / 99999 | Validation loss: 30.83924 |  Validation Accuracy: 4.71565 | Validation Metric (MAE)): 4.71565\n",
      "Load Model from best epoch 580\n",
      "Training Stage ==> Epoch: 581 / 99999 | Training loss: 28.49099 |  Training Accuracy: 4.69123 | Training Metric (MAE): 4.69123\n",
      "Validation Stage ==> Epoch: 581 / 99999 | Validation loss: 30.83610 |  Validation Accuracy: 4.71532 | Validation Metric (MAE)): 4.71532\n",
      "Load Model from best epoch 581\n",
      "Training Stage ==> Epoch: 582 / 99999 | Training loss: 29.26880 |  Training Accuracy: 4.69628 | Training Metric (MAE): 4.69628\n",
      "Validation Stage ==> Epoch: 582 / 99999 | Validation loss: 30.83296 |  Validation Accuracy: 4.71499 | Validation Metric (MAE)): 4.71499\n",
      "Load Model from best epoch 582\n",
      "Training Stage ==> Epoch: 583 / 99999 | Training loss: 30.71995 |  Training Accuracy: 4.70017 | Training Metric (MAE): 4.70017\n",
      "Validation Stage ==> Epoch: 583 / 99999 | Validation loss: 30.82982 |  Validation Accuracy: 4.71466 | Validation Metric (MAE)): 4.71466\n",
      "Load Model from best epoch 583\n",
      "Training Stage ==> Epoch: 584 / 99999 | Training loss: 30.02240 |  Training Accuracy: 4.68948 | Training Metric (MAE): 4.68948\n",
      "Validation Stage ==> Epoch: 584 / 99999 | Validation loss: 30.82669 |  Validation Accuracy: 4.71433 | Validation Metric (MAE)): 4.71433\n",
      "Load Model from best epoch 584\n",
      "Training Stage ==> Epoch: 585 / 99999 | Training loss: 31.02830 |  Training Accuracy: 4.69429 | Training Metric (MAE): 4.69429\n",
      "Validation Stage ==> Epoch: 585 / 99999 | Validation loss: 30.82357 |  Validation Accuracy: 4.71400 | Validation Metric (MAE)): 4.71400\n",
      "Load Model from best epoch 585\n",
      "Training Stage ==> Epoch: 586 / 99999 | Training loss: 31.09223 |  Training Accuracy: 4.68035 | Training Metric (MAE): 4.68035\n",
      "Validation Stage ==> Epoch: 586 / 99999 | Validation loss: 30.82044 |  Validation Accuracy: 4.71367 | Validation Metric (MAE)): 4.71367\n",
      "Load Model from best epoch 586\n",
      "Training Stage ==> Epoch: 587 / 99999 | Training loss: 30.25642 |  Training Accuracy: 4.69851 | Training Metric (MAE): 4.69851\n",
      "Validation Stage ==> Epoch: 587 / 99999 | Validation loss: 30.81731 |  Validation Accuracy: 4.71334 | Validation Metric (MAE)): 4.71334\n",
      "Load Model from best epoch 587\n",
      "Training Stage ==> Epoch: 588 / 99999 | Training loss: 29.98901 |  Training Accuracy: 4.70810 | Training Metric (MAE): 4.70810\n",
      "Validation Stage ==> Epoch: 588 / 99999 | Validation loss: 30.81417 |  Validation Accuracy: 4.71301 | Validation Metric (MAE)): 4.71301\n",
      "Load Model from best epoch 588\n",
      "Training Stage ==> Epoch: 589 / 99999 | Training loss: 29.45011 |  Training Accuracy: 4.69858 | Training Metric (MAE): 4.69858\n",
      "Validation Stage ==> Epoch: 589 / 99999 | Validation loss: 30.81104 |  Validation Accuracy: 4.71268 | Validation Metric (MAE)): 4.71268\n",
      "Load Model from best epoch 589\n",
      "Training Stage ==> Epoch: 590 / 99999 | Training loss: 28.84592 |  Training Accuracy: 4.70624 | Training Metric (MAE): 4.70624\n",
      "Validation Stage ==> Epoch: 590 / 99999 | Validation loss: 30.80792 |  Validation Accuracy: 4.71235 | Validation Metric (MAE)): 4.71235\n",
      "Load Model from best epoch 590\n",
      "Training Stage ==> Epoch: 591 / 99999 | Training loss: 30.01334 |  Training Accuracy: 4.68691 | Training Metric (MAE): 4.68691\n",
      "Validation Stage ==> Epoch: 591 / 99999 | Validation loss: 30.80479 |  Validation Accuracy: 4.71202 | Validation Metric (MAE)): 4.71202\n",
      "Load Model from best epoch 591\n",
      "Training Stage ==> Epoch: 592 / 99999 | Training loss: 29.67479 |  Training Accuracy: 4.68869 | Training Metric (MAE): 4.68869\n",
      "Validation Stage ==> Epoch: 592 / 99999 | Validation loss: 30.80166 |  Validation Accuracy: 4.71169 | Validation Metric (MAE)): 4.71169\n",
      "Load Model from best epoch 592\n",
      "Training Stage ==> Epoch: 593 / 99999 | Training loss: 29.77374 |  Training Accuracy: 4.67991 | Training Metric (MAE): 4.67991\n",
      "Validation Stage ==> Epoch: 593 / 99999 | Validation loss: 30.79853 |  Validation Accuracy: 4.71136 | Validation Metric (MAE)): 4.71136\n",
      "Load Model from best epoch 593\n",
      "Training Stage ==> Epoch: 594 / 99999 | Training loss: 28.95906 |  Training Accuracy: 4.68106 | Training Metric (MAE): 4.68106\n",
      "Validation Stage ==> Epoch: 594 / 99999 | Validation loss: 30.79541 |  Validation Accuracy: 4.71103 | Validation Metric (MAE)): 4.71103\n",
      "Load Model from best epoch 594\n",
      "Training Stage ==> Epoch: 595 / 99999 | Training loss: 31.00041 |  Training Accuracy: 4.67736 | Training Metric (MAE): 4.67736\n",
      "Validation Stage ==> Epoch: 595 / 99999 | Validation loss: 30.79228 |  Validation Accuracy: 4.71070 | Validation Metric (MAE)): 4.71070\n",
      "Load Model from best epoch 595\n",
      "Training Stage ==> Epoch: 596 / 99999 | Training loss: 29.58437 |  Training Accuracy: 4.68695 | Training Metric (MAE): 4.68695\n",
      "Validation Stage ==> Epoch: 596 / 99999 | Validation loss: 30.78915 |  Validation Accuracy: 4.71037 | Validation Metric (MAE)): 4.71037\n",
      "Load Model from best epoch 596\n",
      "Training Stage ==> Epoch: 597 / 99999 | Training loss: 28.79483 |  Training Accuracy: 4.68307 | Training Metric (MAE): 4.68307\n",
      "Validation Stage ==> Epoch: 597 / 99999 | Validation loss: 30.78602 |  Validation Accuracy: 4.71004 | Validation Metric (MAE)): 4.71004\n",
      "Load Model from best epoch 597\n",
      "Training Stage ==> Epoch: 598 / 99999 | Training loss: 30.44036 |  Training Accuracy: 4.68841 | Training Metric (MAE): 4.68841\n",
      "Validation Stage ==> Epoch: 598 / 99999 | Validation loss: 30.78290 |  Validation Accuracy: 4.70971 | Validation Metric (MAE)): 4.70971\n",
      "Load Model from best epoch 598\n",
      "Training Stage ==> Epoch: 599 / 99999 | Training loss: 30.87651 |  Training Accuracy: 4.67515 | Training Metric (MAE): 4.67515\n",
      "Validation Stage ==> Epoch: 599 / 99999 | Validation loss: 30.77978 |  Validation Accuracy: 4.70938 | Validation Metric (MAE)): 4.70938\n",
      "Load Model from best epoch 599\n",
      "Training Stage ==> Epoch: 600 / 99999 | Training loss: 28.46366 |  Training Accuracy: 4.69070 | Training Metric (MAE): 4.69070\n",
      "Validation Stage ==> Epoch: 600 / 99999 | Validation loss: 30.77666 |  Validation Accuracy: 4.70905 | Validation Metric (MAE)): 4.70905\n",
      "Load Model from best epoch 600\n",
      "Training Stage ==> Epoch: 601 / 99999 | Training loss: 30.71149 |  Training Accuracy: 4.68283 | Training Metric (MAE): 4.68283\n",
      "Validation Stage ==> Epoch: 601 / 99999 | Validation loss: 30.77353 |  Validation Accuracy: 4.70872 | Validation Metric (MAE)): 4.70872\n",
      "Load Model from best epoch 601\n",
      "Training Stage ==> Epoch: 602 / 99999 | Training loss: 31.67537 |  Training Accuracy: 4.69383 | Training Metric (MAE): 4.69383\n",
      "Validation Stage ==> Epoch: 602 / 99999 | Validation loss: 30.77042 |  Validation Accuracy: 4.70839 | Validation Metric (MAE)): 4.70839\n",
      "Load Model from best epoch 602\n",
      "Training Stage ==> Epoch: 603 / 99999 | Training loss: 30.58767 |  Training Accuracy: 4.68481 | Training Metric (MAE): 4.68481\n",
      "Validation Stage ==> Epoch: 603 / 99999 | Validation loss: 30.76728 |  Validation Accuracy: 4.70806 | Validation Metric (MAE)): 4.70806\n",
      "Load Model from best epoch 603\n",
      "Training Stage ==> Epoch: 604 / 99999 | Training loss: 31.51050 |  Training Accuracy: 4.69740 | Training Metric (MAE): 4.69740\n",
      "Validation Stage ==> Epoch: 604 / 99999 | Validation loss: 30.76416 |  Validation Accuracy: 4.70773 | Validation Metric (MAE)): 4.70773\n",
      "Load Model from best epoch 604\n",
      "Training Stage ==> Epoch: 605 / 99999 | Training loss: 31.29031 |  Training Accuracy: 4.68690 | Training Metric (MAE): 4.68690\n",
      "Validation Stage ==> Epoch: 605 / 99999 | Validation loss: 30.76104 |  Validation Accuracy: 4.70740 | Validation Metric (MAE)): 4.70740\n",
      "Load Model from best epoch 605\n",
      "Training Stage ==> Epoch: 606 / 99999 | Training loss: 29.98482 |  Training Accuracy: 4.68571 | Training Metric (MAE): 4.68571\n",
      "Validation Stage ==> Epoch: 606 / 99999 | Validation loss: 30.75792 |  Validation Accuracy: 4.70707 | Validation Metric (MAE)): 4.70707\n",
      "Load Model from best epoch 606\n",
      "Training Stage ==> Epoch: 607 / 99999 | Training loss: 29.85927 |  Training Accuracy: 4.67650 | Training Metric (MAE): 4.67650\n",
      "Validation Stage ==> Epoch: 607 / 99999 | Validation loss: 30.75480 |  Validation Accuracy: 4.70674 | Validation Metric (MAE)): 4.70674\n",
      "Load Model from best epoch 607\n",
      "Training Stage ==> Epoch: 608 / 99999 | Training loss: 29.40370 |  Training Accuracy: 4.70121 | Training Metric (MAE): 4.70121\n",
      "Validation Stage ==> Epoch: 608 / 99999 | Validation loss: 30.75169 |  Validation Accuracy: 4.70642 | Validation Metric (MAE)): 4.70642\n",
      "Load Model from best epoch 608\n",
      "Training Stage ==> Epoch: 609 / 99999 | Training loss: 29.96919 |  Training Accuracy: 4.68473 | Training Metric (MAE): 4.68473\n",
      "Validation Stage ==> Epoch: 609 / 99999 | Validation loss: 30.74857 |  Validation Accuracy: 4.70609 | Validation Metric (MAE)): 4.70609\n",
      "Load Model from best epoch 609\n",
      "Training Stage ==> Epoch: 610 / 99999 | Training loss: 28.66655 |  Training Accuracy: 4.69064 | Training Metric (MAE): 4.69064\n",
      "Validation Stage ==> Epoch: 610 / 99999 | Validation loss: 30.74545 |  Validation Accuracy: 4.70576 | Validation Metric (MAE)): 4.70576\n",
      "Load Model from best epoch 610\n",
      "Training Stage ==> Epoch: 611 / 99999 | Training loss: 29.33392 |  Training Accuracy: 4.68381 | Training Metric (MAE): 4.68381\n",
      "Validation Stage ==> Epoch: 611 / 99999 | Validation loss: 30.74234 |  Validation Accuracy: 4.70543 | Validation Metric (MAE)): 4.70543\n",
      "Load Model from best epoch 611\n",
      "Training Stage ==> Epoch: 612 / 99999 | Training loss: 28.18079 |  Training Accuracy: 4.68897 | Training Metric (MAE): 4.68897\n",
      "Validation Stage ==> Epoch: 612 / 99999 | Validation loss: 30.73922 |  Validation Accuracy: 4.70510 | Validation Metric (MAE)): 4.70510\n",
      "Load Model from best epoch 612\n",
      "Training Stage ==> Epoch: 613 / 99999 | Training loss: 29.06095 |  Training Accuracy: 4.69596 | Training Metric (MAE): 4.69596\n",
      "Validation Stage ==> Epoch: 613 / 99999 | Validation loss: 30.73611 |  Validation Accuracy: 4.70477 | Validation Metric (MAE)): 4.70477\n",
      "Load Model from best epoch 613\n",
      "Training Stage ==> Epoch: 614 / 99999 | Training loss: 31.98988 |  Training Accuracy: 4.67954 | Training Metric (MAE): 4.67954\n",
      "Validation Stage ==> Epoch: 614 / 99999 | Validation loss: 30.73298 |  Validation Accuracy: 4.70444 | Validation Metric (MAE)): 4.70444\n",
      "Load Model from best epoch 614\n",
      "Training Stage ==> Epoch: 615 / 99999 | Training loss: 31.38227 |  Training Accuracy: 4.68209 | Training Metric (MAE): 4.68209\n",
      "Validation Stage ==> Epoch: 615 / 99999 | Validation loss: 30.72986 |  Validation Accuracy: 4.70411 | Validation Metric (MAE)): 4.70411\n",
      "Load Model from best epoch 615\n",
      "Training Stage ==> Epoch: 616 / 99999 | Training loss: 28.22734 |  Training Accuracy: 4.68005 | Training Metric (MAE): 4.68005\n",
      "Validation Stage ==> Epoch: 616 / 99999 | Validation loss: 30.72676 |  Validation Accuracy: 4.70378 | Validation Metric (MAE)): 4.70378\n",
      "Load Model from best epoch 616\n",
      "Training Stage ==> Epoch: 617 / 99999 | Training loss: 29.94829 |  Training Accuracy: 4.68402 | Training Metric (MAE): 4.68402\n",
      "Validation Stage ==> Epoch: 617 / 99999 | Validation loss: 30.72365 |  Validation Accuracy: 4.70346 | Validation Metric (MAE)): 4.70346\n",
      "Load Model from best epoch 617\n",
      "Training Stage ==> Epoch: 618 / 99999 | Training loss: 29.71414 |  Training Accuracy: 4.68001 | Training Metric (MAE): 4.68001\n",
      "Validation Stage ==> Epoch: 618 / 99999 | Validation loss: 30.72054 |  Validation Accuracy: 4.70313 | Validation Metric (MAE)): 4.70313\n",
      "Load Model from best epoch 618\n",
      "Training Stage ==> Epoch: 619 / 99999 | Training loss: 30.60739 |  Training Accuracy: 4.69136 | Training Metric (MAE): 4.69136\n",
      "Validation Stage ==> Epoch: 619 / 99999 | Validation loss: 30.71742 |  Validation Accuracy: 4.70280 | Validation Metric (MAE)): 4.70280\n",
      "Load Model from best epoch 619\n",
      "Training Stage ==> Epoch: 620 / 99999 | Training loss: 30.52909 |  Training Accuracy: 4.68635 | Training Metric (MAE): 4.68635\n",
      "Validation Stage ==> Epoch: 620 / 99999 | Validation loss: 30.71431 |  Validation Accuracy: 4.70247 | Validation Metric (MAE)): 4.70247\n",
      "Load Model from best epoch 620\n",
      "Training Stage ==> Epoch: 621 / 99999 | Training loss: 31.35506 |  Training Accuracy: 4.68307 | Training Metric (MAE): 4.68307\n",
      "Validation Stage ==> Epoch: 621 / 99999 | Validation loss: 30.71120 |  Validation Accuracy: 4.70214 | Validation Metric (MAE)): 4.70214\n",
      "Load Model from best epoch 621\n",
      "Training Stage ==> Epoch: 622 / 99999 | Training loss: 29.46234 |  Training Accuracy: 4.67652 | Training Metric (MAE): 4.67652\n",
      "Validation Stage ==> Epoch: 622 / 99999 | Validation loss: 30.70810 |  Validation Accuracy: 4.70181 | Validation Metric (MAE)): 4.70181\n",
      "Load Model from best epoch 622\n",
      "Training Stage ==> Epoch: 623 / 99999 | Training loss: 29.41293 |  Training Accuracy: 4.69721 | Training Metric (MAE): 4.69721\n",
      "Validation Stage ==> Epoch: 623 / 99999 | Validation loss: 30.70499 |  Validation Accuracy: 4.70148 | Validation Metric (MAE)): 4.70148\n",
      "Load Model from best epoch 623\n",
      "Training Stage ==> Epoch: 624 / 99999 | Training loss: 30.06341 |  Training Accuracy: 4.67599 | Training Metric (MAE): 4.67599\n",
      "Validation Stage ==> Epoch: 624 / 99999 | Validation loss: 30.70188 |  Validation Accuracy: 4.70116 | Validation Metric (MAE)): 4.70116\n",
      "Load Model from best epoch 624\n",
      "Training Stage ==> Epoch: 625 / 99999 | Training loss: 30.52338 |  Training Accuracy: 4.66914 | Training Metric (MAE): 4.66914\n",
      "Validation Stage ==> Epoch: 625 / 99999 | Validation loss: 30.69877 |  Validation Accuracy: 4.70083 | Validation Metric (MAE)): 4.70083\n",
      "Load Model from best epoch 625\n",
      "Training Stage ==> Epoch: 626 / 99999 | Training loss: 29.84734 |  Training Accuracy: 4.66908 | Training Metric (MAE): 4.66908\n",
      "Validation Stage ==> Epoch: 626 / 99999 | Validation loss: 30.69566 |  Validation Accuracy: 4.70050 | Validation Metric (MAE)): 4.70050\n",
      "Load Model from best epoch 626\n",
      "Training Stage ==> Epoch: 627 / 99999 | Training loss: 30.71932 |  Training Accuracy: 4.69478 | Training Metric (MAE): 4.69478\n",
      "Validation Stage ==> Epoch: 627 / 99999 | Validation loss: 30.69255 |  Validation Accuracy: 4.70017 | Validation Metric (MAE)): 4.70017\n",
      "Load Model from best epoch 627\n",
      "Training Stage ==> Epoch: 628 / 99999 | Training loss: 29.23993 |  Training Accuracy: 4.68139 | Training Metric (MAE): 4.68139\n",
      "Validation Stage ==> Epoch: 628 / 99999 | Validation loss: 30.68945 |  Validation Accuracy: 4.69984 | Validation Metric (MAE)): 4.69984\n",
      "Load Model from best epoch 628\n",
      "Training Stage ==> Epoch: 629 / 99999 | Training loss: 29.65604 |  Training Accuracy: 4.68011 | Training Metric (MAE): 4.68011\n",
      "Validation Stage ==> Epoch: 629 / 99999 | Validation loss: 30.68633 |  Validation Accuracy: 4.69951 | Validation Metric (MAE)): 4.69951\n",
      "Load Model from best epoch 629\n",
      "Training Stage ==> Epoch: 630 / 99999 | Training loss: 29.99134 |  Training Accuracy: 4.67425 | Training Metric (MAE): 4.67425\n",
      "Validation Stage ==> Epoch: 630 / 99999 | Validation loss: 30.68323 |  Validation Accuracy: 4.69918 | Validation Metric (MAE)): 4.69918\n",
      "Load Model from best epoch 630\n",
      "Training Stage ==> Epoch: 631 / 99999 | Training loss: 30.93029 |  Training Accuracy: 4.68555 | Training Metric (MAE): 4.68555\n",
      "Validation Stage ==> Epoch: 631 / 99999 | Validation loss: 30.68012 |  Validation Accuracy: 4.69885 | Validation Metric (MAE)): 4.69885\n",
      "Load Model from best epoch 631\n",
      "Training Stage ==> Epoch: 632 / 99999 | Training loss: 30.39991 |  Training Accuracy: 4.67725 | Training Metric (MAE): 4.67725\n",
      "Validation Stage ==> Epoch: 632 / 99999 | Validation loss: 30.67701 |  Validation Accuracy: 4.69853 | Validation Metric (MAE)): 4.69853\n",
      "Load Model from best epoch 632\n",
      "Training Stage ==> Epoch: 633 / 99999 | Training loss: 29.30369 |  Training Accuracy: 4.68521 | Training Metric (MAE): 4.68521\n",
      "Validation Stage ==> Epoch: 633 / 99999 | Validation loss: 30.67392 |  Validation Accuracy: 4.69820 | Validation Metric (MAE)): 4.69820\n",
      "Load Model from best epoch 633\n",
      "Training Stage ==> Epoch: 634 / 99999 | Training loss: 29.94201 |  Training Accuracy: 4.68455 | Training Metric (MAE): 4.68455\n",
      "Validation Stage ==> Epoch: 634 / 99999 | Validation loss: 30.67081 |  Validation Accuracy: 4.69787 | Validation Metric (MAE)): 4.69787\n",
      "Load Model from best epoch 634\n",
      "Training Stage ==> Epoch: 635 / 99999 | Training loss: 30.49441 |  Training Accuracy: 4.66913 | Training Metric (MAE): 4.66913\n",
      "Validation Stage ==> Epoch: 635 / 99999 | Validation loss: 30.66770 |  Validation Accuracy: 4.69754 | Validation Metric (MAE)): 4.69754\n",
      "Load Model from best epoch 635\n",
      "Training Stage ==> Epoch: 636 / 99999 | Training loss: 29.13762 |  Training Accuracy: 4.68350 | Training Metric (MAE): 4.68350\n",
      "Validation Stage ==> Epoch: 636 / 99999 | Validation loss: 30.66460 |  Validation Accuracy: 4.69721 | Validation Metric (MAE)): 4.69721\n",
      "Load Model from best epoch 636\n",
      "Training Stage ==> Epoch: 637 / 99999 | Training loss: 29.47298 |  Training Accuracy: 4.66213 | Training Metric (MAE): 4.66213\n",
      "Validation Stage ==> Epoch: 637 / 99999 | Validation loss: 30.66150 |  Validation Accuracy: 4.69689 | Validation Metric (MAE)): 4.69689\n",
      "Load Model from best epoch 637\n",
      "Training Stage ==> Epoch: 638 / 99999 | Training loss: 30.55061 |  Training Accuracy: 4.68328 | Training Metric (MAE): 4.68328\n",
      "Validation Stage ==> Epoch: 638 / 99999 | Validation loss: 30.65841 |  Validation Accuracy: 4.69656 | Validation Metric (MAE)): 4.69656\n",
      "Load Model from best epoch 638\n",
      "Training Stage ==> Epoch: 639 / 99999 | Training loss: 30.44006 |  Training Accuracy: 4.66546 | Training Metric (MAE): 4.66546\n",
      "Validation Stage ==> Epoch: 639 / 99999 | Validation loss: 30.65531 |  Validation Accuracy: 4.69623 | Validation Metric (MAE)): 4.69623\n",
      "Load Model from best epoch 639\n",
      "Training Stage ==> Epoch: 640 / 99999 | Training loss: 29.08437 |  Training Accuracy: 4.67023 | Training Metric (MAE): 4.67023\n",
      "Validation Stage ==> Epoch: 640 / 99999 | Validation loss: 30.65221 |  Validation Accuracy: 4.69590 | Validation Metric (MAE)): 4.69590\n",
      "Load Model from best epoch 640\n",
      "Training Stage ==> Epoch: 641 / 99999 | Training loss: 30.12103 |  Training Accuracy: 4.67646 | Training Metric (MAE): 4.67646\n",
      "Validation Stage ==> Epoch: 641 / 99999 | Validation loss: 30.64912 |  Validation Accuracy: 4.69558 | Validation Metric (MAE)): 4.69558\n",
      "Load Model from best epoch 641\n",
      "Training Stage ==> Epoch: 642 / 99999 | Training loss: 30.52131 |  Training Accuracy: 4.67962 | Training Metric (MAE): 4.67962\n",
      "Validation Stage ==> Epoch: 642 / 99999 | Validation loss: 30.64601 |  Validation Accuracy: 4.69525 | Validation Metric (MAE)): 4.69525\n",
      "Load Model from best epoch 642\n",
      "Training Stage ==> Epoch: 643 / 99999 | Training loss: 30.84796 |  Training Accuracy: 4.67170 | Training Metric (MAE): 4.67170\n",
      "Validation Stage ==> Epoch: 643 / 99999 | Validation loss: 30.64290 |  Validation Accuracy: 4.69492 | Validation Metric (MAE)): 4.69492\n",
      "Load Model from best epoch 643\n",
      "Training Stage ==> Epoch: 644 / 99999 | Training loss: 31.40626 |  Training Accuracy: 4.67140 | Training Metric (MAE): 4.67140\n",
      "Validation Stage ==> Epoch: 644 / 99999 | Validation loss: 30.63981 |  Validation Accuracy: 4.69459 | Validation Metric (MAE)): 4.69459\n",
      "Load Model from best epoch 644\n",
      "Training Stage ==> Epoch: 645 / 99999 | Training loss: 29.22450 |  Training Accuracy: 4.67904 | Training Metric (MAE): 4.67904\n",
      "Validation Stage ==> Epoch: 645 / 99999 | Validation loss: 30.63672 |  Validation Accuracy: 4.69426 | Validation Metric (MAE)): 4.69426\n",
      "Load Model from best epoch 645\n",
      "Training Stage ==> Epoch: 646 / 99999 | Training loss: 27.45923 |  Training Accuracy: 4.66944 | Training Metric (MAE): 4.66944\n",
      "Validation Stage ==> Epoch: 646 / 99999 | Validation loss: 30.63363 |  Validation Accuracy: 4.69394 | Validation Metric (MAE)): 4.69394\n",
      "Load Model from best epoch 646\n",
      "Training Stage ==> Epoch: 647 / 99999 | Training loss: 27.75041 |  Training Accuracy: 4.68557 | Training Metric (MAE): 4.68557\n",
      "Validation Stage ==> Epoch: 647 / 99999 | Validation loss: 30.63053 |  Validation Accuracy: 4.69361 | Validation Metric (MAE)): 4.69361\n",
      "Load Model from best epoch 647\n",
      "Training Stage ==> Epoch: 648 / 99999 | Training loss: 31.16455 |  Training Accuracy: 4.66430 | Training Metric (MAE): 4.66430\n",
      "Validation Stage ==> Epoch: 648 / 99999 | Validation loss: 30.62743 |  Validation Accuracy: 4.69328 | Validation Metric (MAE)): 4.69328\n",
      "Load Model from best epoch 648\n",
      "Training Stage ==> Epoch: 649 / 99999 | Training loss: 29.28130 |  Training Accuracy: 4.67413 | Training Metric (MAE): 4.67413\n",
      "Validation Stage ==> Epoch: 649 / 99999 | Validation loss: 30.62434 |  Validation Accuracy: 4.69295 | Validation Metric (MAE)): 4.69295\n",
      "Load Model from best epoch 649\n",
      "Training Stage ==> Epoch: 650 / 99999 | Training loss: 27.35695 |  Training Accuracy: 4.68176 | Training Metric (MAE): 4.68176\n",
      "Validation Stage ==> Epoch: 650 / 99999 | Validation loss: 30.62126 |  Validation Accuracy: 4.69263 | Validation Metric (MAE)): 4.69263\n",
      "Load Model from best epoch 650\n",
      "Training Stage ==> Epoch: 651 / 99999 | Training loss: 30.38698 |  Training Accuracy: 4.68205 | Training Metric (MAE): 4.68205\n",
      "Validation Stage ==> Epoch: 651 / 99999 | Validation loss: 30.61816 |  Validation Accuracy: 4.69230 | Validation Metric (MAE)): 4.69230\n",
      "Load Model from best epoch 651\n",
      "Training Stage ==> Epoch: 652 / 99999 | Training loss: 29.70065 |  Training Accuracy: 4.66641 | Training Metric (MAE): 4.66641\n",
      "Validation Stage ==> Epoch: 652 / 99999 | Validation loss: 30.61507 |  Validation Accuracy: 4.69197 | Validation Metric (MAE)): 4.69197\n",
      "Load Model from best epoch 652\n",
      "Training Stage ==> Epoch: 653 / 99999 | Training loss: 30.15983 |  Training Accuracy: 4.66308 | Training Metric (MAE): 4.66308\n",
      "Validation Stage ==> Epoch: 653 / 99999 | Validation loss: 30.61198 |  Validation Accuracy: 4.69165 | Validation Metric (MAE)): 4.69165\n",
      "Load Model from best epoch 653\n",
      "Training Stage ==> Epoch: 654 / 99999 | Training loss: 29.06375 |  Training Accuracy: 4.66509 | Training Metric (MAE): 4.66509\n",
      "Validation Stage ==> Epoch: 654 / 99999 | Validation loss: 30.60889 |  Validation Accuracy: 4.69132 | Validation Metric (MAE)): 4.69132\n",
      "Load Model from best epoch 654\n",
      "Training Stage ==> Epoch: 655 / 99999 | Training loss: 31.75359 |  Training Accuracy: 4.65893 | Training Metric (MAE): 4.65893\n",
      "Validation Stage ==> Epoch: 655 / 99999 | Validation loss: 30.60581 |  Validation Accuracy: 4.69099 | Validation Metric (MAE)): 4.69099\n",
      "Load Model from best epoch 655\n",
      "Training Stage ==> Epoch: 656 / 99999 | Training loss: 30.69373 |  Training Accuracy: 4.67086 | Training Metric (MAE): 4.67086\n",
      "Validation Stage ==> Epoch: 656 / 99999 | Validation loss: 30.60272 |  Validation Accuracy: 4.69066 | Validation Metric (MAE)): 4.69066\n",
      "Load Model from best epoch 656\n",
      "Training Stage ==> Epoch: 657 / 99999 | Training loss: 30.10632 |  Training Accuracy: 4.68357 | Training Metric (MAE): 4.68357\n",
      "Validation Stage ==> Epoch: 657 / 99999 | Validation loss: 30.59962 |  Validation Accuracy: 4.69034 | Validation Metric (MAE)): 4.69034\n",
      "Load Model from best epoch 657\n",
      "Training Stage ==> Epoch: 658 / 99999 | Training loss: 30.83969 |  Training Accuracy: 4.66961 | Training Metric (MAE): 4.66961\n",
      "Validation Stage ==> Epoch: 658 / 99999 | Validation loss: 30.59653 |  Validation Accuracy: 4.69001 | Validation Metric (MAE)): 4.69001\n",
      "Load Model from best epoch 658\n",
      "Training Stage ==> Epoch: 659 / 99999 | Training loss: 30.93162 |  Training Accuracy: 4.68871 | Training Metric (MAE): 4.68871\n",
      "Validation Stage ==> Epoch: 659 / 99999 | Validation loss: 30.59344 |  Validation Accuracy: 4.68968 | Validation Metric (MAE)): 4.68968\n",
      "Load Model from best epoch 659\n",
      "Training Stage ==> Epoch: 660 / 99999 | Training loss: 30.44724 |  Training Accuracy: 4.67592 | Training Metric (MAE): 4.67592\n",
      "Validation Stage ==> Epoch: 660 / 99999 | Validation loss: 30.59036 |  Validation Accuracy: 4.68936 | Validation Metric (MAE)): 4.68936\n",
      "Load Model from best epoch 660\n",
      "Training Stage ==> Epoch: 661 / 99999 | Training loss: 29.61457 |  Training Accuracy: 4.66924 | Training Metric (MAE): 4.66924\n",
      "Validation Stage ==> Epoch: 661 / 99999 | Validation loss: 30.58727 |  Validation Accuracy: 4.68903 | Validation Metric (MAE)): 4.68903\n",
      "Load Model from best epoch 661\n",
      "Training Stage ==> Epoch: 662 / 99999 | Training loss: 28.86602 |  Training Accuracy: 4.68275 | Training Metric (MAE): 4.68275\n",
      "Validation Stage ==> Epoch: 662 / 99999 | Validation loss: 30.58418 |  Validation Accuracy: 4.68870 | Validation Metric (MAE)): 4.68870\n",
      "Load Model from best epoch 662\n",
      "Training Stage ==> Epoch: 663 / 99999 | Training loss: 28.43059 |  Training Accuracy: 4.66254 | Training Metric (MAE): 4.66254\n",
      "Validation Stage ==> Epoch: 663 / 99999 | Validation loss: 30.58111 |  Validation Accuracy: 4.68838 | Validation Metric (MAE)): 4.68838\n",
      "Load Model from best epoch 663\n",
      "Training Stage ==> Epoch: 664 / 99999 | Training loss: 29.24092 |  Training Accuracy: 4.65631 | Training Metric (MAE): 4.65631\n",
      "Validation Stage ==> Epoch: 664 / 99999 | Validation loss: 30.57802 |  Validation Accuracy: 4.68805 | Validation Metric (MAE)): 4.68805\n",
      "Load Model from best epoch 664\n",
      "Training Stage ==> Epoch: 665 / 99999 | Training loss: 28.17481 |  Training Accuracy: 4.66689 | Training Metric (MAE): 4.66689\n",
      "Validation Stage ==> Epoch: 665 / 99999 | Validation loss: 30.57495 |  Validation Accuracy: 4.68772 | Validation Metric (MAE)): 4.68772\n",
      "Load Model from best epoch 665\n",
      "Training Stage ==> Epoch: 666 / 99999 | Training loss: 31.23708 |  Training Accuracy: 4.67129 | Training Metric (MAE): 4.67129\n",
      "Validation Stage ==> Epoch: 666 / 99999 | Validation loss: 30.57186 |  Validation Accuracy: 4.68740 | Validation Metric (MAE)): 4.68740\n",
      "Load Model from best epoch 666\n",
      "Training Stage ==> Epoch: 667 / 99999 | Training loss: 30.06559 |  Training Accuracy: 4.67310 | Training Metric (MAE): 4.67310\n",
      "Validation Stage ==> Epoch: 667 / 99999 | Validation loss: 30.56878 |  Validation Accuracy: 4.68707 | Validation Metric (MAE)): 4.68707\n",
      "Load Model from best epoch 667\n",
      "Training Stage ==> Epoch: 668 / 99999 | Training loss: 29.48714 |  Training Accuracy: 4.67233 | Training Metric (MAE): 4.67233\n",
      "Validation Stage ==> Epoch: 668 / 99999 | Validation loss: 30.56569 |  Validation Accuracy: 4.68674 | Validation Metric (MAE)): 4.68674\n",
      "Load Model from best epoch 668\n",
      "Training Stage ==> Epoch: 669 / 99999 | Training loss: 30.01756 |  Training Accuracy: 4.65318 | Training Metric (MAE): 4.65318\n",
      "Validation Stage ==> Epoch: 669 / 99999 | Validation loss: 30.56261 |  Validation Accuracy: 4.68642 | Validation Metric (MAE)): 4.68642\n",
      "Load Model from best epoch 669\n",
      "Training Stage ==> Epoch: 670 / 99999 | Training loss: 29.60382 |  Training Accuracy: 4.66563 | Training Metric (MAE): 4.66563\n",
      "Validation Stage ==> Epoch: 670 / 99999 | Validation loss: 30.55953 |  Validation Accuracy: 4.68609 | Validation Metric (MAE)): 4.68609\n",
      "Load Model from best epoch 670\n",
      "Training Stage ==> Epoch: 671 / 99999 | Training loss: 30.72343 |  Training Accuracy: 4.66441 | Training Metric (MAE): 4.66441\n",
      "Validation Stage ==> Epoch: 671 / 99999 | Validation loss: 30.55644 |  Validation Accuracy: 4.68576 | Validation Metric (MAE)): 4.68576\n",
      "Load Model from best epoch 671\n",
      "Training Stage ==> Epoch: 672 / 99999 | Training loss: 29.14992 |  Training Accuracy: 4.66544 | Training Metric (MAE): 4.66544\n",
      "Validation Stage ==> Epoch: 672 / 99999 | Validation loss: 30.55336 |  Validation Accuracy: 4.68544 | Validation Metric (MAE)): 4.68544\n",
      "Load Model from best epoch 672\n",
      "Training Stage ==> Epoch: 673 / 99999 | Training loss: 27.51562 |  Training Accuracy: 4.67464 | Training Metric (MAE): 4.67464\n",
      "Validation Stage ==> Epoch: 673 / 99999 | Validation loss: 30.55028 |  Validation Accuracy: 4.68511 | Validation Metric (MAE)): 4.68511\n",
      "Load Model from best epoch 673\n",
      "Training Stage ==> Epoch: 674 / 99999 | Training loss: 28.56589 |  Training Accuracy: 4.67244 | Training Metric (MAE): 4.67244\n",
      "Validation Stage ==> Epoch: 674 / 99999 | Validation loss: 30.54721 |  Validation Accuracy: 4.68478 | Validation Metric (MAE)): 4.68478\n",
      "Load Model from best epoch 674\n",
      "Training Stage ==> Epoch: 675 / 99999 | Training loss: 29.09948 |  Training Accuracy: 4.66584 | Training Metric (MAE): 4.66584\n",
      "Validation Stage ==> Epoch: 675 / 99999 | Validation loss: 30.54413 |  Validation Accuracy: 4.68446 | Validation Metric (MAE)): 4.68446\n",
      "Load Model from best epoch 675\n",
      "Training Stage ==> Epoch: 676 / 99999 | Training loss: 27.81100 |  Training Accuracy: 4.66705 | Training Metric (MAE): 4.66705\n",
      "Validation Stage ==> Epoch: 676 / 99999 | Validation loss: 30.54105 |  Validation Accuracy: 4.68413 | Validation Metric (MAE)): 4.68413\n",
      "Load Model from best epoch 676\n",
      "Training Stage ==> Epoch: 677 / 99999 | Training loss: 28.65572 |  Training Accuracy: 4.65604 | Training Metric (MAE): 4.65604\n",
      "Validation Stage ==> Epoch: 677 / 99999 | Validation loss: 30.53798 |  Validation Accuracy: 4.68380 | Validation Metric (MAE)): 4.68380\n",
      "Load Model from best epoch 677\n",
      "Training Stage ==> Epoch: 678 / 99999 | Training loss: 28.32018 |  Training Accuracy: 4.66645 | Training Metric (MAE): 4.66645\n",
      "Validation Stage ==> Epoch: 678 / 99999 | Validation loss: 30.53491 |  Validation Accuracy: 4.68348 | Validation Metric (MAE)): 4.68348\n",
      "Load Model from best epoch 678\n",
      "Training Stage ==> Epoch: 679 / 99999 | Training loss: 31.17445 |  Training Accuracy: 4.64371 | Training Metric (MAE): 4.64371\n",
      "Validation Stage ==> Epoch: 679 / 99999 | Validation loss: 30.53184 |  Validation Accuracy: 4.68315 | Validation Metric (MAE)): 4.68315\n",
      "Load Model from best epoch 679\n",
      "Training Stage ==> Epoch: 680 / 99999 | Training loss: 29.75543 |  Training Accuracy: 4.66363 | Training Metric (MAE): 4.66363\n",
      "Validation Stage ==> Epoch: 680 / 99999 | Validation loss: 30.52876 |  Validation Accuracy: 4.68283 | Validation Metric (MAE)): 4.68283\n",
      "Load Model from best epoch 680\n",
      "Training Stage ==> Epoch: 681 / 99999 | Training loss: 31.19415 |  Training Accuracy: 4.65472 | Training Metric (MAE): 4.65472\n",
      "Validation Stage ==> Epoch: 681 / 99999 | Validation loss: 30.52568 |  Validation Accuracy: 4.68250 | Validation Metric (MAE)): 4.68250\n",
      "Load Model from best epoch 681\n",
      "Training Stage ==> Epoch: 682 / 99999 | Training loss: 30.08217 |  Training Accuracy: 4.65924 | Training Metric (MAE): 4.65924\n",
      "Validation Stage ==> Epoch: 682 / 99999 | Validation loss: 30.52261 |  Validation Accuracy: 4.68217 | Validation Metric (MAE)): 4.68217\n",
      "Load Model from best epoch 682\n",
      "Training Stage ==> Epoch: 683 / 99999 | Training loss: 28.44429 |  Training Accuracy: 4.66435 | Training Metric (MAE): 4.66435\n",
      "Validation Stage ==> Epoch: 683 / 99999 | Validation loss: 30.51954 |  Validation Accuracy: 4.68185 | Validation Metric (MAE)): 4.68185\n",
      "Load Model from best epoch 683\n",
      "Training Stage ==> Epoch: 684 / 99999 | Training loss: 28.59224 |  Training Accuracy: 4.66028 | Training Metric (MAE): 4.66028\n",
      "Validation Stage ==> Epoch: 684 / 99999 | Validation loss: 30.51647 |  Validation Accuracy: 4.68152 | Validation Metric (MAE)): 4.68152\n",
      "Load Model from best epoch 684\n",
      "Training Stage ==> Epoch: 685 / 99999 | Training loss: 30.96284 |  Training Accuracy: 4.65316 | Training Metric (MAE): 4.65316\n",
      "Validation Stage ==> Epoch: 685 / 99999 | Validation loss: 30.51339 |  Validation Accuracy: 4.68120 | Validation Metric (MAE)): 4.68120\n",
      "Load Model from best epoch 685\n",
      "Training Stage ==> Epoch: 686 / 99999 | Training loss: 29.54601 |  Training Accuracy: 4.65398 | Training Metric (MAE): 4.65398\n",
      "Validation Stage ==> Epoch: 686 / 99999 | Validation loss: 30.51032 |  Validation Accuracy: 4.68087 | Validation Metric (MAE)): 4.68087\n",
      "Load Model from best epoch 686\n",
      "Training Stage ==> Epoch: 687 / 99999 | Training loss: 29.95731 |  Training Accuracy: 4.65562 | Training Metric (MAE): 4.65562\n",
      "Validation Stage ==> Epoch: 687 / 99999 | Validation loss: 30.50726 |  Validation Accuracy: 4.68054 | Validation Metric (MAE)): 4.68054\n",
      "Load Model from best epoch 687\n",
      "Training Stage ==> Epoch: 688 / 99999 | Training loss: 30.09991 |  Training Accuracy: 4.65197 | Training Metric (MAE): 4.65197\n",
      "Validation Stage ==> Epoch: 688 / 99999 | Validation loss: 30.50418 |  Validation Accuracy: 4.68022 | Validation Metric (MAE)): 4.68022\n",
      "Load Model from best epoch 688\n",
      "Training Stage ==> Epoch: 689 / 99999 | Training loss: 27.83717 |  Training Accuracy: 4.67066 | Training Metric (MAE): 4.67066\n",
      "Validation Stage ==> Epoch: 689 / 99999 | Validation loss: 30.50112 |  Validation Accuracy: 4.67989 | Validation Metric (MAE)): 4.67989\n",
      "Load Model from best epoch 689\n",
      "Training Stage ==> Epoch: 690 / 99999 | Training loss: 28.50196 |  Training Accuracy: 4.65881 | Training Metric (MAE): 4.65881\n",
      "Validation Stage ==> Epoch: 690 / 99999 | Validation loss: 30.49806 |  Validation Accuracy: 4.67957 | Validation Metric (MAE)): 4.67957\n",
      "Load Model from best epoch 690\n",
      "Training Stage ==> Epoch: 691 / 99999 | Training loss: 30.09108 |  Training Accuracy: 4.66431 | Training Metric (MAE): 4.66431\n",
      "Validation Stage ==> Epoch: 691 / 99999 | Validation loss: 30.49499 |  Validation Accuracy: 4.67924 | Validation Metric (MAE)): 4.67924\n",
      "Load Model from best epoch 691\n",
      "Training Stage ==> Epoch: 692 / 99999 | Training loss: 29.60771 |  Training Accuracy: 4.66787 | Training Metric (MAE): 4.66787\n",
      "Validation Stage ==> Epoch: 692 / 99999 | Validation loss: 30.49192 |  Validation Accuracy: 4.67892 | Validation Metric (MAE)): 4.67892\n",
      "Load Model from best epoch 692\n",
      "Training Stage ==> Epoch: 693 / 99999 | Training loss: 30.07410 |  Training Accuracy: 4.65025 | Training Metric (MAE): 4.65025\n",
      "Validation Stage ==> Epoch: 693 / 99999 | Validation loss: 30.48885 |  Validation Accuracy: 4.67859 | Validation Metric (MAE)): 4.67859\n",
      "Load Model from best epoch 693\n",
      "Training Stage ==> Epoch: 694 / 99999 | Training loss: 29.95991 |  Training Accuracy: 4.65627 | Training Metric (MAE): 4.65627\n",
      "Validation Stage ==> Epoch: 694 / 99999 | Validation loss: 30.48577 |  Validation Accuracy: 4.67826 | Validation Metric (MAE)): 4.67826\n",
      "Load Model from best epoch 694\n",
      "Training Stage ==> Epoch: 695 / 99999 | Training loss: 28.52267 |  Training Accuracy: 4.65803 | Training Metric (MAE): 4.65803\n",
      "Validation Stage ==> Epoch: 695 / 99999 | Validation loss: 30.48271 |  Validation Accuracy: 4.67794 | Validation Metric (MAE)): 4.67794\n",
      "Load Model from best epoch 695\n",
      "Training Stage ==> Epoch: 696 / 99999 | Training loss: 29.55109 |  Training Accuracy: 4.66653 | Training Metric (MAE): 4.66653\n",
      "Validation Stage ==> Epoch: 696 / 99999 | Validation loss: 30.47965 |  Validation Accuracy: 4.67761 | Validation Metric (MAE)): 4.67761\n",
      "Load Model from best epoch 696\n",
      "Training Stage ==> Epoch: 697 / 99999 | Training loss: 28.39806 |  Training Accuracy: 4.64931 | Training Metric (MAE): 4.64931\n",
      "Validation Stage ==> Epoch: 697 / 99999 | Validation loss: 30.47658 |  Validation Accuracy: 4.67729 | Validation Metric (MAE)): 4.67729\n",
      "Load Model from best epoch 697\n",
      "Training Stage ==> Epoch: 698 / 99999 | Training loss: 28.64871 |  Training Accuracy: 4.65172 | Training Metric (MAE): 4.65172\n",
      "Validation Stage ==> Epoch: 698 / 99999 | Validation loss: 30.47352 |  Validation Accuracy: 4.67696 | Validation Metric (MAE)): 4.67696\n",
      "Load Model from best epoch 698\n",
      "Training Stage ==> Epoch: 699 / 99999 | Training loss: 29.64181 |  Training Accuracy: 4.65936 | Training Metric (MAE): 4.65936\n",
      "Validation Stage ==> Epoch: 699 / 99999 | Validation loss: 30.47046 |  Validation Accuracy: 4.67664 | Validation Metric (MAE)): 4.67664\n",
      "Load Model from best epoch 699\n",
      "Training Stage ==> Epoch: 700 / 99999 | Training loss: 30.06387 |  Training Accuracy: 4.66010 | Training Metric (MAE): 4.66010\n",
      "Validation Stage ==> Epoch: 700 / 99999 | Validation loss: 30.46739 |  Validation Accuracy: 4.67631 | Validation Metric (MAE)): 4.67631\n",
      "Load Model from best epoch 700\n",
      "Training Stage ==> Epoch: 701 / 99999 | Training loss: 29.41952 |  Training Accuracy: 4.65585 | Training Metric (MAE): 4.65585\n",
      "Validation Stage ==> Epoch: 701 / 99999 | Validation loss: 30.46433 |  Validation Accuracy: 4.67599 | Validation Metric (MAE)): 4.67599\n",
      "Load Model from best epoch 701\n",
      "Training Stage ==> Epoch: 702 / 99999 | Training loss: 27.83834 |  Training Accuracy: 4.65592 | Training Metric (MAE): 4.65592\n",
      "Validation Stage ==> Epoch: 702 / 99999 | Validation loss: 30.46128 |  Validation Accuracy: 4.67566 | Validation Metric (MAE)): 4.67566\n",
      "Load Model from best epoch 702\n",
      "Training Stage ==> Epoch: 703 / 99999 | Training loss: 27.69098 |  Training Accuracy: 4.66953 | Training Metric (MAE): 4.66953\n",
      "Validation Stage ==> Epoch: 703 / 99999 | Validation loss: 30.45822 |  Validation Accuracy: 4.67534 | Validation Metric (MAE)): 4.67534\n",
      "Load Model from best epoch 703\n",
      "Training Stage ==> Epoch: 704 / 99999 | Training loss: 29.73063 |  Training Accuracy: 4.65328 | Training Metric (MAE): 4.65328\n",
      "Validation Stage ==> Epoch: 704 / 99999 | Validation loss: 30.45517 |  Validation Accuracy: 4.67501 | Validation Metric (MAE)): 4.67501\n",
      "Load Model from best epoch 704\n",
      "Training Stage ==> Epoch: 705 / 99999 | Training loss: 30.43896 |  Training Accuracy: 4.65278 | Training Metric (MAE): 4.65278\n",
      "Validation Stage ==> Epoch: 705 / 99999 | Validation loss: 30.45211 |  Validation Accuracy: 4.67469 | Validation Metric (MAE)): 4.67469\n",
      "Load Model from best epoch 705\n",
      "Training Stage ==> Epoch: 706 / 99999 | Training loss: 28.60692 |  Training Accuracy: 4.65500 | Training Metric (MAE): 4.65500\n",
      "Validation Stage ==> Epoch: 706 / 99999 | Validation loss: 30.44905 |  Validation Accuracy: 4.67436 | Validation Metric (MAE)): 4.67436\n",
      "Load Model from best epoch 706\n",
      "Training Stage ==> Epoch: 707 / 99999 | Training loss: 28.72226 |  Training Accuracy: 4.64852 | Training Metric (MAE): 4.64852\n",
      "Validation Stage ==> Epoch: 707 / 99999 | Validation loss: 30.44599 |  Validation Accuracy: 4.67404 | Validation Metric (MAE)): 4.67404\n",
      "Load Model from best epoch 707\n",
      "Training Stage ==> Epoch: 708 / 99999 | Training loss: 29.09927 |  Training Accuracy: 4.65141 | Training Metric (MAE): 4.65141\n",
      "Validation Stage ==> Epoch: 708 / 99999 | Validation loss: 30.44293 |  Validation Accuracy: 4.67371 | Validation Metric (MAE)): 4.67371\n",
      "Load Model from best epoch 708\n",
      "Training Stage ==> Epoch: 709 / 99999 | Training loss: 28.46250 |  Training Accuracy: 4.64545 | Training Metric (MAE): 4.64545\n",
      "Validation Stage ==> Epoch: 709 / 99999 | Validation loss: 30.43987 |  Validation Accuracy: 4.67339 | Validation Metric (MAE)): 4.67339\n",
      "Load Model from best epoch 709\n",
      "Training Stage ==> Epoch: 710 / 99999 | Training loss: 29.79531 |  Training Accuracy: 4.66083 | Training Metric (MAE): 4.66083\n",
      "Validation Stage ==> Epoch: 710 / 99999 | Validation loss: 30.43682 |  Validation Accuracy: 4.67306 | Validation Metric (MAE)): 4.67306\n",
      "Load Model from best epoch 710\n",
      "Training Stage ==> Epoch: 711 / 99999 | Training loss: 28.75483 |  Training Accuracy: 4.65028 | Training Metric (MAE): 4.65028\n",
      "Validation Stage ==> Epoch: 711 / 99999 | Validation loss: 30.43377 |  Validation Accuracy: 4.67274 | Validation Metric (MAE)): 4.67274\n",
      "Load Model from best epoch 711\n",
      "Training Stage ==> Epoch: 712 / 99999 | Training loss: 29.27369 |  Training Accuracy: 4.65504 | Training Metric (MAE): 4.65504\n",
      "Validation Stage ==> Epoch: 712 / 99999 | Validation loss: 30.43071 |  Validation Accuracy: 4.67241 | Validation Metric (MAE)): 4.67241\n",
      "Load Model from best epoch 712\n",
      "Training Stage ==> Epoch: 713 / 99999 | Training loss: 28.17227 |  Training Accuracy: 4.64932 | Training Metric (MAE): 4.64932\n",
      "Validation Stage ==> Epoch: 713 / 99999 | Validation loss: 30.42766 |  Validation Accuracy: 4.67209 | Validation Metric (MAE)): 4.67209\n",
      "Load Model from best epoch 713\n",
      "Training Stage ==> Epoch: 714 / 99999 | Training loss: 29.43694 |  Training Accuracy: 4.64877 | Training Metric (MAE): 4.64877\n",
      "Validation Stage ==> Epoch: 714 / 99999 | Validation loss: 30.42460 |  Validation Accuracy: 4.67176 | Validation Metric (MAE)): 4.67176\n",
      "Load Model from best epoch 714\n",
      "Training Stage ==> Epoch: 715 / 99999 | Training loss: 30.94450 |  Training Accuracy: 4.64529 | Training Metric (MAE): 4.64529\n",
      "Validation Stage ==> Epoch: 715 / 99999 | Validation loss: 30.42155 |  Validation Accuracy: 4.67144 | Validation Metric (MAE)): 4.67144\n",
      "Load Model from best epoch 715\n",
      "Training Stage ==> Epoch: 716 / 99999 | Training loss: 29.89651 |  Training Accuracy: 4.64499 | Training Metric (MAE): 4.64499\n",
      "Validation Stage ==> Epoch: 716 / 99999 | Validation loss: 30.41849 |  Validation Accuracy: 4.67111 | Validation Metric (MAE)): 4.67111\n",
      "Load Model from best epoch 716\n",
      "Training Stage ==> Epoch: 717 / 99999 | Training loss: 30.01484 |  Training Accuracy: 4.63929 | Training Metric (MAE): 4.63929\n",
      "Validation Stage ==> Epoch: 717 / 99999 | Validation loss: 30.41543 |  Validation Accuracy: 4.67079 | Validation Metric (MAE)): 4.67079\n",
      "Load Model from best epoch 717\n",
      "Training Stage ==> Epoch: 718 / 99999 | Training loss: 29.36608 |  Training Accuracy: 4.64155 | Training Metric (MAE): 4.64155\n",
      "Validation Stage ==> Epoch: 718 / 99999 | Validation loss: 30.41238 |  Validation Accuracy: 4.67046 | Validation Metric (MAE)): 4.67046\n",
      "Load Model from best epoch 718\n",
      "Training Stage ==> Epoch: 719 / 99999 | Training loss: 30.10954 |  Training Accuracy: 4.64682 | Training Metric (MAE): 4.64682\n",
      "Validation Stage ==> Epoch: 719 / 99999 | Validation loss: 30.40933 |  Validation Accuracy: 4.67014 | Validation Metric (MAE)): 4.67014\n",
      "Load Model from best epoch 719\n",
      "Training Stage ==> Epoch: 720 / 99999 | Training loss: 28.86063 |  Training Accuracy: 4.63771 | Training Metric (MAE): 4.63771\n",
      "Validation Stage ==> Epoch: 720 / 99999 | Validation loss: 30.40628 |  Validation Accuracy: 4.66982 | Validation Metric (MAE)): 4.66982\n",
      "Load Model from best epoch 720\n",
      "Training Stage ==> Epoch: 721 / 99999 | Training loss: 28.11729 |  Training Accuracy: 4.64715 | Training Metric (MAE): 4.64715\n",
      "Validation Stage ==> Epoch: 721 / 99999 | Validation loss: 30.40323 |  Validation Accuracy: 4.66949 | Validation Metric (MAE)): 4.66949\n",
      "Load Model from best epoch 721\n",
      "Training Stage ==> Epoch: 722 / 99999 | Training loss: 30.39690 |  Training Accuracy: 4.65560 | Training Metric (MAE): 4.65560\n",
      "Validation Stage ==> Epoch: 722 / 99999 | Validation loss: 30.40019 |  Validation Accuracy: 4.66917 | Validation Metric (MAE)): 4.66917\n",
      "Load Model from best epoch 722\n",
      "Training Stage ==> Epoch: 723 / 99999 | Training loss: 29.00469 |  Training Accuracy: 4.64055 | Training Metric (MAE): 4.64055\n",
      "Validation Stage ==> Epoch: 723 / 99999 | Validation loss: 30.39714 |  Validation Accuracy: 4.66884 | Validation Metric (MAE)): 4.66884\n",
      "Load Model from best epoch 723\n",
      "Training Stage ==> Epoch: 724 / 99999 | Training loss: 29.65708 |  Training Accuracy: 4.64732 | Training Metric (MAE): 4.64732\n",
      "Validation Stage ==> Epoch: 724 / 99999 | Validation loss: 30.39409 |  Validation Accuracy: 4.66852 | Validation Metric (MAE)): 4.66852\n",
      "Load Model from best epoch 724\n",
      "Training Stage ==> Epoch: 725 / 99999 | Training loss: 28.07435 |  Training Accuracy: 4.65716 | Training Metric (MAE): 4.65716\n",
      "Validation Stage ==> Epoch: 725 / 99999 | Validation loss: 30.39105 |  Validation Accuracy: 4.66819 | Validation Metric (MAE)): 4.66819\n",
      "Load Model from best epoch 725\n",
      "Training Stage ==> Epoch: 726 / 99999 | Training loss: 29.56994 |  Training Accuracy: 4.63673 | Training Metric (MAE): 4.63673\n",
      "Validation Stage ==> Epoch: 726 / 99999 | Validation loss: 30.38800 |  Validation Accuracy: 4.66787 | Validation Metric (MAE)): 4.66787\n",
      "Load Model from best epoch 726\n",
      "Training Stage ==> Epoch: 727 / 99999 | Training loss: 29.90980 |  Training Accuracy: 4.65686 | Training Metric (MAE): 4.65686\n",
      "Validation Stage ==> Epoch: 727 / 99999 | Validation loss: 30.38495 |  Validation Accuracy: 4.66755 | Validation Metric (MAE)): 4.66755\n",
      "Load Model from best epoch 727\n",
      "Training Stage ==> Epoch: 728 / 99999 | Training loss: 27.59149 |  Training Accuracy: 4.65295 | Training Metric (MAE): 4.65295\n",
      "Validation Stage ==> Epoch: 728 / 99999 | Validation loss: 30.38191 |  Validation Accuracy: 4.66722 | Validation Metric (MAE)): 4.66722\n",
      "Load Model from best epoch 728\n",
      "Training Stage ==> Epoch: 729 / 99999 | Training loss: 29.56872 |  Training Accuracy: 4.64871 | Training Metric (MAE): 4.64871\n",
      "Validation Stage ==> Epoch: 729 / 99999 | Validation loss: 30.37886 |  Validation Accuracy: 4.66690 | Validation Metric (MAE)): 4.66690\n",
      "Load Model from best epoch 729\n",
      "Training Stage ==> Epoch: 730 / 99999 | Training loss: 30.34020 |  Training Accuracy: 4.64841 | Training Metric (MAE): 4.64841\n",
      "Validation Stage ==> Epoch: 730 / 99999 | Validation loss: 30.37581 |  Validation Accuracy: 4.66657 | Validation Metric (MAE)): 4.66657\n",
      "Load Model from best epoch 730\n",
      "Training Stage ==> Epoch: 731 / 99999 | Training loss: 30.44124 |  Training Accuracy: 4.66109 | Training Metric (MAE): 4.66109\n",
      "Validation Stage ==> Epoch: 731 / 99999 | Validation loss: 30.37278 |  Validation Accuracy: 4.66625 | Validation Metric (MAE)): 4.66625\n",
      "Load Model from best epoch 731\n",
      "Training Stage ==> Epoch: 732 / 99999 | Training loss: 29.18383 |  Training Accuracy: 4.66215 | Training Metric (MAE): 4.66215\n",
      "Validation Stage ==> Epoch: 732 / 99999 | Validation loss: 30.36973 |  Validation Accuracy: 4.66593 | Validation Metric (MAE)): 4.66593\n",
      "Load Model from best epoch 732\n",
      "Training Stage ==> Epoch: 733 / 99999 | Training loss: 27.62088 |  Training Accuracy: 4.64772 | Training Metric (MAE): 4.64772\n",
      "Validation Stage ==> Epoch: 733 / 99999 | Validation loss: 30.36669 |  Validation Accuracy: 4.66560 | Validation Metric (MAE)): 4.66560\n",
      "Load Model from best epoch 733\n",
      "Training Stage ==> Epoch: 734 / 99999 | Training loss: 29.24671 |  Training Accuracy: 4.64384 | Training Metric (MAE): 4.64384\n",
      "Validation Stage ==> Epoch: 734 / 99999 | Validation loss: 30.36365 |  Validation Accuracy: 4.66528 | Validation Metric (MAE)): 4.66528\n",
      "Load Model from best epoch 734\n",
      "Training Stage ==> Epoch: 735 / 99999 | Training loss: 29.77380 |  Training Accuracy: 4.64996 | Training Metric (MAE): 4.64996\n",
      "Validation Stage ==> Epoch: 735 / 99999 | Validation loss: 30.36060 |  Validation Accuracy: 4.66495 | Validation Metric (MAE)): 4.66495\n",
      "Load Model from best epoch 735\n",
      "Training Stage ==> Epoch: 736 / 99999 | Training loss: 28.66294 |  Training Accuracy: 4.63578 | Training Metric (MAE): 4.63578\n",
      "Validation Stage ==> Epoch: 736 / 99999 | Validation loss: 30.35756 |  Validation Accuracy: 4.66463 | Validation Metric (MAE)): 4.66463\n",
      "Load Model from best epoch 736\n",
      "Training Stage ==> Epoch: 737 / 99999 | Training loss: 28.03865 |  Training Accuracy: 4.65860 | Training Metric (MAE): 4.65860\n",
      "Validation Stage ==> Epoch: 737 / 99999 | Validation loss: 30.35451 |  Validation Accuracy: 4.66431 | Validation Metric (MAE)): 4.66431\n",
      "Load Model from best epoch 737\n",
      "Training Stage ==> Epoch: 738 / 99999 | Training loss: 29.16525 |  Training Accuracy: 4.64668 | Training Metric (MAE): 4.64668\n",
      "Validation Stage ==> Epoch: 738 / 99999 | Validation loss: 30.35147 |  Validation Accuracy: 4.66398 | Validation Metric (MAE)): 4.66398\n",
      "Load Model from best epoch 738\n",
      "Training Stage ==> Epoch: 739 / 99999 | Training loss: 29.59259 |  Training Accuracy: 4.64096 | Training Metric (MAE): 4.64096\n",
      "Validation Stage ==> Epoch: 739 / 99999 | Validation loss: 30.34844 |  Validation Accuracy: 4.66366 | Validation Metric (MAE)): 4.66366\n",
      "Load Model from best epoch 739\n",
      "Training Stage ==> Epoch: 740 / 99999 | Training loss: 30.73433 |  Training Accuracy: 4.65278 | Training Metric (MAE): 4.65278\n",
      "Validation Stage ==> Epoch: 740 / 99999 | Validation loss: 30.34539 |  Validation Accuracy: 4.66333 | Validation Metric (MAE)): 4.66333\n",
      "Load Model from best epoch 740\n",
      "Training Stage ==> Epoch: 741 / 99999 | Training loss: 30.36552 |  Training Accuracy: 4.63901 | Training Metric (MAE): 4.63901\n",
      "Validation Stage ==> Epoch: 741 / 99999 | Validation loss: 30.34235 |  Validation Accuracy: 4.66301 | Validation Metric (MAE)): 4.66301\n",
      "Load Model from best epoch 741\n",
      "Training Stage ==> Epoch: 742 / 99999 | Training loss: 29.94100 |  Training Accuracy: 4.64658 | Training Metric (MAE): 4.64658\n",
      "Validation Stage ==> Epoch: 742 / 99999 | Validation loss: 30.33932 |  Validation Accuracy: 4.66269 | Validation Metric (MAE)): 4.66269\n",
      "Load Model from best epoch 742\n",
      "Training Stage ==> Epoch: 743 / 99999 | Training loss: 29.90067 |  Training Accuracy: 4.64700 | Training Metric (MAE): 4.64700\n",
      "Validation Stage ==> Epoch: 743 / 99999 | Validation loss: 30.33627 |  Validation Accuracy: 4.66236 | Validation Metric (MAE)): 4.66236\n",
      "Load Model from best epoch 743\n",
      "Training Stage ==> Epoch: 744 / 99999 | Training loss: 28.50964 |  Training Accuracy: 4.64386 | Training Metric (MAE): 4.64386\n",
      "Validation Stage ==> Epoch: 744 / 99999 | Validation loss: 30.33323 |  Validation Accuracy: 4.66204 | Validation Metric (MAE)): 4.66204\n",
      "Load Model from best epoch 744\n",
      "Training Stage ==> Epoch: 745 / 99999 | Training loss: 28.33519 |  Training Accuracy: 4.64666 | Training Metric (MAE): 4.64666\n",
      "Validation Stage ==> Epoch: 745 / 99999 | Validation loss: 30.33020 |  Validation Accuracy: 4.66172 | Validation Metric (MAE)): 4.66172\n",
      "Load Model from best epoch 745\n",
      "Training Stage ==> Epoch: 746 / 99999 | Training loss: 29.63836 |  Training Accuracy: 4.64123 | Training Metric (MAE): 4.64123\n",
      "Validation Stage ==> Epoch: 746 / 99999 | Validation loss: 30.32717 |  Validation Accuracy: 4.66139 | Validation Metric (MAE)): 4.66139\n",
      "Load Model from best epoch 746\n",
      "Training Stage ==> Epoch: 747 / 99999 | Training loss: 29.16304 |  Training Accuracy: 4.63719 | Training Metric (MAE): 4.63719\n",
      "Validation Stage ==> Epoch: 747 / 99999 | Validation loss: 30.32415 |  Validation Accuracy: 4.66107 | Validation Metric (MAE)): 4.66107\n",
      "Load Model from best epoch 747\n",
      "Training Stage ==> Epoch: 748 / 99999 | Training loss: 30.52570 |  Training Accuracy: 4.63016 | Training Metric (MAE): 4.63016\n",
      "Validation Stage ==> Epoch: 748 / 99999 | Validation loss: 30.32111 |  Validation Accuracy: 4.66075 | Validation Metric (MAE)): 4.66075\n",
      "Load Model from best epoch 748\n",
      "Training Stage ==> Epoch: 749 / 99999 | Training loss: 29.61835 |  Training Accuracy: 4.64594 | Training Metric (MAE): 4.64594\n",
      "Validation Stage ==> Epoch: 749 / 99999 | Validation loss: 30.31807 |  Validation Accuracy: 4.66042 | Validation Metric (MAE)): 4.66042\n",
      "Load Model from best epoch 749\n",
      "Training Stage ==> Epoch: 750 / 99999 | Training loss: 27.08419 |  Training Accuracy: 4.63819 | Training Metric (MAE): 4.63819\n",
      "Validation Stage ==> Epoch: 750 / 99999 | Validation loss: 30.31504 |  Validation Accuracy: 4.66010 | Validation Metric (MAE)): 4.66010\n",
      "Load Model from best epoch 750\n",
      "Training Stage ==> Epoch: 751 / 99999 | Training loss: 30.62066 |  Training Accuracy: 4.64726 | Training Metric (MAE): 4.64726\n",
      "Validation Stage ==> Epoch: 751 / 99999 | Validation loss: 30.31201 |  Validation Accuracy: 4.65978 | Validation Metric (MAE)): 4.65978\n",
      "Load Model from best epoch 751\n",
      "Training Stage ==> Epoch: 752 / 99999 | Training loss: 30.11805 |  Training Accuracy: 4.64003 | Training Metric (MAE): 4.64003\n",
      "Validation Stage ==> Epoch: 752 / 99999 | Validation loss: 30.30897 |  Validation Accuracy: 4.65945 | Validation Metric (MAE)): 4.65945\n",
      "Load Model from best epoch 752\n",
      "Training Stage ==> Epoch: 753 / 99999 | Training loss: 28.03704 |  Training Accuracy: 4.63916 | Training Metric (MAE): 4.63916\n",
      "Validation Stage ==> Epoch: 753 / 99999 | Validation loss: 30.30594 |  Validation Accuracy: 4.65913 | Validation Metric (MAE)): 4.65913\n",
      "Load Model from best epoch 753\n",
      "Training Stage ==> Epoch: 754 / 99999 | Training loss: 29.09017 |  Training Accuracy: 4.64363 | Training Metric (MAE): 4.64363\n",
      "Validation Stage ==> Epoch: 754 / 99999 | Validation loss: 30.30291 |  Validation Accuracy: 4.65881 | Validation Metric (MAE)): 4.65881\n",
      "Load Model from best epoch 754\n",
      "Training Stage ==> Epoch: 755 / 99999 | Training loss: 29.78326 |  Training Accuracy: 4.63153 | Training Metric (MAE): 4.63153\n",
      "Validation Stage ==> Epoch: 755 / 99999 | Validation loss: 30.29987 |  Validation Accuracy: 4.65848 | Validation Metric (MAE)): 4.65848\n",
      "Load Model from best epoch 755\n",
      "Training Stage ==> Epoch: 756 / 99999 | Training loss: 30.10089 |  Training Accuracy: 4.65217 | Training Metric (MAE): 4.65217\n",
      "Validation Stage ==> Epoch: 756 / 99999 | Validation loss: 30.29684 |  Validation Accuracy: 4.65816 | Validation Metric (MAE)): 4.65816\n",
      "Load Model from best epoch 756\n",
      "Training Stage ==> Epoch: 757 / 99999 | Training loss: 30.06413 |  Training Accuracy: 4.64272 | Training Metric (MAE): 4.64272\n",
      "Validation Stage ==> Epoch: 757 / 99999 | Validation loss: 30.29382 |  Validation Accuracy: 4.65784 | Validation Metric (MAE)): 4.65784\n",
      "Load Model from best epoch 757\n",
      "Training Stage ==> Epoch: 758 / 99999 | Training loss: 27.80330 |  Training Accuracy: 4.62831 | Training Metric (MAE): 4.62831\n",
      "Validation Stage ==> Epoch: 758 / 99999 | Validation loss: 30.29078 |  Validation Accuracy: 4.65751 | Validation Metric (MAE)): 4.65751\n",
      "Load Model from best epoch 758\n",
      "Training Stage ==> Epoch: 759 / 99999 | Training loss: 29.68889 |  Training Accuracy: 4.63836 | Training Metric (MAE): 4.63836\n",
      "Validation Stage ==> Epoch: 759 / 99999 | Validation loss: 30.28775 |  Validation Accuracy: 4.65719 | Validation Metric (MAE)): 4.65719\n",
      "Load Model from best epoch 759\n",
      "Training Stage ==> Epoch: 760 / 99999 | Training loss: 28.22792 |  Training Accuracy: 4.64372 | Training Metric (MAE): 4.64372\n",
      "Validation Stage ==> Epoch: 760 / 99999 | Validation loss: 30.28473 |  Validation Accuracy: 4.65687 | Validation Metric (MAE)): 4.65687\n",
      "Load Model from best epoch 760\n",
      "Training Stage ==> Epoch: 761 / 99999 | Training loss: 29.48546 |  Training Accuracy: 4.63489 | Training Metric (MAE): 4.63489\n",
      "Validation Stage ==> Epoch: 761 / 99999 | Validation loss: 30.28171 |  Validation Accuracy: 4.65655 | Validation Metric (MAE)): 4.65655\n",
      "Load Model from best epoch 761\n",
      "Training Stage ==> Epoch: 762 / 99999 | Training loss: 28.92166 |  Training Accuracy: 4.62843 | Training Metric (MAE): 4.62843\n",
      "Validation Stage ==> Epoch: 762 / 99999 | Validation loss: 30.27869 |  Validation Accuracy: 4.65622 | Validation Metric (MAE)): 4.65622\n",
      "Load Model from best epoch 762\n",
      "Training Stage ==> Epoch: 763 / 99999 | Training loss: 31.14014 |  Training Accuracy: 4.62961 | Training Metric (MAE): 4.62961\n",
      "Validation Stage ==> Epoch: 763 / 99999 | Validation loss: 30.27566 |  Validation Accuracy: 4.65590 | Validation Metric (MAE)): 4.65590\n",
      "Load Model from best epoch 763\n",
      "Training Stage ==> Epoch: 764 / 99999 | Training loss: 30.06784 |  Training Accuracy: 4.62735 | Training Metric (MAE): 4.62735\n",
      "Validation Stage ==> Epoch: 764 / 99999 | Validation loss: 30.27263 |  Validation Accuracy: 4.65558 | Validation Metric (MAE)): 4.65558\n",
      "Load Model from best epoch 764\n",
      "Training Stage ==> Epoch: 765 / 99999 | Training loss: 27.53371 |  Training Accuracy: 4.63170 | Training Metric (MAE): 4.63170\n",
      "Validation Stage ==> Epoch: 765 / 99999 | Validation loss: 30.26962 |  Validation Accuracy: 4.65525 | Validation Metric (MAE)): 4.65525\n",
      "Load Model from best epoch 765\n",
      "Training Stage ==> Epoch: 766 / 99999 | Training loss: 29.21747 |  Training Accuracy: 4.63313 | Training Metric (MAE): 4.63313\n",
      "Validation Stage ==> Epoch: 766 / 99999 | Validation loss: 30.26659 |  Validation Accuracy: 4.65493 | Validation Metric (MAE)): 4.65493\n",
      "Load Model from best epoch 766\n",
      "Training Stage ==> Epoch: 767 / 99999 | Training loss: 29.61203 |  Training Accuracy: 4.63655 | Training Metric (MAE): 4.63655\n",
      "Validation Stage ==> Epoch: 767 / 99999 | Validation loss: 30.26356 |  Validation Accuracy: 4.65461 | Validation Metric (MAE)): 4.65461\n",
      "Load Model from best epoch 767\n",
      "Training Stage ==> Epoch: 768 / 99999 | Training loss: 31.48665 |  Training Accuracy: 4.63276 | Training Metric (MAE): 4.63276\n",
      "Validation Stage ==> Epoch: 768 / 99999 | Validation loss: 30.26053 |  Validation Accuracy: 4.65428 | Validation Metric (MAE)): 4.65428\n",
      "Load Model from best epoch 768\n",
      "Training Stage ==> Epoch: 769 / 99999 | Training loss: 29.67990 |  Training Accuracy: 4.63649 | Training Metric (MAE): 4.63649\n",
      "Validation Stage ==> Epoch: 769 / 99999 | Validation loss: 30.25751 |  Validation Accuracy: 4.65396 | Validation Metric (MAE)): 4.65396\n",
      "Load Model from best epoch 769\n",
      "Training Stage ==> Epoch: 770 / 99999 | Training loss: 30.61739 |  Training Accuracy: 4.63298 | Training Metric (MAE): 4.63298\n",
      "Validation Stage ==> Epoch: 770 / 99999 | Validation loss: 30.25448 |  Validation Accuracy: 4.65364 | Validation Metric (MAE)): 4.65364\n",
      "Load Model from best epoch 770\n",
      "Training Stage ==> Epoch: 771 / 99999 | Training loss: 30.37128 |  Training Accuracy: 4.62567 | Training Metric (MAE): 4.62567\n",
      "Validation Stage ==> Epoch: 771 / 99999 | Validation loss: 30.25146 |  Validation Accuracy: 4.65332 | Validation Metric (MAE)): 4.65332\n",
      "Load Model from best epoch 771\n",
      "Training Stage ==> Epoch: 772 / 99999 | Training loss: 30.55523 |  Training Accuracy: 4.63866 | Training Metric (MAE): 4.63866\n",
      "Validation Stage ==> Epoch: 772 / 99999 | Validation loss: 30.24844 |  Validation Accuracy: 4.65299 | Validation Metric (MAE)): 4.65299\n",
      "Load Model from best epoch 772\n",
      "Training Stage ==> Epoch: 773 / 99999 | Training loss: 29.23520 |  Training Accuracy: 4.63658 | Training Metric (MAE): 4.63658\n",
      "Validation Stage ==> Epoch: 773 / 99999 | Validation loss: 30.24541 |  Validation Accuracy: 4.65267 | Validation Metric (MAE)): 4.65267\n",
      "Load Model from best epoch 773\n",
      "Training Stage ==> Epoch: 774 / 99999 | Training loss: 28.92404 |  Training Accuracy: 4.63400 | Training Metric (MAE): 4.63400\n",
      "Validation Stage ==> Epoch: 774 / 99999 | Validation loss: 30.24240 |  Validation Accuracy: 4.65235 | Validation Metric (MAE)): 4.65235\n",
      "Load Model from best epoch 774\n",
      "Training Stage ==> Epoch: 775 / 99999 | Training loss: 29.57826 |  Training Accuracy: 4.62794 | Training Metric (MAE): 4.62794\n",
      "Validation Stage ==> Epoch: 775 / 99999 | Validation loss: 30.23938 |  Validation Accuracy: 4.65203 | Validation Metric (MAE)): 4.65203\n",
      "Load Model from best epoch 775\n",
      "Training Stage ==> Epoch: 776 / 99999 | Training loss: 28.58368 |  Training Accuracy: 4.63900 | Training Metric (MAE): 4.63900\n",
      "Validation Stage ==> Epoch: 776 / 99999 | Validation loss: 30.23637 |  Validation Accuracy: 4.65171 | Validation Metric (MAE)): 4.65171\n",
      "Load Model from best epoch 776\n",
      "Training Stage ==> Epoch: 777 / 99999 | Training loss: 28.44735 |  Training Accuracy: 4.62901 | Training Metric (MAE): 4.62901\n",
      "Validation Stage ==> Epoch: 777 / 99999 | Validation loss: 30.23336 |  Validation Accuracy: 4.65138 | Validation Metric (MAE)): 4.65138\n",
      "Load Model from best epoch 777\n",
      "Training Stage ==> Epoch: 778 / 99999 | Training loss: 27.53329 |  Training Accuracy: 4.63117 | Training Metric (MAE): 4.63117\n",
      "Validation Stage ==> Epoch: 778 / 99999 | Validation loss: 30.23035 |  Validation Accuracy: 4.65106 | Validation Metric (MAE)): 4.65106\n",
      "Load Model from best epoch 778\n",
      "Training Stage ==> Epoch: 779 / 99999 | Training loss: 29.20884 |  Training Accuracy: 4.63332 | Training Metric (MAE): 4.63332\n",
      "Validation Stage ==> Epoch: 779 / 99999 | Validation loss: 30.22733 |  Validation Accuracy: 4.65074 | Validation Metric (MAE)): 4.65074\n",
      "Load Model from best epoch 779\n",
      "Training Stage ==> Epoch: 780 / 99999 | Training loss: 29.19214 |  Training Accuracy: 4.62532 | Training Metric (MAE): 4.62532\n",
      "Validation Stage ==> Epoch: 780 / 99999 | Validation loss: 30.22432 |  Validation Accuracy: 4.65042 | Validation Metric (MAE)): 4.65042\n",
      "Load Model from best epoch 780\n",
      "Training Stage ==> Epoch: 781 / 99999 | Training loss: 27.70900 |  Training Accuracy: 4.61778 | Training Metric (MAE): 4.61778\n",
      "Validation Stage ==> Epoch: 781 / 99999 | Validation loss: 30.22130 |  Validation Accuracy: 4.65010 | Validation Metric (MAE)): 4.65010\n",
      "Load Model from best epoch 781\n",
      "Training Stage ==> Epoch: 782 / 99999 | Training loss: 30.40664 |  Training Accuracy: 4.63047 | Training Metric (MAE): 4.63047\n",
      "Validation Stage ==> Epoch: 782 / 99999 | Validation loss: 30.21829 |  Validation Accuracy: 4.64978 | Validation Metric (MAE)): 4.64978\n",
      "Load Model from best epoch 782\n",
      "Training Stage ==> Epoch: 783 / 99999 | Training loss: 28.01833 |  Training Accuracy: 4.63987 | Training Metric (MAE): 4.63987\n",
      "Validation Stage ==> Epoch: 783 / 99999 | Validation loss: 30.21528 |  Validation Accuracy: 4.64945 | Validation Metric (MAE)): 4.64945\n",
      "Load Model from best epoch 783\n",
      "Training Stage ==> Epoch: 784 / 99999 | Training loss: 29.03603 |  Training Accuracy: 4.61450 | Training Metric (MAE): 4.61450\n",
      "Validation Stage ==> Epoch: 784 / 99999 | Validation loss: 30.21227 |  Validation Accuracy: 4.64913 | Validation Metric (MAE)): 4.64913\n",
      "Load Model from best epoch 784\n",
      "Training Stage ==> Epoch: 785 / 99999 | Training loss: 28.80934 |  Training Accuracy: 4.61826 | Training Metric (MAE): 4.61826\n",
      "Validation Stage ==> Epoch: 785 / 99999 | Validation loss: 30.20926 |  Validation Accuracy: 4.64881 | Validation Metric (MAE)): 4.64881\n",
      "Load Model from best epoch 785\n",
      "Training Stage ==> Epoch: 786 / 99999 | Training loss: 28.32647 |  Training Accuracy: 4.63227 | Training Metric (MAE): 4.63227\n",
      "Validation Stage ==> Epoch: 786 / 99999 | Validation loss: 30.20625 |  Validation Accuracy: 4.64849 | Validation Metric (MAE)): 4.64849\n",
      "Load Model from best epoch 786\n",
      "Training Stage ==> Epoch: 787 / 99999 | Training loss: 29.87453 |  Training Accuracy: 4.63475 | Training Metric (MAE): 4.63475\n",
      "Validation Stage ==> Epoch: 787 / 99999 | Validation loss: 30.20324 |  Validation Accuracy: 4.64817 | Validation Metric (MAE)): 4.64817\n",
      "Load Model from best epoch 787\n",
      "Training Stage ==> Epoch: 788 / 99999 | Training loss: 30.17509 |  Training Accuracy: 4.63601 | Training Metric (MAE): 4.63601\n",
      "Validation Stage ==> Epoch: 788 / 99999 | Validation loss: 30.20023 |  Validation Accuracy: 4.64785 | Validation Metric (MAE)): 4.64785\n",
      "Load Model from best epoch 788\n",
      "Training Stage ==> Epoch: 789 / 99999 | Training loss: 27.42825 |  Training Accuracy: 4.62932 | Training Metric (MAE): 4.62932\n",
      "Validation Stage ==> Epoch: 789 / 99999 | Validation loss: 30.19722 |  Validation Accuracy: 4.64752 | Validation Metric (MAE)): 4.64752\n",
      "Load Model from best epoch 789\n",
      "Training Stage ==> Epoch: 790 / 99999 | Training loss: 29.45240 |  Training Accuracy: 4.63051 | Training Metric (MAE): 4.63051\n",
      "Validation Stage ==> Epoch: 790 / 99999 | Validation loss: 30.19421 |  Validation Accuracy: 4.64720 | Validation Metric (MAE)): 4.64720\n",
      "Load Model from best epoch 790\n",
      "Training Stage ==> Epoch: 791 / 99999 | Training loss: 29.46379 |  Training Accuracy: 4.62644 | Training Metric (MAE): 4.62644\n",
      "Validation Stage ==> Epoch: 791 / 99999 | Validation loss: 30.19120 |  Validation Accuracy: 4.64688 | Validation Metric (MAE)): 4.64688\n",
      "Load Model from best epoch 791\n",
      "Training Stage ==> Epoch: 792 / 99999 | Training loss: 30.26974 |  Training Accuracy: 4.62605 | Training Metric (MAE): 4.62605\n",
      "Validation Stage ==> Epoch: 792 / 99999 | Validation loss: 30.18819 |  Validation Accuracy: 4.64656 | Validation Metric (MAE)): 4.64656\n",
      "Load Model from best epoch 792\n",
      "Training Stage ==> Epoch: 793 / 99999 | Training loss: 29.57698 |  Training Accuracy: 4.63399 | Training Metric (MAE): 4.63399\n",
      "Validation Stage ==> Epoch: 793 / 99999 | Validation loss: 30.18518 |  Validation Accuracy: 4.64624 | Validation Metric (MAE)): 4.64624\n",
      "Load Model from best epoch 793\n",
      "Training Stage ==> Epoch: 794 / 99999 | Training loss: 29.22634 |  Training Accuracy: 4.62847 | Training Metric (MAE): 4.62847\n",
      "Validation Stage ==> Epoch: 794 / 99999 | Validation loss: 30.18217 |  Validation Accuracy: 4.64592 | Validation Metric (MAE)): 4.64592\n",
      "Load Model from best epoch 794\n",
      "Training Stage ==> Epoch: 795 / 99999 | Training loss: 30.39802 |  Training Accuracy: 4.61778 | Training Metric (MAE): 4.61778\n",
      "Validation Stage ==> Epoch: 795 / 99999 | Validation loss: 30.17916 |  Validation Accuracy: 4.64559 | Validation Metric (MAE)): 4.64559\n",
      "Load Model from best epoch 795\n",
      "Training Stage ==> Epoch: 796 / 99999 | Training loss: 29.69585 |  Training Accuracy: 4.61859 | Training Metric (MAE): 4.61859\n",
      "Validation Stage ==> Epoch: 796 / 99999 | Validation loss: 30.17615 |  Validation Accuracy: 4.64527 | Validation Metric (MAE)): 4.64527\n",
      "Load Model from best epoch 796\n",
      "Training Stage ==> Epoch: 797 / 99999 | Training loss: 31.71202 |  Training Accuracy: 4.63202 | Training Metric (MAE): 4.63202\n",
      "Validation Stage ==> Epoch: 797 / 99999 | Validation loss: 30.17314 |  Validation Accuracy: 4.64495 | Validation Metric (MAE)): 4.64495\n",
      "Load Model from best epoch 797\n",
      "Training Stage ==> Epoch: 798 / 99999 | Training loss: 29.42490 |  Training Accuracy: 4.62877 | Training Metric (MAE): 4.62877\n",
      "Validation Stage ==> Epoch: 798 / 99999 | Validation loss: 30.17013 |  Validation Accuracy: 4.64463 | Validation Metric (MAE)): 4.64463\n",
      "Load Model from best epoch 798\n",
      "Training Stage ==> Epoch: 799 / 99999 | Training loss: 31.33834 |  Training Accuracy: 4.60886 | Training Metric (MAE): 4.60886\n",
      "Validation Stage ==> Epoch: 799 / 99999 | Validation loss: 30.16712 |  Validation Accuracy: 4.64431 | Validation Metric (MAE)): 4.64431\n",
      "Load Model from best epoch 799\n",
      "Training Stage ==> Epoch: 800 / 99999 | Training loss: 29.59596 |  Training Accuracy: 4.61236 | Training Metric (MAE): 4.61236\n",
      "Validation Stage ==> Epoch: 800 / 99999 | Validation loss: 30.16412 |  Validation Accuracy: 4.64398 | Validation Metric (MAE)): 4.64398\n",
      "Load Model from best epoch 800\n",
      "Training Stage ==> Epoch: 801 / 99999 | Training loss: 28.00110 |  Training Accuracy: 4.61498 | Training Metric (MAE): 4.61498\n",
      "Validation Stage ==> Epoch: 801 / 99999 | Validation loss: 30.16111 |  Validation Accuracy: 4.64366 | Validation Metric (MAE)): 4.64366\n",
      "Load Model from best epoch 801\n",
      "Training Stage ==> Epoch: 802 / 99999 | Training loss: 29.98599 |  Training Accuracy: 4.61626 | Training Metric (MAE): 4.61626\n",
      "Validation Stage ==> Epoch: 802 / 99999 | Validation loss: 30.15811 |  Validation Accuracy: 4.64334 | Validation Metric (MAE)): 4.64334\n",
      "Load Model from best epoch 802\n",
      "Training Stage ==> Epoch: 803 / 99999 | Training loss: 29.04599 |  Training Accuracy: 4.62349 | Training Metric (MAE): 4.62349\n",
      "Validation Stage ==> Epoch: 803 / 99999 | Validation loss: 30.15510 |  Validation Accuracy: 4.64302 | Validation Metric (MAE)): 4.64302\n",
      "Load Model from best epoch 803\n",
      "Training Stage ==> Epoch: 804 / 99999 | Training loss: 30.81195 |  Training Accuracy: 4.60850 | Training Metric (MAE): 4.60850\n",
      "Validation Stage ==> Epoch: 804 / 99999 | Validation loss: 30.15210 |  Validation Accuracy: 4.64270 | Validation Metric (MAE)): 4.64270\n",
      "Load Model from best epoch 804\n",
      "Training Stage ==> Epoch: 805 / 99999 | Training loss: 30.40203 |  Training Accuracy: 4.62573 | Training Metric (MAE): 4.62573\n",
      "Validation Stage ==> Epoch: 805 / 99999 | Validation loss: 30.14910 |  Validation Accuracy: 4.64238 | Validation Metric (MAE)): 4.64238\n",
      "Load Model from best epoch 805\n",
      "Training Stage ==> Epoch: 806 / 99999 | Training loss: 30.24794 |  Training Accuracy: 4.61479 | Training Metric (MAE): 4.61479\n",
      "Validation Stage ==> Epoch: 806 / 99999 | Validation loss: 30.14609 |  Validation Accuracy: 4.64206 | Validation Metric (MAE)): 4.64206\n",
      "Load Model from best epoch 806\n",
      "Training Stage ==> Epoch: 807 / 99999 | Training loss: 29.63908 |  Training Accuracy: 4.62067 | Training Metric (MAE): 4.62067\n",
      "Validation Stage ==> Epoch: 807 / 99999 | Validation loss: 30.14309 |  Validation Accuracy: 4.64174 | Validation Metric (MAE)): 4.64174\n",
      "Load Model from best epoch 807\n",
      "Training Stage ==> Epoch: 808 / 99999 | Training loss: 30.07632 |  Training Accuracy: 4.62560 | Training Metric (MAE): 4.62560\n",
      "Validation Stage ==> Epoch: 808 / 99999 | Validation loss: 30.14009 |  Validation Accuracy: 4.64141 | Validation Metric (MAE)): 4.64141\n",
      "Load Model from best epoch 808\n",
      "Training Stage ==> Epoch: 809 / 99999 | Training loss: 30.24768 |  Training Accuracy: 4.62078 | Training Metric (MAE): 4.62078\n",
      "Validation Stage ==> Epoch: 809 / 99999 | Validation loss: 30.13709 |  Validation Accuracy: 4.64109 | Validation Metric (MAE)): 4.64109\n",
      "Load Model from best epoch 809\n",
      "Training Stage ==> Epoch: 810 / 99999 | Training loss: 29.72438 |  Training Accuracy: 4.63159 | Training Metric (MAE): 4.63159\n",
      "Validation Stage ==> Epoch: 810 / 99999 | Validation loss: 30.13409 |  Validation Accuracy: 4.64077 | Validation Metric (MAE)): 4.64077\n",
      "Load Model from best epoch 810\n",
      "Training Stage ==> Epoch: 811 / 99999 | Training loss: 30.97309 |  Training Accuracy: 4.62604 | Training Metric (MAE): 4.62604\n",
      "Validation Stage ==> Epoch: 811 / 99999 | Validation loss: 30.13109 |  Validation Accuracy: 4.64045 | Validation Metric (MAE)): 4.64045\n",
      "Load Model from best epoch 811\n",
      "Training Stage ==> Epoch: 812 / 99999 | Training loss: 29.29458 |  Training Accuracy: 4.62415 | Training Metric (MAE): 4.62415\n",
      "Validation Stage ==> Epoch: 812 / 99999 | Validation loss: 30.12809 |  Validation Accuracy: 4.64013 | Validation Metric (MAE)): 4.64013\n",
      "Load Model from best epoch 812\n",
      "Training Stage ==> Epoch: 813 / 99999 | Training loss: 27.70223 |  Training Accuracy: 4.61552 | Training Metric (MAE): 4.61552\n",
      "Validation Stage ==> Epoch: 813 / 99999 | Validation loss: 30.12510 |  Validation Accuracy: 4.63981 | Validation Metric (MAE)): 4.63981\n",
      "Load Model from best epoch 813\n",
      "Training Stage ==> Epoch: 814 / 99999 | Training loss: 30.98315 |  Training Accuracy: 4.61496 | Training Metric (MAE): 4.61496\n",
      "Validation Stage ==> Epoch: 814 / 99999 | Validation loss: 30.12210 |  Validation Accuracy: 4.63949 | Validation Metric (MAE)): 4.63949\n",
      "Load Model from best epoch 814\n",
      "Training Stage ==> Epoch: 815 / 99999 | Training loss: 28.76556 |  Training Accuracy: 4.60792 | Training Metric (MAE): 4.60792\n",
      "Validation Stage ==> Epoch: 815 / 99999 | Validation loss: 30.11911 |  Validation Accuracy: 4.63917 | Validation Metric (MAE)): 4.63917\n",
      "Load Model from best epoch 815\n",
      "Training Stage ==> Epoch: 816 / 99999 | Training loss: 28.04205 |  Training Accuracy: 4.61898 | Training Metric (MAE): 4.61898\n",
      "Validation Stage ==> Epoch: 816 / 99999 | Validation loss: 30.11611 |  Validation Accuracy: 4.63885 | Validation Metric (MAE)): 4.63885\n",
      "Load Model from best epoch 816\n",
      "Training Stage ==> Epoch: 817 / 99999 | Training loss: 29.65416 |  Training Accuracy: 4.61146 | Training Metric (MAE): 4.61146\n",
      "Validation Stage ==> Epoch: 817 / 99999 | Validation loss: 30.11311 |  Validation Accuracy: 4.63853 | Validation Metric (MAE)): 4.63853\n",
      "Load Model from best epoch 817\n",
      "Training Stage ==> Epoch: 818 / 99999 | Training loss: 29.61266 |  Training Accuracy: 4.62759 | Training Metric (MAE): 4.62759\n",
      "Validation Stage ==> Epoch: 818 / 99999 | Validation loss: 30.11012 |  Validation Accuracy: 4.63821 | Validation Metric (MAE)): 4.63821\n",
      "Load Model from best epoch 818\n",
      "Training Stage ==> Epoch: 819 / 99999 | Training loss: 29.06241 |  Training Accuracy: 4.62158 | Training Metric (MAE): 4.62158\n",
      "Validation Stage ==> Epoch: 819 / 99999 | Validation loss: 30.10714 |  Validation Accuracy: 4.63789 | Validation Metric (MAE)): 4.63789\n",
      "Load Model from best epoch 819\n",
      "Training Stage ==> Epoch: 820 / 99999 | Training loss: 30.45765 |  Training Accuracy: 4.62125 | Training Metric (MAE): 4.62125\n",
      "Validation Stage ==> Epoch: 820 / 99999 | Validation loss: 30.10415 |  Validation Accuracy: 4.63757 | Validation Metric (MAE)): 4.63757\n",
      "Load Model from best epoch 820\n",
      "Training Stage ==> Epoch: 821 / 99999 | Training loss: 28.03147 |  Training Accuracy: 4.61948 | Training Metric (MAE): 4.61948\n",
      "Validation Stage ==> Epoch: 821 / 99999 | Validation loss: 30.10115 |  Validation Accuracy: 4.63724 | Validation Metric (MAE)): 4.63724\n",
      "Load Model from best epoch 821\n",
      "Training Stage ==> Epoch: 822 / 99999 | Training loss: 29.52768 |  Training Accuracy: 4.61097 | Training Metric (MAE): 4.61097\n",
      "Validation Stage ==> Epoch: 822 / 99999 | Validation loss: 30.09816 |  Validation Accuracy: 4.63692 | Validation Metric (MAE)): 4.63692\n",
      "Load Model from best epoch 822\n",
      "Training Stage ==> Epoch: 823 / 99999 | Training loss: 30.48294 |  Training Accuracy: 4.62941 | Training Metric (MAE): 4.62941\n",
      "Validation Stage ==> Epoch: 823 / 99999 | Validation loss: 30.09517 |  Validation Accuracy: 4.63660 | Validation Metric (MAE)): 4.63660\n",
      "Load Model from best epoch 823\n",
      "Training Stage ==> Epoch: 824 / 99999 | Training loss: 30.18908 |  Training Accuracy: 4.62586 | Training Metric (MAE): 4.62586\n",
      "Validation Stage ==> Epoch: 824 / 99999 | Validation loss: 30.09217 |  Validation Accuracy: 4.63628 | Validation Metric (MAE)): 4.63628\n",
      "Load Model from best epoch 824\n",
      "Training Stage ==> Epoch: 825 / 99999 | Training loss: 27.88673 |  Training Accuracy: 4.62144 | Training Metric (MAE): 4.62144\n",
      "Validation Stage ==> Epoch: 825 / 99999 | Validation loss: 30.08919 |  Validation Accuracy: 4.63596 | Validation Metric (MAE)): 4.63596\n",
      "Load Model from best epoch 825\n",
      "Training Stage ==> Epoch: 826 / 99999 | Training loss: 30.50284 |  Training Accuracy: 4.60657 | Training Metric (MAE): 4.60657\n",
      "Validation Stage ==> Epoch: 826 / 99999 | Validation loss: 30.08620 |  Validation Accuracy: 4.63564 | Validation Metric (MAE)): 4.63564\n",
      "Load Model from best epoch 826\n",
      "Training Stage ==> Epoch: 827 / 99999 | Training loss: 29.18787 |  Training Accuracy: 4.61431 | Training Metric (MAE): 4.61431\n",
      "Validation Stage ==> Epoch: 827 / 99999 | Validation loss: 30.08321 |  Validation Accuracy: 4.63532 | Validation Metric (MAE)): 4.63532\n",
      "Load Model from best epoch 827\n",
      "Training Stage ==> Epoch: 828 / 99999 | Training loss: 28.08496 |  Training Accuracy: 4.61755 | Training Metric (MAE): 4.61755\n",
      "Validation Stage ==> Epoch: 828 / 99999 | Validation loss: 30.08022 |  Validation Accuracy: 4.63500 | Validation Metric (MAE)): 4.63500\n",
      "Load Model from best epoch 828\n",
      "Training Stage ==> Epoch: 829 / 99999 | Training loss: 28.17826 |  Training Accuracy: 4.60992 | Training Metric (MAE): 4.60992\n",
      "Validation Stage ==> Epoch: 829 / 99999 | Validation loss: 30.07724 |  Validation Accuracy: 4.63468 | Validation Metric (MAE)): 4.63468\n",
      "Load Model from best epoch 829\n",
      "Training Stage ==> Epoch: 830 / 99999 | Training loss: 29.73537 |  Training Accuracy: 4.60512 | Training Metric (MAE): 4.60512\n",
      "Validation Stage ==> Epoch: 830 / 99999 | Validation loss: 30.07425 |  Validation Accuracy: 4.63436 | Validation Metric (MAE)): 4.63436\n",
      "Load Model from best epoch 830\n",
      "Training Stage ==> Epoch: 831 / 99999 | Training loss: 29.27139 |  Training Accuracy: 4.62111 | Training Metric (MAE): 4.62111\n",
      "Validation Stage ==> Epoch: 831 / 99999 | Validation loss: 30.07126 |  Validation Accuracy: 4.63404 | Validation Metric (MAE)): 4.63404\n",
      "Load Model from best epoch 831\n",
      "Training Stage ==> Epoch: 832 / 99999 | Training loss: 29.77780 |  Training Accuracy: 4.59625 | Training Metric (MAE): 4.59625\n",
      "Validation Stage ==> Epoch: 832 / 99999 | Validation loss: 30.06827 |  Validation Accuracy: 4.63372 | Validation Metric (MAE)): 4.63372\n",
      "Load Model from best epoch 832\n",
      "Training Stage ==> Epoch: 833 / 99999 | Training loss: 28.35266 |  Training Accuracy: 4.62096 | Training Metric (MAE): 4.62096\n",
      "Validation Stage ==> Epoch: 833 / 99999 | Validation loss: 30.06528 |  Validation Accuracy: 4.63340 | Validation Metric (MAE)): 4.63340\n",
      "Load Model from best epoch 833\n",
      "Training Stage ==> Epoch: 834 / 99999 | Training loss: 28.30742 |  Training Accuracy: 4.60830 | Training Metric (MAE): 4.60830\n",
      "Validation Stage ==> Epoch: 834 / 99999 | Validation loss: 30.06230 |  Validation Accuracy: 4.63308 | Validation Metric (MAE)): 4.63308\n",
      "Load Model from best epoch 834\n",
      "Training Stage ==> Epoch: 835 / 99999 | Training loss: 29.30344 |  Training Accuracy: 4.61464 | Training Metric (MAE): 4.61464\n",
      "Validation Stage ==> Epoch: 835 / 99999 | Validation loss: 30.05931 |  Validation Accuracy: 4.63276 | Validation Metric (MAE)): 4.63276\n",
      "Load Model from best epoch 835\n",
      "Training Stage ==> Epoch: 836 / 99999 | Training loss: 28.77828 |  Training Accuracy: 4.61733 | Training Metric (MAE): 4.61733\n",
      "Validation Stage ==> Epoch: 836 / 99999 | Validation loss: 30.05633 |  Validation Accuracy: 4.63244 | Validation Metric (MAE)): 4.63244\n",
      "Load Model from best epoch 836\n",
      "Training Stage ==> Epoch: 837 / 99999 | Training loss: 28.54436 |  Training Accuracy: 4.61159 | Training Metric (MAE): 4.61159\n",
      "Validation Stage ==> Epoch: 837 / 99999 | Validation loss: 30.05335 |  Validation Accuracy: 4.63212 | Validation Metric (MAE)): 4.63212\n",
      "Load Model from best epoch 837\n",
      "Training Stage ==> Epoch: 838 / 99999 | Training loss: 28.92303 |  Training Accuracy: 4.61695 | Training Metric (MAE): 4.61695\n",
      "Validation Stage ==> Epoch: 838 / 99999 | Validation loss: 30.05036 |  Validation Accuracy: 4.63180 | Validation Metric (MAE)): 4.63180\n",
      "Load Model from best epoch 838\n",
      "Training Stage ==> Epoch: 839 / 99999 | Training loss: 30.24105 |  Training Accuracy: 4.61547 | Training Metric (MAE): 4.61547\n",
      "Validation Stage ==> Epoch: 839 / 99999 | Validation loss: 30.04738 |  Validation Accuracy: 4.63148 | Validation Metric (MAE)): 4.63148\n",
      "Load Model from best epoch 839\n",
      "Training Stage ==> Epoch: 840 / 99999 | Training loss: 28.14041 |  Training Accuracy: 4.62620 | Training Metric (MAE): 4.62620\n",
      "Validation Stage ==> Epoch: 840 / 99999 | Validation loss: 30.04440 |  Validation Accuracy: 4.63116 | Validation Metric (MAE)): 4.63116\n",
      "Load Model from best epoch 840\n",
      "Training Stage ==> Epoch: 841 / 99999 | Training loss: 30.17516 |  Training Accuracy: 4.61067 | Training Metric (MAE): 4.61067\n",
      "Validation Stage ==> Epoch: 841 / 99999 | Validation loss: 30.04142 |  Validation Accuracy: 4.63084 | Validation Metric (MAE)): 4.63084\n",
      "Load Model from best epoch 841\n",
      "Training Stage ==> Epoch: 842 / 99999 | Training loss: 29.69229 |  Training Accuracy: 4.61954 | Training Metric (MAE): 4.61954\n",
      "Validation Stage ==> Epoch: 842 / 99999 | Validation loss: 30.03845 |  Validation Accuracy: 4.63052 | Validation Metric (MAE)): 4.63052\n",
      "Load Model from best epoch 842\n",
      "Training Stage ==> Epoch: 843 / 99999 | Training loss: 28.67118 |  Training Accuracy: 4.61103 | Training Metric (MAE): 4.61103\n",
      "Validation Stage ==> Epoch: 843 / 99999 | Validation loss: 30.03546 |  Validation Accuracy: 4.63020 | Validation Metric (MAE)): 4.63020\n",
      "Load Model from best epoch 843\n",
      "Training Stage ==> Epoch: 844 / 99999 | Training loss: 30.21856 |  Training Accuracy: 4.60399 | Training Metric (MAE): 4.60399\n",
      "Validation Stage ==> Epoch: 844 / 99999 | Validation loss: 30.03248 |  Validation Accuracy: 4.62988 | Validation Metric (MAE)): 4.62988\n",
      "Load Model from best epoch 844\n",
      "Training Stage ==> Epoch: 845 / 99999 | Training loss: 28.41459 |  Training Accuracy: 4.61752 | Training Metric (MAE): 4.61752\n",
      "Validation Stage ==> Epoch: 845 / 99999 | Validation loss: 30.02951 |  Validation Accuracy: 4.62956 | Validation Metric (MAE)): 4.62956\n",
      "Load Model from best epoch 845\n",
      "Training Stage ==> Epoch: 846 / 99999 | Training loss: 30.30579 |  Training Accuracy: 4.59821 | Training Metric (MAE): 4.59821\n",
      "Validation Stage ==> Epoch: 846 / 99999 | Validation loss: 30.02653 |  Validation Accuracy: 4.62924 | Validation Metric (MAE)): 4.62924\n",
      "Load Model from best epoch 846\n",
      "Training Stage ==> Epoch: 847 / 99999 | Training loss: 28.26641 |  Training Accuracy: 4.60128 | Training Metric (MAE): 4.60128\n",
      "Validation Stage ==> Epoch: 847 / 99999 | Validation loss: 30.02355 |  Validation Accuracy: 4.62893 | Validation Metric (MAE)): 4.62893\n",
      "Load Model from best epoch 847\n",
      "Training Stage ==> Epoch: 848 / 99999 | Training loss: 28.58101 |  Training Accuracy: 4.60865 | Training Metric (MAE): 4.60865\n",
      "Validation Stage ==> Epoch: 848 / 99999 | Validation loss: 30.02058 |  Validation Accuracy: 4.62861 | Validation Metric (MAE)): 4.62861\n",
      "Load Model from best epoch 848\n",
      "Training Stage ==> Epoch: 849 / 99999 | Training loss: 30.89780 |  Training Accuracy: 4.60496 | Training Metric (MAE): 4.60496\n",
      "Validation Stage ==> Epoch: 849 / 99999 | Validation loss: 30.01760 |  Validation Accuracy: 4.62829 | Validation Metric (MAE)): 4.62829\n",
      "Load Model from best epoch 849\n",
      "Training Stage ==> Epoch: 850 / 99999 | Training loss: 29.92346 |  Training Accuracy: 4.59726 | Training Metric (MAE): 4.59726\n",
      "Validation Stage ==> Epoch: 850 / 99999 | Validation loss: 30.01463 |  Validation Accuracy: 4.62797 | Validation Metric (MAE)): 4.62797\n",
      "Load Model from best epoch 850\n",
      "Training Stage ==> Epoch: 851 / 99999 | Training loss: 31.23073 |  Training Accuracy: 4.61153 | Training Metric (MAE): 4.61153\n",
      "Validation Stage ==> Epoch: 851 / 99999 | Validation loss: 30.01165 |  Validation Accuracy: 4.62765 | Validation Metric (MAE)): 4.62765\n",
      "Load Model from best epoch 851\n",
      "Training Stage ==> Epoch: 852 / 99999 | Training loss: 29.03652 |  Training Accuracy: 4.60696 | Training Metric (MAE): 4.60696\n",
      "Validation Stage ==> Epoch: 852 / 99999 | Validation loss: 30.00869 |  Validation Accuracy: 4.62733 | Validation Metric (MAE)): 4.62733\n",
      "Load Model from best epoch 852\n",
      "Training Stage ==> Epoch: 853 / 99999 | Training loss: 31.02112 |  Training Accuracy: 4.60706 | Training Metric (MAE): 4.60706\n",
      "Validation Stage ==> Epoch: 853 / 99999 | Validation loss: 30.00571 |  Validation Accuracy: 4.62701 | Validation Metric (MAE)): 4.62701\n",
      "Load Model from best epoch 853\n",
      "Training Stage ==> Epoch: 854 / 99999 | Training loss: 31.31502 |  Training Accuracy: 4.60562 | Training Metric (MAE): 4.60562\n",
      "Validation Stage ==> Epoch: 854 / 99999 | Validation loss: 30.00275 |  Validation Accuracy: 4.62669 | Validation Metric (MAE)): 4.62669\n",
      "Load Model from best epoch 854\n",
      "Training Stage ==> Epoch: 855 / 99999 | Training loss: 30.40157 |  Training Accuracy: 4.60180 | Training Metric (MAE): 4.60180\n",
      "Validation Stage ==> Epoch: 855 / 99999 | Validation loss: 29.99978 |  Validation Accuracy: 4.62637 | Validation Metric (MAE)): 4.62637\n",
      "Load Model from best epoch 855\n",
      "Training Stage ==> Epoch: 856 / 99999 | Training loss: 30.78541 |  Training Accuracy: 4.60089 | Training Metric (MAE): 4.60089\n",
      "Validation Stage ==> Epoch: 856 / 99999 | Validation loss: 29.99680 |  Validation Accuracy: 4.62605 | Validation Metric (MAE)): 4.62605\n",
      "Load Model from best epoch 856\n",
      "Training Stage ==> Epoch: 857 / 99999 | Training loss: 31.01933 |  Training Accuracy: 4.59932 | Training Metric (MAE): 4.59932\n",
      "Validation Stage ==> Epoch: 857 / 99999 | Validation loss: 29.99382 |  Validation Accuracy: 4.62573 | Validation Metric (MAE)): 4.62573\n",
      "Load Model from best epoch 857\n",
      "Training Stage ==> Epoch: 858 / 99999 | Training loss: 28.70028 |  Training Accuracy: 4.61348 | Training Metric (MAE): 4.61348\n",
      "Validation Stage ==> Epoch: 858 / 99999 | Validation loss: 29.99085 |  Validation Accuracy: 4.62541 | Validation Metric (MAE)): 4.62541\n",
      "Load Model from best epoch 858\n",
      "Training Stage ==> Epoch: 859 / 99999 | Training loss: 28.70614 |  Training Accuracy: 4.59519 | Training Metric (MAE): 4.59519\n",
      "Validation Stage ==> Epoch: 859 / 99999 | Validation loss: 29.98789 |  Validation Accuracy: 4.62510 | Validation Metric (MAE)): 4.62510\n",
      "Load Model from best epoch 859\n",
      "Training Stage ==> Epoch: 860 / 99999 | Training loss: 29.90241 |  Training Accuracy: 4.58693 | Training Metric (MAE): 4.58693\n",
      "Validation Stage ==> Epoch: 860 / 99999 | Validation loss: 29.98491 |  Validation Accuracy: 4.62478 | Validation Metric (MAE)): 4.62478\n",
      "Load Model from best epoch 860\n",
      "Training Stage ==> Epoch: 861 / 99999 | Training loss: 28.72028 |  Training Accuracy: 4.60628 | Training Metric (MAE): 4.60628\n",
      "Validation Stage ==> Epoch: 861 / 99999 | Validation loss: 29.98196 |  Validation Accuracy: 4.62446 | Validation Metric (MAE)): 4.62446\n",
      "Load Model from best epoch 861\n",
      "Training Stage ==> Epoch: 862 / 99999 | Training loss: 30.51933 |  Training Accuracy: 4.61030 | Training Metric (MAE): 4.61030\n",
      "Validation Stage ==> Epoch: 862 / 99999 | Validation loss: 29.97898 |  Validation Accuracy: 4.62414 | Validation Metric (MAE)): 4.62414\n",
      "Load Model from best epoch 862\n",
      "Training Stage ==> Epoch: 863 / 99999 | Training loss: 27.98829 |  Training Accuracy: 4.60372 | Training Metric (MAE): 4.60372\n",
      "Validation Stage ==> Epoch: 863 / 99999 | Validation loss: 29.97602 |  Validation Accuracy: 4.62382 | Validation Metric (MAE)): 4.62382\n",
      "Load Model from best epoch 863\n",
      "Training Stage ==> Epoch: 864 / 99999 | Training loss: 28.97350 |  Training Accuracy: 4.60413 | Training Metric (MAE): 4.60413\n",
      "Validation Stage ==> Epoch: 864 / 99999 | Validation loss: 29.97305 |  Validation Accuracy: 4.62350 | Validation Metric (MAE)): 4.62350\n",
      "Load Model from best epoch 864\n",
      "Training Stage ==> Epoch: 865 / 99999 | Training loss: 28.18899 |  Training Accuracy: 4.58010 | Training Metric (MAE): 4.58010\n",
      "Validation Stage ==> Epoch: 865 / 99999 | Validation loss: 29.97009 |  Validation Accuracy: 4.62318 | Validation Metric (MAE)): 4.62318\n",
      "Load Model from best epoch 865\n",
      "Training Stage ==> Epoch: 866 / 99999 | Training loss: 29.49983 |  Training Accuracy: 4.59301 | Training Metric (MAE): 4.59301\n",
      "Validation Stage ==> Epoch: 866 / 99999 | Validation loss: 29.96713 |  Validation Accuracy: 4.62287 | Validation Metric (MAE)): 4.62287\n",
      "Load Model from best epoch 866\n",
      "Training Stage ==> Epoch: 867 / 99999 | Training loss: 27.85274 |  Training Accuracy: 4.60466 | Training Metric (MAE): 4.60466\n",
      "Validation Stage ==> Epoch: 867 / 99999 | Validation loss: 29.96416 |  Validation Accuracy: 4.62255 | Validation Metric (MAE)): 4.62255\n",
      "Load Model from best epoch 867\n",
      "Training Stage ==> Epoch: 868 / 99999 | Training loss: 29.52813 |  Training Accuracy: 4.59895 | Training Metric (MAE): 4.59895\n",
      "Validation Stage ==> Epoch: 868 / 99999 | Validation loss: 29.96120 |  Validation Accuracy: 4.62223 | Validation Metric (MAE)): 4.62223\n",
      "Load Model from best epoch 868\n",
      "Training Stage ==> Epoch: 869 / 99999 | Training loss: 30.78716 |  Training Accuracy: 4.59203 | Training Metric (MAE): 4.59203\n",
      "Validation Stage ==> Epoch: 869 / 99999 | Validation loss: 29.95823 |  Validation Accuracy: 4.62191 | Validation Metric (MAE)): 4.62191\n",
      "Load Model from best epoch 869\n",
      "Training Stage ==> Epoch: 870 / 99999 | Training loss: 28.01867 |  Training Accuracy: 4.60501 | Training Metric (MAE): 4.60501\n",
      "Validation Stage ==> Epoch: 870 / 99999 | Validation loss: 29.95528 |  Validation Accuracy: 4.62159 | Validation Metric (MAE)): 4.62159\n",
      "Load Model from best epoch 870\n",
      "Training Stage ==> Epoch: 871 / 99999 | Training loss: 27.76143 |  Training Accuracy: 4.60901 | Training Metric (MAE): 4.60901\n",
      "Validation Stage ==> Epoch: 871 / 99999 | Validation loss: 29.95231 |  Validation Accuracy: 4.62127 | Validation Metric (MAE)): 4.62127\n",
      "Load Model from best epoch 871\n",
      "Training Stage ==> Epoch: 872 / 99999 | Training loss: 28.87414 |  Training Accuracy: 4.60872 | Training Metric (MAE): 4.60872\n",
      "Validation Stage ==> Epoch: 872 / 99999 | Validation loss: 29.94935 |  Validation Accuracy: 4.62096 | Validation Metric (MAE)): 4.62096\n",
      "Load Model from best epoch 872\n",
      "Training Stage ==> Epoch: 873 / 99999 | Training loss: 30.36467 |  Training Accuracy: 4.60404 | Training Metric (MAE): 4.60404\n",
      "Validation Stage ==> Epoch: 873 / 99999 | Validation loss: 29.94639 |  Validation Accuracy: 4.62064 | Validation Metric (MAE)): 4.62064\n",
      "Load Model from best epoch 873\n",
      "Training Stage ==> Epoch: 874 / 99999 | Training loss: 28.92966 |  Training Accuracy: 4.60106 | Training Metric (MAE): 4.60106\n",
      "Validation Stage ==> Epoch: 874 / 99999 | Validation loss: 29.94343 |  Validation Accuracy: 4.62032 | Validation Metric (MAE)): 4.62032\n",
      "Load Model from best epoch 874\n",
      "Training Stage ==> Epoch: 875 / 99999 | Training loss: 30.43300 |  Training Accuracy: 4.59461 | Training Metric (MAE): 4.59461\n",
      "Validation Stage ==> Epoch: 875 / 99999 | Validation loss: 29.94047 |  Validation Accuracy: 4.62000 | Validation Metric (MAE)): 4.62000\n",
      "Load Model from best epoch 875\n",
      "Training Stage ==> Epoch: 876 / 99999 | Training loss: 29.02004 |  Training Accuracy: 4.59645 | Training Metric (MAE): 4.59645\n",
      "Validation Stage ==> Epoch: 876 / 99999 | Validation loss: 29.93751 |  Validation Accuracy: 4.61968 | Validation Metric (MAE)): 4.61968\n",
      "Load Model from best epoch 876\n",
      "Training Stage ==> Epoch: 877 / 99999 | Training loss: 29.42157 |  Training Accuracy: 4.59957 | Training Metric (MAE): 4.59957\n",
      "Validation Stage ==> Epoch: 877 / 99999 | Validation loss: 29.93454 |  Validation Accuracy: 4.61936 | Validation Metric (MAE)): 4.61936\n",
      "Load Model from best epoch 877\n",
      "Training Stage ==> Epoch: 878 / 99999 | Training loss: 28.90009 |  Training Accuracy: 4.61149 | Training Metric (MAE): 4.61149\n",
      "Validation Stage ==> Epoch: 878 / 99999 | Validation loss: 29.93158 |  Validation Accuracy: 4.61905 | Validation Metric (MAE)): 4.61905\n",
      "Load Model from best epoch 878\n",
      "Training Stage ==> Epoch: 879 / 99999 | Training loss: 29.56458 |  Training Accuracy: 4.59453 | Training Metric (MAE): 4.59453\n",
      "Validation Stage ==> Epoch: 879 / 99999 | Validation loss: 29.92862 |  Validation Accuracy: 4.61873 | Validation Metric (MAE)): 4.61873\n",
      "Load Model from best epoch 879\n",
      "Training Stage ==> Epoch: 880 / 99999 | Training loss: 30.76222 |  Training Accuracy: 4.59016 | Training Metric (MAE): 4.59016\n",
      "Validation Stage ==> Epoch: 880 / 99999 | Validation loss: 29.92566 |  Validation Accuracy: 4.61841 | Validation Metric (MAE)): 4.61841\n",
      "Load Model from best epoch 880\n",
      "Training Stage ==> Epoch: 881 / 99999 | Training loss: 28.72620 |  Training Accuracy: 4.61219 | Training Metric (MAE): 4.61219\n",
      "Validation Stage ==> Epoch: 881 / 99999 | Validation loss: 29.92270 |  Validation Accuracy: 4.61809 | Validation Metric (MAE)): 4.61809\n",
      "Load Model from best epoch 881\n",
      "Training Stage ==> Epoch: 882 / 99999 | Training loss: 31.42715 |  Training Accuracy: 4.59464 | Training Metric (MAE): 4.59464\n",
      "Validation Stage ==> Epoch: 882 / 99999 | Validation loss: 29.91973 |  Validation Accuracy: 4.61777 | Validation Metric (MAE)): 4.61777\n",
      "Load Model from best epoch 882\n",
      "Training Stage ==> Epoch: 883 / 99999 | Training loss: 29.73585 |  Training Accuracy: 4.59261 | Training Metric (MAE): 4.59261\n",
      "Validation Stage ==> Epoch: 883 / 99999 | Validation loss: 29.91678 |  Validation Accuracy: 4.61745 | Validation Metric (MAE)): 4.61745\n",
      "Load Model from best epoch 883\n",
      "Training Stage ==> Epoch: 884 / 99999 | Training loss: 28.21695 |  Training Accuracy: 4.61288 | Training Metric (MAE): 4.61288\n",
      "Validation Stage ==> Epoch: 884 / 99999 | Validation loss: 29.91383 |  Validation Accuracy: 4.61714 | Validation Metric (MAE)): 4.61714\n",
      "Load Model from best epoch 884\n",
      "Training Stage ==> Epoch: 885 / 99999 | Training loss: 29.56229 |  Training Accuracy: 4.59281 | Training Metric (MAE): 4.59281\n",
      "Validation Stage ==> Epoch: 885 / 99999 | Validation loss: 29.91087 |  Validation Accuracy: 4.61682 | Validation Metric (MAE)): 4.61682\n",
      "Load Model from best epoch 885\n",
      "Training Stage ==> Epoch: 886 / 99999 | Training loss: 30.26991 |  Training Accuracy: 4.60425 | Training Metric (MAE): 4.60425\n",
      "Validation Stage ==> Epoch: 886 / 99999 | Validation loss: 29.90791 |  Validation Accuracy: 4.61650 | Validation Metric (MAE)): 4.61650\n",
      "Load Model from best epoch 886\n",
      "Training Stage ==> Epoch: 887 / 99999 | Training loss: 30.62025 |  Training Accuracy: 4.58803 | Training Metric (MAE): 4.58803\n",
      "Validation Stage ==> Epoch: 887 / 99999 | Validation loss: 29.90495 |  Validation Accuracy: 4.61618 | Validation Metric (MAE)): 4.61618\n",
      "Load Model from best epoch 887\n",
      "Training Stage ==> Epoch: 888 / 99999 | Training loss: 29.86176 |  Training Accuracy: 4.59267 | Training Metric (MAE): 4.59267\n",
      "Validation Stage ==> Epoch: 888 / 99999 | Validation loss: 29.90200 |  Validation Accuracy: 4.61586 | Validation Metric (MAE)): 4.61586\n",
      "Load Model from best epoch 888\n",
      "Training Stage ==> Epoch: 889 / 99999 | Training loss: 28.76551 |  Training Accuracy: 4.60091 | Training Metric (MAE): 4.60091\n",
      "Validation Stage ==> Epoch: 889 / 99999 | Validation loss: 29.89905 |  Validation Accuracy: 4.61555 | Validation Metric (MAE)): 4.61555\n",
      "Load Model from best epoch 889\n",
      "Training Stage ==> Epoch: 890 / 99999 | Training loss: 30.12266 |  Training Accuracy: 4.61255 | Training Metric (MAE): 4.61255\n",
      "Validation Stage ==> Epoch: 890 / 99999 | Validation loss: 29.89610 |  Validation Accuracy: 4.61523 | Validation Metric (MAE)): 4.61523\n",
      "Load Model from best epoch 890\n",
      "Training Stage ==> Epoch: 891 / 99999 | Training loss: 29.48782 |  Training Accuracy: 4.59897 | Training Metric (MAE): 4.59897\n",
      "Validation Stage ==> Epoch: 891 / 99999 | Validation loss: 29.89314 |  Validation Accuracy: 4.61491 | Validation Metric (MAE)): 4.61491\n",
      "Load Model from best epoch 891\n",
      "Training Stage ==> Epoch: 892 / 99999 | Training loss: 29.63120 |  Training Accuracy: 4.59098 | Training Metric (MAE): 4.59098\n",
      "Validation Stage ==> Epoch: 892 / 99999 | Validation loss: 29.89019 |  Validation Accuracy: 4.61459 | Validation Metric (MAE)): 4.61459\n",
      "Load Model from best epoch 892\n",
      "Training Stage ==> Epoch: 893 / 99999 | Training loss: 28.69562 |  Training Accuracy: 4.60080 | Training Metric (MAE): 4.60080\n",
      "Validation Stage ==> Epoch: 893 / 99999 | Validation loss: 29.88725 |  Validation Accuracy: 4.61427 | Validation Metric (MAE)): 4.61427\n",
      "Load Model from best epoch 893\n",
      "Training Stage ==> Epoch: 894 / 99999 | Training loss: 30.06134 |  Training Accuracy: 4.60567 | Training Metric (MAE): 4.60567\n",
      "Validation Stage ==> Epoch: 894 / 99999 | Validation loss: 29.88430 |  Validation Accuracy: 4.61396 | Validation Metric (MAE)): 4.61396\n",
      "Load Model from best epoch 894\n",
      "Training Stage ==> Epoch: 895 / 99999 | Training loss: 30.97762 |  Training Accuracy: 4.60106 | Training Metric (MAE): 4.60106\n",
      "Validation Stage ==> Epoch: 895 / 99999 | Validation loss: 29.88135 |  Validation Accuracy: 4.61364 | Validation Metric (MAE)): 4.61364\n",
      "Load Model from best epoch 895\n",
      "Training Stage ==> Epoch: 896 / 99999 | Training loss: 29.20134 |  Training Accuracy: 4.58311 | Training Metric (MAE): 4.58311\n",
      "Validation Stage ==> Epoch: 896 / 99999 | Validation loss: 29.87840 |  Validation Accuracy: 4.61333 | Validation Metric (MAE)): 4.61333\n",
      "Load Model from best epoch 896\n",
      "Training Stage ==> Epoch: 897 / 99999 | Training loss: 27.89737 |  Training Accuracy: 4.59628 | Training Metric (MAE): 4.59628\n",
      "Validation Stage ==> Epoch: 897 / 99999 | Validation loss: 29.87546 |  Validation Accuracy: 4.61305 | Validation Metric (MAE)): 4.61305\n",
      "Load Model from best epoch 897\n",
      "Training Stage ==> Epoch: 898 / 99999 | Training loss: 30.36926 |  Training Accuracy: 4.59365 | Training Metric (MAE): 4.59365\n",
      "Validation Stage ==> Epoch: 898 / 99999 | Validation loss: 29.87251 |  Validation Accuracy: 4.61277 | Validation Metric (MAE)): 4.61277\n",
      "Load Model from best epoch 898\n",
      "Training Stage ==> Epoch: 899 / 99999 | Training loss: 26.98396 |  Training Accuracy: 4.59657 | Training Metric (MAE): 4.59657\n",
      "Validation Stage ==> Epoch: 899 / 99999 | Validation loss: 29.86958 |  Validation Accuracy: 4.61252 | Validation Metric (MAE)): 4.61252\n",
      "Load Model from best epoch 899\n",
      "Training Stage ==> Epoch: 900 / 99999 | Training loss: 29.81358 |  Training Accuracy: 4.60299 | Training Metric (MAE): 4.60299\n",
      "Validation Stage ==> Epoch: 900 / 99999 | Validation loss: 29.86663 |  Validation Accuracy: 4.61226 | Validation Metric (MAE)): 4.61226\n",
      "Load Model from best epoch 900\n",
      "Training Stage ==> Epoch: 901 / 99999 | Training loss: 28.93898 |  Training Accuracy: 4.59161 | Training Metric (MAE): 4.59161\n",
      "Validation Stage ==> Epoch: 901 / 99999 | Validation loss: 29.86369 |  Validation Accuracy: 4.61201 | Validation Metric (MAE)): 4.61201\n",
      "Load Model from best epoch 901\n",
      "Training Stage ==> Epoch: 902 / 99999 | Training loss: 31.02608 |  Training Accuracy: 4.60321 | Training Metric (MAE): 4.60321\n",
      "Validation Stage ==> Epoch: 902 / 99999 | Validation loss: 29.86074 |  Validation Accuracy: 4.61175 | Validation Metric (MAE)): 4.61175\n",
      "Load Model from best epoch 902\n",
      "Training Stage ==> Epoch: 903 / 99999 | Training loss: 30.16694 |  Training Accuracy: 4.58540 | Training Metric (MAE): 4.58540\n",
      "Validation Stage ==> Epoch: 903 / 99999 | Validation loss: 29.85780 |  Validation Accuracy: 4.61150 | Validation Metric (MAE)): 4.61150\n",
      "Load Model from best epoch 903\n",
      "Training Stage ==> Epoch: 904 / 99999 | Training loss: 27.78367 |  Training Accuracy: 4.58664 | Training Metric (MAE): 4.58664\n",
      "Validation Stage ==> Epoch: 904 / 99999 | Validation loss: 29.85486 |  Validation Accuracy: 4.61124 | Validation Metric (MAE)): 4.61124\n",
      "Load Model from best epoch 904\n",
      "Training Stage ==> Epoch: 905 / 99999 | Training loss: 30.52364 |  Training Accuracy: 4.60002 | Training Metric (MAE): 4.60002\n",
      "Validation Stage ==> Epoch: 905 / 99999 | Validation loss: 29.85192 |  Validation Accuracy: 4.61099 | Validation Metric (MAE)): 4.61099\n",
      "Load Model from best epoch 905\n",
      "Training Stage ==> Epoch: 906 / 99999 | Training loss: 29.36566 |  Training Accuracy: 4.58896 | Training Metric (MAE): 4.58896\n",
      "Validation Stage ==> Epoch: 906 / 99999 | Validation loss: 29.84898 |  Validation Accuracy: 4.61074 | Validation Metric (MAE)): 4.61074\n",
      "Load Model from best epoch 906\n",
      "Training Stage ==> Epoch: 907 / 99999 | Training loss: 28.36415 |  Training Accuracy: 4.58420 | Training Metric (MAE): 4.58420\n",
      "Validation Stage ==> Epoch: 907 / 99999 | Validation loss: 29.84603 |  Validation Accuracy: 4.61048 | Validation Metric (MAE)): 4.61048\n",
      "Load Model from best epoch 907\n",
      "Training Stage ==> Epoch: 908 / 99999 | Training loss: 29.65333 |  Training Accuracy: 4.59273 | Training Metric (MAE): 4.59273\n",
      "Validation Stage ==> Epoch: 908 / 99999 | Validation loss: 29.84309 |  Validation Accuracy: 4.61023 | Validation Metric (MAE)): 4.61023\n",
      "Load Model from best epoch 908\n",
      "Training Stage ==> Epoch: 909 / 99999 | Training loss: 31.33243 |  Training Accuracy: 4.59263 | Training Metric (MAE): 4.59263\n",
      "Validation Stage ==> Epoch: 909 / 99999 | Validation loss: 29.84014 |  Validation Accuracy: 4.60997 | Validation Metric (MAE)): 4.60997\n",
      "Load Model from best epoch 909\n",
      "Training Stage ==> Epoch: 910 / 99999 | Training loss: 30.15471 |  Training Accuracy: 4.60074 | Training Metric (MAE): 4.60074\n",
      "Validation Stage ==> Epoch: 910 / 99999 | Validation loss: 29.83720 |  Validation Accuracy: 4.60972 | Validation Metric (MAE)): 4.60972\n",
      "Load Model from best epoch 910\n",
      "Training Stage ==> Epoch: 911 / 99999 | Training loss: 28.71934 |  Training Accuracy: 4.58556 | Training Metric (MAE): 4.58556\n",
      "Validation Stage ==> Epoch: 911 / 99999 | Validation loss: 29.83426 |  Validation Accuracy: 4.60946 | Validation Metric (MAE)): 4.60946\n",
      "Load Model from best epoch 911\n",
      "Training Stage ==> Epoch: 912 / 99999 | Training loss: 28.88517 |  Training Accuracy: 4.59796 | Training Metric (MAE): 4.59796\n",
      "Validation Stage ==> Epoch: 912 / 99999 | Validation loss: 29.83132 |  Validation Accuracy: 4.60921 | Validation Metric (MAE)): 4.60921\n",
      "Load Model from best epoch 912\n",
      "Training Stage ==> Epoch: 913 / 99999 | Training loss: 26.55803 |  Training Accuracy: 4.59843 | Training Metric (MAE): 4.59843\n",
      "Validation Stage ==> Epoch: 913 / 99999 | Validation loss: 29.82839 |  Validation Accuracy: 4.60896 | Validation Metric (MAE)): 4.60896\n",
      "Load Model from best epoch 913\n",
      "Training Stage ==> Epoch: 914 / 99999 | Training loss: 30.31073 |  Training Accuracy: 4.58288 | Training Metric (MAE): 4.58288\n",
      "Validation Stage ==> Epoch: 914 / 99999 | Validation loss: 29.82544 |  Validation Accuracy: 4.60870 | Validation Metric (MAE)): 4.60870\n",
      "Load Model from best epoch 914\n",
      "Training Stage ==> Epoch: 915 / 99999 | Training loss: 29.54082 |  Training Accuracy: 4.58184 | Training Metric (MAE): 4.58184\n",
      "Validation Stage ==> Epoch: 915 / 99999 | Validation loss: 29.82251 |  Validation Accuracy: 4.60845 | Validation Metric (MAE)): 4.60845\n",
      "Load Model from best epoch 915\n",
      "Training Stage ==> Epoch: 916 / 99999 | Training loss: 28.97761 |  Training Accuracy: 4.58852 | Training Metric (MAE): 4.58852\n",
      "Validation Stage ==> Epoch: 916 / 99999 | Validation loss: 29.81957 |  Validation Accuracy: 4.60819 | Validation Metric (MAE)): 4.60819\n",
      "Load Model from best epoch 916\n",
      "Training Stage ==> Epoch: 917 / 99999 | Training loss: 29.87069 |  Training Accuracy: 4.57766 | Training Metric (MAE): 4.57766\n",
      "Validation Stage ==> Epoch: 917 / 99999 | Validation loss: 29.81664 |  Validation Accuracy: 4.60794 | Validation Metric (MAE)): 4.60794\n",
      "Load Model from best epoch 917\n",
      "Training Stage ==> Epoch: 918 / 99999 | Training loss: 28.29367 |  Training Accuracy: 4.58312 | Training Metric (MAE): 4.58312\n",
      "Validation Stage ==> Epoch: 918 / 99999 | Validation loss: 29.81370 |  Validation Accuracy: 4.60768 | Validation Metric (MAE)): 4.60768\n",
      "Load Model from best epoch 918\n",
      "Training Stage ==> Epoch: 919 / 99999 | Training loss: 28.42959 |  Training Accuracy: 4.58212 | Training Metric (MAE): 4.58212\n",
      "Validation Stage ==> Epoch: 919 / 99999 | Validation loss: 29.81078 |  Validation Accuracy: 4.60743 | Validation Metric (MAE)): 4.60743\n",
      "Load Model from best epoch 919\n",
      "Training Stage ==> Epoch: 920 / 99999 | Training loss: 29.98562 |  Training Accuracy: 4.58849 | Training Metric (MAE): 4.58849\n",
      "Validation Stage ==> Epoch: 920 / 99999 | Validation loss: 29.80785 |  Validation Accuracy: 4.60718 | Validation Metric (MAE)): 4.60718\n",
      "Load Model from best epoch 920\n",
      "Training Stage ==> Epoch: 921 / 99999 | Training loss: 29.81997 |  Training Accuracy: 4.59642 | Training Metric (MAE): 4.59642\n",
      "Validation Stage ==> Epoch: 921 / 99999 | Validation loss: 29.80491 |  Validation Accuracy: 4.60692 | Validation Metric (MAE)): 4.60692\n",
      "Load Model from best epoch 921\n",
      "Training Stage ==> Epoch: 922 / 99999 | Training loss: 28.26454 |  Training Accuracy: 4.59276 | Training Metric (MAE): 4.59276\n",
      "Validation Stage ==> Epoch: 922 / 99999 | Validation loss: 29.80198 |  Validation Accuracy: 4.60667 | Validation Metric (MAE)): 4.60667\n",
      "Load Model from best epoch 922\n",
      "Training Stage ==> Epoch: 923 / 99999 | Training loss: 30.23393 |  Training Accuracy: 4.59193 | Training Metric (MAE): 4.59193\n",
      "Validation Stage ==> Epoch: 923 / 99999 | Validation loss: 29.79905 |  Validation Accuracy: 4.60642 | Validation Metric (MAE)): 4.60642\n",
      "Load Model from best epoch 923\n",
      "Training Stage ==> Epoch: 924 / 99999 | Training loss: 28.63126 |  Training Accuracy: 4.58712 | Training Metric (MAE): 4.58712\n",
      "Validation Stage ==> Epoch: 924 / 99999 | Validation loss: 29.79612 |  Validation Accuracy: 4.60616 | Validation Metric (MAE)): 4.60616\n",
      "Load Model from best epoch 924\n",
      "Training Stage ==> Epoch: 925 / 99999 | Training loss: 28.72161 |  Training Accuracy: 4.58894 | Training Metric (MAE): 4.58894\n",
      "Validation Stage ==> Epoch: 925 / 99999 | Validation loss: 29.79319 |  Validation Accuracy: 4.60591 | Validation Metric (MAE)): 4.60591\n",
      "Load Model from best epoch 925\n",
      "Training Stage ==> Epoch: 926 / 99999 | Training loss: 31.20847 |  Training Accuracy: 4.57899 | Training Metric (MAE): 4.57899\n",
      "Validation Stage ==> Epoch: 926 / 99999 | Validation loss: 29.79025 |  Validation Accuracy: 4.60565 | Validation Metric (MAE)): 4.60565\n",
      "Load Model from best epoch 926\n",
      "Training Stage ==> Epoch: 927 / 99999 | Training loss: 30.99944 |  Training Accuracy: 4.57611 | Training Metric (MAE): 4.57611\n",
      "Validation Stage ==> Epoch: 927 / 99999 | Validation loss: 29.78732 |  Validation Accuracy: 4.60540 | Validation Metric (MAE)): 4.60540\n",
      "Load Model from best epoch 927\n",
      "Training Stage ==> Epoch: 928 / 99999 | Training loss: 29.81544 |  Training Accuracy: 4.58634 | Training Metric (MAE): 4.58634\n",
      "Validation Stage ==> Epoch: 928 / 99999 | Validation loss: 29.78439 |  Validation Accuracy: 4.60515 | Validation Metric (MAE)): 4.60515\n",
      "Load Model from best epoch 928\n",
      "Training Stage ==> Epoch: 929 / 99999 | Training loss: 27.71118 |  Training Accuracy: 4.60287 | Training Metric (MAE): 4.60287\n",
      "Validation Stage ==> Epoch: 929 / 99999 | Validation loss: 29.78147 |  Validation Accuracy: 4.60489 | Validation Metric (MAE)): 4.60489\n",
      "Load Model from best epoch 929\n",
      "Training Stage ==> Epoch: 930 / 99999 | Training loss: 28.88118 |  Training Accuracy: 4.58471 | Training Metric (MAE): 4.58471\n",
      "Validation Stage ==> Epoch: 930 / 99999 | Validation loss: 29.77854 |  Validation Accuracy: 4.60464 | Validation Metric (MAE)): 4.60464\n",
      "Load Model from best epoch 930\n",
      "Training Stage ==> Epoch: 931 / 99999 | Training loss: 27.71587 |  Training Accuracy: 4.58440 | Training Metric (MAE): 4.58440\n",
      "Validation Stage ==> Epoch: 931 / 99999 | Validation loss: 29.77561 |  Validation Accuracy: 4.60439 | Validation Metric (MAE)): 4.60439\n",
      "Load Model from best epoch 931\n",
      "Training Stage ==> Epoch: 932 / 99999 | Training loss: 29.26117 |  Training Accuracy: 4.59395 | Training Metric (MAE): 4.59395\n",
      "Validation Stage ==> Epoch: 932 / 99999 | Validation loss: 29.77269 |  Validation Accuracy: 4.60413 | Validation Metric (MAE)): 4.60413\n",
      "Load Model from best epoch 932\n",
      "Training Stage ==> Epoch: 933 / 99999 | Training loss: 29.32311 |  Training Accuracy: 4.58637 | Training Metric (MAE): 4.58637\n",
      "Validation Stage ==> Epoch: 933 / 99999 | Validation loss: 29.76977 |  Validation Accuracy: 4.60388 | Validation Metric (MAE)): 4.60388\n",
      "Load Model from best epoch 933\n",
      "Training Stage ==> Epoch: 934 / 99999 | Training loss: 28.32645 |  Training Accuracy: 4.58608 | Training Metric (MAE): 4.58608\n",
      "Validation Stage ==> Epoch: 934 / 99999 | Validation loss: 29.76684 |  Validation Accuracy: 4.60363 | Validation Metric (MAE)): 4.60363\n",
      "Load Model from best epoch 934\n",
      "Training Stage ==> Epoch: 935 / 99999 | Training loss: 29.25922 |  Training Accuracy: 4.59916 | Training Metric (MAE): 4.59916\n",
      "Validation Stage ==> Epoch: 935 / 99999 | Validation loss: 29.76391 |  Validation Accuracy: 4.60337 | Validation Metric (MAE)): 4.60337\n",
      "Load Model from best epoch 935\n",
      "Training Stage ==> Epoch: 936 / 99999 | Training loss: 29.68885 |  Training Accuracy: 4.58977 | Training Metric (MAE): 4.58977\n",
      "Validation Stage ==> Epoch: 936 / 99999 | Validation loss: 29.76099 |  Validation Accuracy: 4.60312 | Validation Metric (MAE)): 4.60312\n",
      "Load Model from best epoch 936\n",
      "Training Stage ==> Epoch: 937 / 99999 | Training loss: 29.01904 |  Training Accuracy: 4.58565 | Training Metric (MAE): 4.58565\n",
      "Validation Stage ==> Epoch: 937 / 99999 | Validation loss: 29.75806 |  Validation Accuracy: 4.60287 | Validation Metric (MAE)): 4.60287\n",
      "Load Model from best epoch 937\n",
      "Training Stage ==> Epoch: 938 / 99999 | Training loss: 29.38576 |  Training Accuracy: 4.58828 | Training Metric (MAE): 4.58828\n",
      "Validation Stage ==> Epoch: 938 / 99999 | Validation loss: 29.75514 |  Validation Accuracy: 4.60261 | Validation Metric (MAE)): 4.60261\n",
      "Load Model from best epoch 938\n",
      "Training Stage ==> Epoch: 939 / 99999 | Training loss: 28.65815 |  Training Accuracy: 4.58685 | Training Metric (MAE): 4.58685\n",
      "Validation Stage ==> Epoch: 939 / 99999 | Validation loss: 29.75222 |  Validation Accuracy: 4.60236 | Validation Metric (MAE)): 4.60236\n",
      "Load Model from best epoch 939\n",
      "Training Stage ==> Epoch: 940 / 99999 | Training loss: 29.04918 |  Training Accuracy: 4.57339 | Training Metric (MAE): 4.57339\n",
      "Validation Stage ==> Epoch: 940 / 99999 | Validation loss: 29.74930 |  Validation Accuracy: 4.60211 | Validation Metric (MAE)): 4.60211\n",
      "Load Model from best epoch 940\n",
      "Training Stage ==> Epoch: 941 / 99999 | Training loss: 28.75383 |  Training Accuracy: 4.56898 | Training Metric (MAE): 4.56898\n",
      "Validation Stage ==> Epoch: 941 / 99999 | Validation loss: 29.74638 |  Validation Accuracy: 4.60185 | Validation Metric (MAE)): 4.60185\n",
      "Load Model from best epoch 941\n",
      "Training Stage ==> Epoch: 942 / 99999 | Training loss: 28.56735 |  Training Accuracy: 4.57928 | Training Metric (MAE): 4.57928\n",
      "Validation Stage ==> Epoch: 942 / 99999 | Validation loss: 29.74346 |  Validation Accuracy: 4.60160 | Validation Metric (MAE)): 4.60160\n",
      "Load Model from best epoch 942\n",
      "Training Stage ==> Epoch: 943 / 99999 | Training loss: 30.22080 |  Training Accuracy: 4.56408 | Training Metric (MAE): 4.56408\n",
      "Validation Stage ==> Epoch: 943 / 99999 | Validation loss: 29.74054 |  Validation Accuracy: 4.60135 | Validation Metric (MAE)): 4.60135\n",
      "Load Model from best epoch 943\n",
      "Training Stage ==> Epoch: 944 / 99999 | Training loss: 29.13241 |  Training Accuracy: 4.58495 | Training Metric (MAE): 4.58495\n",
      "Validation Stage ==> Epoch: 944 / 99999 | Validation loss: 29.73762 |  Validation Accuracy: 4.60109 | Validation Metric (MAE)): 4.60109\n",
      "Load Model from best epoch 944\n",
      "Training Stage ==> Epoch: 945 / 99999 | Training loss: 28.36316 |  Training Accuracy: 4.58112 | Training Metric (MAE): 4.58112\n",
      "Validation Stage ==> Epoch: 945 / 99999 | Validation loss: 29.73471 |  Validation Accuracy: 4.60084 | Validation Metric (MAE)): 4.60084\n",
      "Load Model from best epoch 945\n",
      "Training Stage ==> Epoch: 946 / 99999 | Training loss: 29.42448 |  Training Accuracy: 4.58493 | Training Metric (MAE): 4.58493\n",
      "Validation Stage ==> Epoch: 946 / 99999 | Validation loss: 29.73179 |  Validation Accuracy: 4.60059 | Validation Metric (MAE)): 4.60059\n",
      "Load Model from best epoch 946\n",
      "Training Stage ==> Epoch: 947 / 99999 | Training loss: 29.03911 |  Training Accuracy: 4.59240 | Training Metric (MAE): 4.59240\n",
      "Validation Stage ==> Epoch: 947 / 99999 | Validation loss: 29.72887 |  Validation Accuracy: 4.60034 | Validation Metric (MAE)): 4.60034\n",
      "Load Model from best epoch 947\n",
      "Training Stage ==> Epoch: 948 / 99999 | Training loss: 28.58003 |  Training Accuracy: 4.58832 | Training Metric (MAE): 4.58832\n",
      "Validation Stage ==> Epoch: 948 / 99999 | Validation loss: 29.72596 |  Validation Accuracy: 4.60008 | Validation Metric (MAE)): 4.60008\n",
      "Load Model from best epoch 948\n",
      "Training Stage ==> Epoch: 949 / 99999 | Training loss: 28.17149 |  Training Accuracy: 4.57820 | Training Metric (MAE): 4.57820\n",
      "Validation Stage ==> Epoch: 949 / 99999 | Validation loss: 29.72305 |  Validation Accuracy: 4.59983 | Validation Metric (MAE)): 4.59983\n",
      "Load Model from best epoch 949\n",
      "Training Stage ==> Epoch: 950 / 99999 | Training loss: 29.17124 |  Training Accuracy: 4.57150 | Training Metric (MAE): 4.57150\n",
      "Validation Stage ==> Epoch: 950 / 99999 | Validation loss: 29.72014 |  Validation Accuracy: 4.59958 | Validation Metric (MAE)): 4.59958\n",
      "Load Model from best epoch 950\n",
      "Training Stage ==> Epoch: 951 / 99999 | Training loss: 29.33040 |  Training Accuracy: 4.58993 | Training Metric (MAE): 4.58993\n",
      "Validation Stage ==> Epoch: 951 / 99999 | Validation loss: 29.71722 |  Validation Accuracy: 4.59933 | Validation Metric (MAE)): 4.59933\n",
      "Load Model from best epoch 951\n",
      "Training Stage ==> Epoch: 952 / 99999 | Training loss: 29.71420 |  Training Accuracy: 4.57809 | Training Metric (MAE): 4.57809\n",
      "Validation Stage ==> Epoch: 952 / 99999 | Validation loss: 29.71430 |  Validation Accuracy: 4.59907 | Validation Metric (MAE)): 4.59907\n",
      "Load Model from best epoch 952\n",
      "Training Stage ==> Epoch: 953 / 99999 | Training loss: 28.80385 |  Training Accuracy: 4.58010 | Training Metric (MAE): 4.58010\n",
      "Validation Stage ==> Epoch: 953 / 99999 | Validation loss: 29.71139 |  Validation Accuracy: 4.59882 | Validation Metric (MAE)): 4.59882\n",
      "Load Model from best epoch 953\n",
      "Training Stage ==> Epoch: 954 / 99999 | Training loss: 30.14376 |  Training Accuracy: 4.57841 | Training Metric (MAE): 4.57841\n",
      "Validation Stage ==> Epoch: 954 / 99999 | Validation loss: 29.70848 |  Validation Accuracy: 4.59857 | Validation Metric (MAE)): 4.59857\n",
      "Load Model from best epoch 954\n",
      "Training Stage ==> Epoch: 955 / 99999 | Training loss: 28.98349 |  Training Accuracy: 4.57080 | Training Metric (MAE): 4.57080\n",
      "Validation Stage ==> Epoch: 955 / 99999 | Validation loss: 29.70556 |  Validation Accuracy: 4.59831 | Validation Metric (MAE)): 4.59831\n",
      "Load Model from best epoch 955\n",
      "Training Stage ==> Epoch: 956 / 99999 | Training loss: 26.80293 |  Training Accuracy: 4.57017 | Training Metric (MAE): 4.57017\n",
      "Validation Stage ==> Epoch: 956 / 99999 | Validation loss: 29.70266 |  Validation Accuracy: 4.59806 | Validation Metric (MAE)): 4.59806\n",
      "Load Model from best epoch 956\n",
      "Training Stage ==> Epoch: 957 / 99999 | Training loss: 27.74092 |  Training Accuracy: 4.58385 | Training Metric (MAE): 4.58385\n",
      "Validation Stage ==> Epoch: 957 / 99999 | Validation loss: 29.69974 |  Validation Accuracy: 4.59781 | Validation Metric (MAE)): 4.59781\n",
      "Load Model from best epoch 957\n",
      "Training Stage ==> Epoch: 958 / 99999 | Training loss: 29.27765 |  Training Accuracy: 4.57575 | Training Metric (MAE): 4.57575\n",
      "Validation Stage ==> Epoch: 958 / 99999 | Validation loss: 29.69683 |  Validation Accuracy: 4.59756 | Validation Metric (MAE)): 4.59756\n",
      "Load Model from best epoch 958\n",
      "Training Stage ==> Epoch: 959 / 99999 | Training loss: 27.60577 |  Training Accuracy: 4.57916 | Training Metric (MAE): 4.57916\n",
      "Validation Stage ==> Epoch: 959 / 99999 | Validation loss: 29.69393 |  Validation Accuracy: 4.59730 | Validation Metric (MAE)): 4.59730\n",
      "Load Model from best epoch 959\n",
      "Training Stage ==> Epoch: 960 / 99999 | Training loss: 30.52374 |  Training Accuracy: 4.57556 | Training Metric (MAE): 4.57556\n",
      "Validation Stage ==> Epoch: 960 / 99999 | Validation loss: 29.69102 |  Validation Accuracy: 4.59705 | Validation Metric (MAE)): 4.59705\n",
      "Load Model from best epoch 960\n",
      "Training Stage ==> Epoch: 961 / 99999 | Training loss: 29.80723 |  Training Accuracy: 4.57998 | Training Metric (MAE): 4.57998\n",
      "Validation Stage ==> Epoch: 961 / 99999 | Validation loss: 29.68811 |  Validation Accuracy: 4.59680 | Validation Metric (MAE)): 4.59680\n",
      "Load Model from best epoch 961\n",
      "Training Stage ==> Epoch: 962 / 99999 | Training loss: 28.03537 |  Training Accuracy: 4.58596 | Training Metric (MAE): 4.58596\n",
      "Validation Stage ==> Epoch: 962 / 99999 | Validation loss: 29.68521 |  Validation Accuracy: 4.59655 | Validation Metric (MAE)): 4.59655\n",
      "Load Model from best epoch 962\n",
      "Training Stage ==> Epoch: 963 / 99999 | Training loss: 28.96990 |  Training Accuracy: 4.57947 | Training Metric (MAE): 4.57947\n",
      "Validation Stage ==> Epoch: 963 / 99999 | Validation loss: 29.68230 |  Validation Accuracy: 4.59630 | Validation Metric (MAE)): 4.59630\n",
      "Load Model from best epoch 963\n",
      "Training Stage ==> Epoch: 964 / 99999 | Training loss: 28.19389 |  Training Accuracy: 4.57420 | Training Metric (MAE): 4.57420\n",
      "Validation Stage ==> Epoch: 964 / 99999 | Validation loss: 29.67940 |  Validation Accuracy: 4.59604 | Validation Metric (MAE)): 4.59604\n",
      "Load Model from best epoch 964\n",
      "Training Stage ==> Epoch: 965 / 99999 | Training loss: 28.29039 |  Training Accuracy: 4.58132 | Training Metric (MAE): 4.58132\n",
      "Validation Stage ==> Epoch: 965 / 99999 | Validation loss: 29.67650 |  Validation Accuracy: 4.59579 | Validation Metric (MAE)): 4.59579\n",
      "Load Model from best epoch 965\n",
      "Training Stage ==> Epoch: 966 / 99999 | Training loss: 28.87407 |  Training Accuracy: 4.58836 | Training Metric (MAE): 4.58836\n",
      "Validation Stage ==> Epoch: 966 / 99999 | Validation loss: 29.67359 |  Validation Accuracy: 4.59554 | Validation Metric (MAE)): 4.59554\n",
      "Load Model from best epoch 966\n",
      "Training Stage ==> Epoch: 967 / 99999 | Training loss: 29.01822 |  Training Accuracy: 4.57596 | Training Metric (MAE): 4.57596\n",
      "Validation Stage ==> Epoch: 967 / 99999 | Validation loss: 29.67069 |  Validation Accuracy: 4.59529 | Validation Metric (MAE)): 4.59529\n",
      "Load Model from best epoch 967\n",
      "Training Stage ==> Epoch: 968 / 99999 | Training loss: 28.49175 |  Training Accuracy: 4.57354 | Training Metric (MAE): 4.57354\n",
      "Validation Stage ==> Epoch: 968 / 99999 | Validation loss: 29.66779 |  Validation Accuracy: 4.59504 | Validation Metric (MAE)): 4.59504\n",
      "Load Model from best epoch 968\n",
      "Training Stage ==> Epoch: 969 / 99999 | Training loss: 27.84002 |  Training Accuracy: 4.57193 | Training Metric (MAE): 4.57193\n",
      "Validation Stage ==> Epoch: 969 / 99999 | Validation loss: 29.66489 |  Validation Accuracy: 4.59478 | Validation Metric (MAE)): 4.59478\n",
      "Load Model from best epoch 969\n",
      "Training Stage ==> Epoch: 970 / 99999 | Training loss: 28.61685 |  Training Accuracy: 4.57041 | Training Metric (MAE): 4.57041\n",
      "Validation Stage ==> Epoch: 970 / 99999 | Validation loss: 29.66199 |  Validation Accuracy: 4.59453 | Validation Metric (MAE)): 4.59453\n",
      "Load Model from best epoch 970\n",
      "Training Stage ==> Epoch: 971 / 99999 | Training loss: 29.02795 |  Training Accuracy: 4.57831 | Training Metric (MAE): 4.57831\n",
      "Validation Stage ==> Epoch: 971 / 99999 | Validation loss: 29.65909 |  Validation Accuracy: 4.59428 | Validation Metric (MAE)): 4.59428\n",
      "Load Model from best epoch 971\n",
      "Training Stage ==> Epoch: 972 / 99999 | Training loss: 27.91626 |  Training Accuracy: 4.57733 | Training Metric (MAE): 4.57733\n",
      "Validation Stage ==> Epoch: 972 / 99999 | Validation loss: 29.65619 |  Validation Accuracy: 4.59403 | Validation Metric (MAE)): 4.59403\n",
      "Load Model from best epoch 972\n",
      "Training Stage ==> Epoch: 973 / 99999 | Training loss: 29.51343 |  Training Accuracy: 4.56840 | Training Metric (MAE): 4.56840\n",
      "Validation Stage ==> Epoch: 973 / 99999 | Validation loss: 29.65329 |  Validation Accuracy: 4.59378 | Validation Metric (MAE)): 4.59378\n",
      "Load Model from best epoch 973\n",
      "Training Stage ==> Epoch: 974 / 99999 | Training loss: 27.85607 |  Training Accuracy: 4.57657 | Training Metric (MAE): 4.57657\n",
      "Validation Stage ==> Epoch: 974 / 99999 | Validation loss: 29.65040 |  Validation Accuracy: 4.59352 | Validation Metric (MAE)): 4.59352\n",
      "Load Model from best epoch 974\n",
      "Training Stage ==> Epoch: 975 / 99999 | Training loss: 28.83805 |  Training Accuracy: 4.56234 | Training Metric (MAE): 4.56234\n",
      "Validation Stage ==> Epoch: 975 / 99999 | Validation loss: 29.64749 |  Validation Accuracy: 4.59327 | Validation Metric (MAE)): 4.59327\n",
      "Load Model from best epoch 975\n",
      "Training Stage ==> Epoch: 976 / 99999 | Training loss: 28.84300 |  Training Accuracy: 4.57166 | Training Metric (MAE): 4.57166\n",
      "Validation Stage ==> Epoch: 976 / 99999 | Validation loss: 29.64460 |  Validation Accuracy: 4.59302 | Validation Metric (MAE)): 4.59302\n",
      "Load Model from best epoch 976\n",
      "Training Stage ==> Epoch: 977 / 99999 | Training loss: 30.54801 |  Training Accuracy: 4.58066 | Training Metric (MAE): 4.58066\n",
      "Validation Stage ==> Epoch: 977 / 99999 | Validation loss: 29.64169 |  Validation Accuracy: 4.59277 | Validation Metric (MAE)): 4.59277\n",
      "Load Model from best epoch 977\n",
      "Training Stage ==> Epoch: 978 / 99999 | Training loss: 29.16848 |  Training Accuracy: 4.57115 | Training Metric (MAE): 4.57115\n",
      "Validation Stage ==> Epoch: 978 / 99999 | Validation loss: 29.63880 |  Validation Accuracy: 4.59252 | Validation Metric (MAE)): 4.59252\n",
      "Load Model from best epoch 978\n",
      "Training Stage ==> Epoch: 979 / 99999 | Training loss: 28.83269 |  Training Accuracy: 4.57232 | Training Metric (MAE): 4.57232\n",
      "Validation Stage ==> Epoch: 979 / 99999 | Validation loss: 29.63590 |  Validation Accuracy: 4.59227 | Validation Metric (MAE)): 4.59227\n",
      "Load Model from best epoch 979\n",
      "Training Stage ==> Epoch: 980 / 99999 | Training loss: 29.91035 |  Training Accuracy: 4.57451 | Training Metric (MAE): 4.57451\n",
      "Validation Stage ==> Epoch: 980 / 99999 | Validation loss: 29.63301 |  Validation Accuracy: 4.59201 | Validation Metric (MAE)): 4.59201\n",
      "Load Model from best epoch 980\n",
      "Training Stage ==> Epoch: 981 / 99999 | Training loss: 29.91498 |  Training Accuracy: 4.58457 | Training Metric (MAE): 4.58457\n",
      "Validation Stage ==> Epoch: 981 / 99999 | Validation loss: 29.63011 |  Validation Accuracy: 4.59176 | Validation Metric (MAE)): 4.59176\n",
      "Load Model from best epoch 981\n",
      "Training Stage ==> Epoch: 982 / 99999 | Training loss: 25.84758 |  Training Accuracy: 4.57589 | Training Metric (MAE): 4.57589\n",
      "Validation Stage ==> Epoch: 982 / 99999 | Validation loss: 29.62722 |  Validation Accuracy: 4.59151 | Validation Metric (MAE)): 4.59151\n",
      "Load Model from best epoch 982\n",
      "Training Stage ==> Epoch: 983 / 99999 | Training loss: 29.13354 |  Training Accuracy: 4.56741 | Training Metric (MAE): 4.56741\n",
      "Validation Stage ==> Epoch: 983 / 99999 | Validation loss: 29.62432 |  Validation Accuracy: 4.59126 | Validation Metric (MAE)): 4.59126\n",
      "Load Model from best epoch 983\n",
      "Training Stage ==> Epoch: 984 / 99999 | Training loss: 28.58672 |  Training Accuracy: 4.57716 | Training Metric (MAE): 4.57716\n",
      "Validation Stage ==> Epoch: 984 / 99999 | Validation loss: 29.62143 |  Validation Accuracy: 4.59101 | Validation Metric (MAE)): 4.59101\n",
      "Load Model from best epoch 984\n",
      "Training Stage ==> Epoch: 985 / 99999 | Training loss: 29.60219 |  Training Accuracy: 4.57067 | Training Metric (MAE): 4.57067\n",
      "Validation Stage ==> Epoch: 985 / 99999 | Validation loss: 29.61853 |  Validation Accuracy: 4.59075 | Validation Metric (MAE)): 4.59075\n",
      "Load Model from best epoch 985\n",
      "Training Stage ==> Epoch: 986 / 99999 | Training loss: 28.74580 |  Training Accuracy: 4.57534 | Training Metric (MAE): 4.57534\n",
      "Validation Stage ==> Epoch: 986 / 99999 | Validation loss: 29.61564 |  Validation Accuracy: 4.59050 | Validation Metric (MAE)): 4.59050\n",
      "Load Model from best epoch 986\n",
      "Training Stage ==> Epoch: 987 / 99999 | Training loss: 30.57269 |  Training Accuracy: 4.57350 | Training Metric (MAE): 4.57350\n",
      "Validation Stage ==> Epoch: 987 / 99999 | Validation loss: 29.61275 |  Validation Accuracy: 4.59025 | Validation Metric (MAE)): 4.59025\n",
      "Load Model from best epoch 987\n",
      "Training Stage ==> Epoch: 988 / 99999 | Training loss: 29.79906 |  Training Accuracy: 4.57322 | Training Metric (MAE): 4.57322\n",
      "Validation Stage ==> Epoch: 988 / 99999 | Validation loss: 29.60986 |  Validation Accuracy: 4.59000 | Validation Metric (MAE)): 4.59000\n",
      "Load Model from best epoch 988\n",
      "Training Stage ==> Epoch: 989 / 99999 | Training loss: 29.55894 |  Training Accuracy: 4.56864 | Training Metric (MAE): 4.56864\n",
      "Validation Stage ==> Epoch: 989 / 99999 | Validation loss: 29.60697 |  Validation Accuracy: 4.58975 | Validation Metric (MAE)): 4.58975\n",
      "Load Model from best epoch 989\n",
      "Training Stage ==> Epoch: 990 / 99999 | Training loss: 28.80692 |  Training Accuracy: 4.57433 | Training Metric (MAE): 4.57433\n",
      "Validation Stage ==> Epoch: 990 / 99999 | Validation loss: 29.60409 |  Validation Accuracy: 4.58950 | Validation Metric (MAE)): 4.58950\n",
      "Load Model from best epoch 990\n",
      "Training Stage ==> Epoch: 991 / 99999 | Training loss: 27.70709 |  Training Accuracy: 4.56296 | Training Metric (MAE): 4.56296\n",
      "Validation Stage ==> Epoch: 991 / 99999 | Validation loss: 29.60120 |  Validation Accuracy: 4.58925 | Validation Metric (MAE)): 4.58925\n",
      "Load Model from best epoch 991\n",
      "Training Stage ==> Epoch: 992 / 99999 | Training loss: 29.90156 |  Training Accuracy: 4.57626 | Training Metric (MAE): 4.57626\n",
      "Validation Stage ==> Epoch: 992 / 99999 | Validation loss: 29.59831 |  Validation Accuracy: 4.58900 | Validation Metric (MAE)): 4.58900\n",
      "Load Model from best epoch 992\n",
      "Training Stage ==> Epoch: 993 / 99999 | Training loss: 29.97613 |  Training Accuracy: 4.56879 | Training Metric (MAE): 4.56879\n",
      "Validation Stage ==> Epoch: 993 / 99999 | Validation loss: 29.59542 |  Validation Accuracy: 4.58875 | Validation Metric (MAE)): 4.58875\n",
      "Load Model from best epoch 993\n",
      "Training Stage ==> Epoch: 994 / 99999 | Training loss: 29.46510 |  Training Accuracy: 4.56907 | Training Metric (MAE): 4.56907\n",
      "Validation Stage ==> Epoch: 994 / 99999 | Validation loss: 29.59253 |  Validation Accuracy: 4.58849 | Validation Metric (MAE)): 4.58849\n",
      "Load Model from best epoch 994\n",
      "Training Stage ==> Epoch: 995 / 99999 | Training loss: 29.64981 |  Training Accuracy: 4.55044 | Training Metric (MAE): 4.55044\n",
      "Validation Stage ==> Epoch: 995 / 99999 | Validation loss: 29.58964 |  Validation Accuracy: 4.58824 | Validation Metric (MAE)): 4.58824\n",
      "Load Model from best epoch 995\n",
      "Training Stage ==> Epoch: 996 / 99999 | Training loss: 28.58143 |  Training Accuracy: 4.56742 | Training Metric (MAE): 4.56742\n",
      "Validation Stage ==> Epoch: 996 / 99999 | Validation loss: 29.58676 |  Validation Accuracy: 4.58799 | Validation Metric (MAE)): 4.58799\n",
      "Load Model from best epoch 996\n",
      "Training Stage ==> Epoch: 997 / 99999 | Training loss: 29.86419 |  Training Accuracy: 4.57802 | Training Metric (MAE): 4.57802\n",
      "Validation Stage ==> Epoch: 997 / 99999 | Validation loss: 29.58386 |  Validation Accuracy: 4.58774 | Validation Metric (MAE)): 4.58774\n",
      "Load Model from best epoch 997\n",
      "Training Stage ==> Epoch: 998 / 99999 | Training loss: 29.18194 |  Training Accuracy: 4.58138 | Training Metric (MAE): 4.58138\n",
      "Validation Stage ==> Epoch: 998 / 99999 | Validation loss: 29.58098 |  Validation Accuracy: 4.58749 | Validation Metric (MAE)): 4.58749\n",
      "Load Model from best epoch 998\n",
      "Training Stage ==> Epoch: 999 / 99999 | Training loss: 28.80171 |  Training Accuracy: 4.56987 | Training Metric (MAE): 4.56987\n",
      "Validation Stage ==> Epoch: 999 / 99999 | Validation loss: 29.57809 |  Validation Accuracy: 4.58724 | Validation Metric (MAE)): 4.58724\n",
      "Load Model from best epoch 999\n",
      "Training Stage ==> Epoch: 1000 / 99999 | Training loss: 29.10276 |  Training Accuracy: 4.57265 | Training Metric (MAE): 4.57265\n",
      "Validation Stage ==> Epoch: 1000 / 99999 | Validation loss: 29.57521 |  Validation Accuracy: 4.58699 | Validation Metric (MAE)): 4.58699\n",
      "Load Model from best epoch 1000\n",
      "Training Stage ==> Epoch: 1001 / 99999 | Training loss: 28.18212 |  Training Accuracy: 4.56488 | Training Metric (MAE): 4.56488\n",
      "Validation Stage ==> Epoch: 1001 / 99999 | Validation loss: 29.57233 |  Validation Accuracy: 4.58674 | Validation Metric (MAE)): 4.58674\n",
      "Load Model from best epoch 1001\n",
      "Training Stage ==> Epoch: 1002 / 99999 | Training loss: 28.44887 |  Training Accuracy: 4.56261 | Training Metric (MAE): 4.56261\n",
      "Validation Stage ==> Epoch: 1002 / 99999 | Validation loss: 29.56945 |  Validation Accuracy: 4.58649 | Validation Metric (MAE)): 4.58649\n",
      "Load Model from best epoch 1002\n",
      "Training Stage ==> Epoch: 1003 / 99999 | Training loss: 28.96249 |  Training Accuracy: 4.57678 | Training Metric (MAE): 4.57678\n",
      "Validation Stage ==> Epoch: 1003 / 99999 | Validation loss: 29.56658 |  Validation Accuracy: 4.58624 | Validation Metric (MAE)): 4.58624\n",
      "Load Model from best epoch 1003\n",
      "Training Stage ==> Epoch: 1004 / 99999 | Training loss: 29.28966 |  Training Accuracy: 4.57086 | Training Metric (MAE): 4.57086\n",
      "Validation Stage ==> Epoch: 1004 / 99999 | Validation loss: 29.56370 |  Validation Accuracy: 4.58599 | Validation Metric (MAE)): 4.58599\n",
      "Load Model from best epoch 1004\n",
      "Training Stage ==> Epoch: 1005 / 99999 | Training loss: 28.71460 |  Training Accuracy: 4.57979 | Training Metric (MAE): 4.57979\n",
      "Validation Stage ==> Epoch: 1005 / 99999 | Validation loss: 29.56083 |  Validation Accuracy: 4.58574 | Validation Metric (MAE)): 4.58574\n",
      "Load Model from best epoch 1005\n",
      "Training Stage ==> Epoch: 1006 / 99999 | Training loss: 30.53153 |  Training Accuracy: 4.56088 | Training Metric (MAE): 4.56088\n",
      "Validation Stage ==> Epoch: 1006 / 99999 | Validation loss: 29.55795 |  Validation Accuracy: 4.58548 | Validation Metric (MAE)): 4.58548\n",
      "Load Model from best epoch 1006\n",
      "Training Stage ==> Epoch: 1007 / 99999 | Training loss: 28.09336 |  Training Accuracy: 4.56582 | Training Metric (MAE): 4.56582\n",
      "Validation Stage ==> Epoch: 1007 / 99999 | Validation loss: 29.55507 |  Validation Accuracy: 4.58523 | Validation Metric (MAE)): 4.58523\n",
      "Load Model from best epoch 1007\n",
      "Training Stage ==> Epoch: 1008 / 99999 | Training loss: 27.75323 |  Training Accuracy: 4.55718 | Training Metric (MAE): 4.55718\n",
      "Validation Stage ==> Epoch: 1008 / 99999 | Validation loss: 29.55219 |  Validation Accuracy: 4.58498 | Validation Metric (MAE)): 4.58498\n",
      "Load Model from best epoch 1008\n",
      "Training Stage ==> Epoch: 1009 / 99999 | Training loss: 30.38481 |  Training Accuracy: 4.55604 | Training Metric (MAE): 4.55604\n",
      "Validation Stage ==> Epoch: 1009 / 99999 | Validation loss: 29.54931 |  Validation Accuracy: 4.58473 | Validation Metric (MAE)): 4.58473\n",
      "Load Model from best epoch 1009\n",
      "Training Stage ==> Epoch: 1010 / 99999 | Training loss: 29.30063 |  Training Accuracy: 4.56575 | Training Metric (MAE): 4.56575\n",
      "Validation Stage ==> Epoch: 1010 / 99999 | Validation loss: 29.54644 |  Validation Accuracy: 4.58448 | Validation Metric (MAE)): 4.58448\n",
      "Load Model from best epoch 1010\n",
      "Training Stage ==> Epoch: 1011 / 99999 | Training loss: 29.20622 |  Training Accuracy: 4.57028 | Training Metric (MAE): 4.57028\n",
      "Validation Stage ==> Epoch: 1011 / 99999 | Validation loss: 29.54357 |  Validation Accuracy: 4.58423 | Validation Metric (MAE)): 4.58423\n",
      "Load Model from best epoch 1011\n",
      "Training Stage ==> Epoch: 1012 / 99999 | Training loss: 27.41170 |  Training Accuracy: 4.56087 | Training Metric (MAE): 4.56087\n",
      "Validation Stage ==> Epoch: 1012 / 99999 | Validation loss: 29.54069 |  Validation Accuracy: 4.58398 | Validation Metric (MAE)): 4.58398\n",
      "Load Model from best epoch 1012\n",
      "Training Stage ==> Epoch: 1013 / 99999 | Training loss: 29.02917 |  Training Accuracy: 4.56101 | Training Metric (MAE): 4.56101\n",
      "Validation Stage ==> Epoch: 1013 / 99999 | Validation loss: 29.53782 |  Validation Accuracy: 4.58373 | Validation Metric (MAE)): 4.58373\n",
      "Load Model from best epoch 1013\n",
      "Training Stage ==> Epoch: 1014 / 99999 | Training loss: 26.88444 |  Training Accuracy: 4.57234 | Training Metric (MAE): 4.57234\n",
      "Validation Stage ==> Epoch: 1014 / 99999 | Validation loss: 29.53495 |  Validation Accuracy: 4.58348 | Validation Metric (MAE)): 4.58348\n",
      "Load Model from best epoch 1014\n",
      "Training Stage ==> Epoch: 1015 / 99999 | Training loss: 29.85826 |  Training Accuracy: 4.55641 | Training Metric (MAE): 4.55641\n",
      "Validation Stage ==> Epoch: 1015 / 99999 | Validation loss: 29.53207 |  Validation Accuracy: 4.58323 | Validation Metric (MAE)): 4.58323\n",
      "Load Model from best epoch 1015\n",
      "Training Stage ==> Epoch: 1016 / 99999 | Training loss: 29.07619 |  Training Accuracy: 4.56867 | Training Metric (MAE): 4.56867\n",
      "Validation Stage ==> Epoch: 1016 / 99999 | Validation loss: 29.52921 |  Validation Accuracy: 4.58298 | Validation Metric (MAE)): 4.58298\n",
      "Load Model from best epoch 1016\n",
      "Training Stage ==> Epoch: 1017 / 99999 | Training loss: 28.32192 |  Training Accuracy: 4.57054 | Training Metric (MAE): 4.57054\n",
      "Validation Stage ==> Epoch: 1017 / 99999 | Validation loss: 29.52633 |  Validation Accuracy: 4.58273 | Validation Metric (MAE)): 4.58273\n",
      "Load Model from best epoch 1017\n",
      "Training Stage ==> Epoch: 1018 / 99999 | Training loss: 28.50287 |  Training Accuracy: 4.55606 | Training Metric (MAE): 4.55606\n",
      "Validation Stage ==> Epoch: 1018 / 99999 | Validation loss: 29.52346 |  Validation Accuracy: 4.58248 | Validation Metric (MAE)): 4.58248\n",
      "Load Model from best epoch 1018\n",
      "Training Stage ==> Epoch: 1019 / 99999 | Training loss: 29.60691 |  Training Accuracy: 4.55833 | Training Metric (MAE): 4.55833\n",
      "Validation Stage ==> Epoch: 1019 / 99999 | Validation loss: 29.52060 |  Validation Accuracy: 4.58223 | Validation Metric (MAE)): 4.58223\n",
      "Load Model from best epoch 1019\n",
      "Training Stage ==> Epoch: 1020 / 99999 | Training loss: 29.68681 |  Training Accuracy: 4.55244 | Training Metric (MAE): 4.55244\n",
      "Validation Stage ==> Epoch: 1020 / 99999 | Validation loss: 29.51773 |  Validation Accuracy: 4.58198 | Validation Metric (MAE)): 4.58198\n",
      "Load Model from best epoch 1020\n",
      "Training Stage ==> Epoch: 1021 / 99999 | Training loss: 29.89524 |  Training Accuracy: 4.56224 | Training Metric (MAE): 4.56224\n",
      "Validation Stage ==> Epoch: 1021 / 99999 | Validation loss: 29.51486 |  Validation Accuracy: 4.58173 | Validation Metric (MAE)): 4.58173\n",
      "Load Model from best epoch 1021\n",
      "Training Stage ==> Epoch: 1022 / 99999 | Training loss: 29.24668 |  Training Accuracy: 4.56459 | Training Metric (MAE): 4.56459\n",
      "Validation Stage ==> Epoch: 1022 / 99999 | Validation loss: 29.51199 |  Validation Accuracy: 4.58148 | Validation Metric (MAE)): 4.58148\n",
      "Load Model from best epoch 1022\n",
      "Training Stage ==> Epoch: 1023 / 99999 | Training loss: 28.93149 |  Training Accuracy: 4.56134 | Training Metric (MAE): 4.56134\n",
      "Validation Stage ==> Epoch: 1023 / 99999 | Validation loss: 29.50912 |  Validation Accuracy: 4.58123 | Validation Metric (MAE)): 4.58123\n",
      "Load Model from best epoch 1023\n",
      "Training Stage ==> Epoch: 1024 / 99999 | Training loss: 29.74517 |  Training Accuracy: 4.55534 | Training Metric (MAE): 4.55534\n",
      "Validation Stage ==> Epoch: 1024 / 99999 | Validation loss: 29.50626 |  Validation Accuracy: 4.58098 | Validation Metric (MAE)): 4.58098\n",
      "Load Model from best epoch 1024\n",
      "Training Stage ==> Epoch: 1025 / 99999 | Training loss: 29.37583 |  Training Accuracy: 4.55565 | Training Metric (MAE): 4.55565\n",
      "Validation Stage ==> Epoch: 1025 / 99999 | Validation loss: 29.50340 |  Validation Accuracy: 4.58073 | Validation Metric (MAE)): 4.58073\n",
      "Load Model from best epoch 1025\n",
      "Training Stage ==> Epoch: 1026 / 99999 | Training loss: 28.64583 |  Training Accuracy: 4.56845 | Training Metric (MAE): 4.56845\n",
      "Validation Stage ==> Epoch: 1026 / 99999 | Validation loss: 29.50054 |  Validation Accuracy: 4.58048 | Validation Metric (MAE)): 4.58048\n",
      "Load Model from best epoch 1026\n",
      "Training Stage ==> Epoch: 1027 / 99999 | Training loss: 29.02296 |  Training Accuracy: 4.55233 | Training Metric (MAE): 4.55233\n",
      "Validation Stage ==> Epoch: 1027 / 99999 | Validation loss: 29.49768 |  Validation Accuracy: 4.58023 | Validation Metric (MAE)): 4.58023\n",
      "Load Model from best epoch 1027\n",
      "Training Stage ==> Epoch: 1028 / 99999 | Training loss: 28.13525 |  Training Accuracy: 4.55090 | Training Metric (MAE): 4.55090\n",
      "Validation Stage ==> Epoch: 1028 / 99999 | Validation loss: 29.49482 |  Validation Accuracy: 4.57998 | Validation Metric (MAE)): 4.57998\n",
      "Load Model from best epoch 1028\n",
      "Training Stage ==> Epoch: 1029 / 99999 | Training loss: 28.62166 |  Training Accuracy: 4.55153 | Training Metric (MAE): 4.55153\n",
      "Validation Stage ==> Epoch: 1029 / 99999 | Validation loss: 29.49196 |  Validation Accuracy: 4.57973 | Validation Metric (MAE)): 4.57973\n",
      "Load Model from best epoch 1029\n",
      "Training Stage ==> Epoch: 1030 / 99999 | Training loss: 28.21459 |  Training Accuracy: 4.56398 | Training Metric (MAE): 4.56398\n",
      "Validation Stage ==> Epoch: 1030 / 99999 | Validation loss: 29.48910 |  Validation Accuracy: 4.57949 | Validation Metric (MAE)): 4.57949\n",
      "Load Model from best epoch 1030\n",
      "Training Stage ==> Epoch: 1031 / 99999 | Training loss: 27.07156 |  Training Accuracy: 4.55710 | Training Metric (MAE): 4.55710\n",
      "Validation Stage ==> Epoch: 1031 / 99999 | Validation loss: 29.48625 |  Validation Accuracy: 4.57924 | Validation Metric (MAE)): 4.57924\n",
      "Load Model from best epoch 1031\n",
      "Training Stage ==> Epoch: 1032 / 99999 | Training loss: 29.36078 |  Training Accuracy: 4.56441 | Training Metric (MAE): 4.56441\n",
      "Validation Stage ==> Epoch: 1032 / 99999 | Validation loss: 29.48339 |  Validation Accuracy: 4.57899 | Validation Metric (MAE)): 4.57899\n",
      "Load Model from best epoch 1032\n",
      "Training Stage ==> Epoch: 1033 / 99999 | Training loss: 28.28544 |  Training Accuracy: 4.55454 | Training Metric (MAE): 4.55454\n",
      "Validation Stage ==> Epoch: 1033 / 99999 | Validation loss: 29.48053 |  Validation Accuracy: 4.57874 | Validation Metric (MAE)): 4.57874\n",
      "Load Model from best epoch 1033\n",
      "Training Stage ==> Epoch: 1034 / 99999 | Training loss: 29.40948 |  Training Accuracy: 4.56020 | Training Metric (MAE): 4.56020\n",
      "Validation Stage ==> Epoch: 1034 / 99999 | Validation loss: 29.47767 |  Validation Accuracy: 4.57849 | Validation Metric (MAE)): 4.57849\n",
      "Load Model from best epoch 1034\n",
      "Training Stage ==> Epoch: 1035 / 99999 | Training loss: 27.94815 |  Training Accuracy: 4.55693 | Training Metric (MAE): 4.55693\n",
      "Validation Stage ==> Epoch: 1035 / 99999 | Validation loss: 29.47482 |  Validation Accuracy: 4.57824 | Validation Metric (MAE)): 4.57824\n",
      "Load Model from best epoch 1035\n",
      "Training Stage ==> Epoch: 1036 / 99999 | Training loss: 29.51221 |  Training Accuracy: 4.57035 | Training Metric (MAE): 4.57035\n",
      "Validation Stage ==> Epoch: 1036 / 99999 | Validation loss: 29.47196 |  Validation Accuracy: 4.57799 | Validation Metric (MAE)): 4.57799\n",
      "Load Model from best epoch 1036\n",
      "Training Stage ==> Epoch: 1037 / 99999 | Training loss: 29.42397 |  Training Accuracy: 4.55293 | Training Metric (MAE): 4.55293\n",
      "Validation Stage ==> Epoch: 1037 / 99999 | Validation loss: 29.46911 |  Validation Accuracy: 4.57774 | Validation Metric (MAE)): 4.57774\n",
      "Load Model from best epoch 1037\n",
      "Training Stage ==> Epoch: 1038 / 99999 | Training loss: 29.42735 |  Training Accuracy: 4.56401 | Training Metric (MAE): 4.56401\n",
      "Validation Stage ==> Epoch: 1038 / 99999 | Validation loss: 29.46625 |  Validation Accuracy: 4.57749 | Validation Metric (MAE)): 4.57749\n",
      "Load Model from best epoch 1038\n",
      "Training Stage ==> Epoch: 1039 / 99999 | Training loss: 28.21331 |  Training Accuracy: 4.57696 | Training Metric (MAE): 4.57696\n",
      "Validation Stage ==> Epoch: 1039 / 99999 | Validation loss: 29.46339 |  Validation Accuracy: 4.57724 | Validation Metric (MAE)): 4.57724\n",
      "Load Model from best epoch 1039\n",
      "Training Stage ==> Epoch: 1040 / 99999 | Training loss: 29.82922 |  Training Accuracy: 4.55467 | Training Metric (MAE): 4.55467\n",
      "Validation Stage ==> Epoch: 1040 / 99999 | Validation loss: 29.46054 |  Validation Accuracy: 4.57699 | Validation Metric (MAE)): 4.57699\n",
      "Load Model from best epoch 1040\n",
      "Training Stage ==> Epoch: 1041 / 99999 | Training loss: 29.39587 |  Training Accuracy: 4.55739 | Training Metric (MAE): 4.55739\n",
      "Validation Stage ==> Epoch: 1041 / 99999 | Validation loss: 29.45769 |  Validation Accuracy: 4.57675 | Validation Metric (MAE)): 4.57675\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_27236\\2947960070.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_27236\\1979633904.py\u001b[0m in \u001b[0;36mtrainModel\u001b[1;34m(self, process_factor, patiente, show_process, earlyStopFlag)\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m                     \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'./training/lossTraining_EPOCH_{epoch}'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlossTraining\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 175\u001b[1;33m                     \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'./training/accTraining_EPOCH_{epoch}'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccTraining\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    176\u001b[0m                     \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'./training/lossValidation_EPOCH_{epoch}'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlossValidation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m                     \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'./training/accValidation_EPOCH_{epoch}'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccValidation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36msave\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Miguel\\anaconda3\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(file, arr, allow_pickle, fix_imports)\u001b[0m\n\u001b[0;32m    527\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mfile_ctx\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfid\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    528\u001b[0m         \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 529\u001b[1;33m         format.write_array(fid, arr, allow_pickle=allow_pickle,\n\u001b[0m\u001b[0;32m    530\u001b[0m                            pickle_kwargs=dict(fix_imports=fix_imports))\n\u001b[0;32m    531\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "t.trainModel(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = DLModel(f.train, f.validate, f.testDATAFILE,  epoch = 100000, batch_size = 1024, learning_rate=2.6e-6, loadModelFlag = True, loadModelFile = './model/model_EPOCH_53915')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1024, 10]) torch.Size([1024, 19]) torch.Size([1024, 126])\n",
      "torch.Size([1024, 10]) torch.Size([1024, 19]) torch.Size([1024, 126])\n",
      "torch.Size([700, 10]) torch.Size([700, 19]) torch.Size([700, 126])\n",
      "Loss: 8.30034 |  Validation Accuracy: 2.51979\n"
     ]
    }
   ],
   "source": [
    "y, y_hat =t.testinfModel(t.test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7., 1., 8., ..., 8., 3., 3.], dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n",
      "4.3832307\n"
     ]
    }
   ],
   "source": [
    "for i in y_hat:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
