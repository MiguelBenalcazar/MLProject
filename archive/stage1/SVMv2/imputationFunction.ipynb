{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from itertools import product\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pickle\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "original = pd.read_csv('../html2023-spring-final-project/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingLabels = original['Danceability']\n",
    "original.drop(['Danceability'], axis=1, inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillOptions(data, option = 'max'):\n",
    "    if data.isna().sum() != len(data):\n",
    "        if option == 'max':\n",
    "            return data.value_counts().idxmax()\n",
    "        elif option == 'mean':\n",
    "            return data.mean()\n",
    "        elif option == 'median':\n",
    "            return data.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterArtistComposerDance(data, nameColumnFill):\n",
    "\n",
    "    listArtist = data['Artist'].unique()\n",
    "    listComposer = data['Composer'].unique()\n",
    "    \n",
    "    filter = list(product(listArtist, listComposer))\n",
    "\n",
    "    newData = pd.DataFrame(columns=data.columns)\n",
    "\n",
    "    for i in filter:\n",
    "        artist, composer = i[0], i[1]\n",
    "        filterData = data[(data['Artist'] == artist) & (data['Composer'] == composer) ].copy()\n",
    "        if len(filterData) != 0:\n",
    "            # Fill column Name\n",
    "            for nameColumn in nameColumnFill:\n",
    "                fillInfo = fillOptions(filterData[nameColumn], option = 'max')\n",
    "                if fillInfo != None:\n",
    "                    filterData.loc[:,nameColumn].fillna(fillInfo, inplace=True)\n",
    "\n",
    "            newData = pd.concat([newData, filterData], ignore_index=True)\n",
    "    return newData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterArtist(data, nameColumnFill):\n",
    "    listDance = data['Artist'].unique()\n",
    "    filter = listDance\n",
    "\n",
    "\n",
    "    newData = pd.DataFrame(columns=data.columns)\n",
    "\n",
    "    for i in filter:\n",
    "        dance = i\n",
    "        filterData = data[ (data['Artist'] == dance)].copy()\n",
    "    \n",
    "    \n",
    "        if len(filterData) != 0:\n",
    "            # Fill column Name\n",
    "            for nameColumn in nameColumnFill:\n",
    "                fillInfo = fillOptions(filterData[nameColumn], option = 'max')\n",
    "                if fillInfo != None:\n",
    "                    filterData.loc[:,nameColumn].fillna(fillInfo, inplace=True)\n",
    "\n",
    "            newData = pd.concat([newData, filterData], ignore_index=True)\n",
    "\n",
    "    return newData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterFillData(data, nameColumnFill):\n",
    "    if not data.isnull().any().any():\n",
    "        return data\n",
    "    else:\n",
    "        for nameColumn in nameColumnFill:\n",
    "            fillInfo = fillOptions(data[nameColumn], option = 'max')\n",
    "            if fillInfo != None:\n",
    "                data.loc[:,nameColumn].fillna(fillInfo, inplace=True)\n",
    "    return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataPreprocessing(original):\n",
    "    \n",
    "    # pd.options.mode.chained_assignment = None\n",
    "\n",
    "    data = original.copy()\n",
    "\n",
    "    nameColumnFill = ['Energy', 'Key', 'Loudness', 'Speechiness', 'Acousticness', 'Instrumentalness', 'Liveness', 'Valence', 'Tempo', 'Duration_ms', 'Duration_ms', 'Views', 'Likes', \"Stream\" , \"Comments\"]\n",
    "\n",
    "    # License and official_video\n",
    "    data['Licensed'].fillna(data['official_video'], inplace=True)\n",
    "    data['Licensed'].fillna(False, inplace=True)\n",
    "\n",
    "    data['official_video'].fillna(data['Licensed'], inplace=True)\n",
    "    data['official_video'].fillna(False, inplace=True)\n",
    "\n",
    "    data['official_video'].fillna(False, inplace=True)\n",
    "    data['Licensed'].fillna(False, inplace=True)\n",
    "\n",
    "    data['Licensed'] =  data['Licensed'].map({True: 1, False: 0})\n",
    "    data['official_video'] = data['official_video'].map({True: 1, False: 0})\n",
    "    \n",
    "    # Create new class = 'Unknown'\n",
    "    data['Composer'].fillna(\"Unknown\", inplace=True)\n",
    "    data['Artist'].fillna(\"Unknown\", inplace=True)\n",
    "    data['Album_type'].fillna(\"Unknown\", inplace=True)\n",
    "\n",
    "    newData = filterArtistComposerDance(data, nameColumnFill)\n",
    "    data = newData.copy()\n",
    "\n",
    "    newData = filterArtist(data, nameColumnFill)\n",
    "    data = newData.copy()\n",
    "\n",
    "    newData = filterFillData(data, nameColumnFill)\n",
    "    data = newData.copy()\n",
    "\n",
    "    #Transform type key to use as class\n",
    "    data['Key'] = data['Key'].astype(int)\n",
    "    data['Key'] = data['Key'].astype(str)\n",
    "\n",
    "    data = data.sort_values('id')\n",
    "\n",
    "    # DELETE Track, Album, Uri, Url_spotify, Url_youtube, Description, Title, Channel, id, Comments\n",
    "    data.drop(['Track', 'Album', 'Uri', 'Url_spotify', 'Url_youtube', 'Description', 'Title', 'Channel', 'id'], axis=1, inplace=True)\n",
    "\n",
    "    # pd.options.mode.chained_assignment = 'warn'\n",
    "\n",
    "    return data\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertEncoderPD(data, prefix = 'key'):\n",
    "    titleKeys = []\n",
    "    for i in range(data.shape[1]):\n",
    "        titleKeys.append(f'{prefix}_{i}')\n",
    "    \n",
    "    return pd.DataFrame(data=data, columns= titleKeys)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# minX -60  maxX = 0  ~ 0 - 1\n",
    "# y = (-1/60) x\n",
    "def scaleMinMaxLoudness(data):\n",
    "    return -data/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createEncodeDataTraining(data):\n",
    "\n",
    "    encoderKey = OneHotEncoder()\n",
    "    encodedKey = encoderKey.fit_transform(data[['Key']])\n",
    "    Key = encodedKey.toarray()\n",
    "    key_pd = convertEncoderPD(Key, prefix = 'key')\n",
    "\n",
    "    encoderAlbumType = OneHotEncoder()\n",
    "    encodedKeyAlbumType = encoderAlbumType.fit_transform(data[['Album_type']])\n",
    "    AlbumType = encodedKeyAlbumType.toarray()\n",
    "    AlbumType_pd = convertEncoderPD(AlbumType, prefix = 'AlbumType')\n",
    "\n",
    "    encoderComposer = OneHotEncoder()\n",
    "    encodedKeyComposer = encoderComposer.fit_transform(data[['Composer']])\n",
    "    Composer = encodedKeyComposer.toarray()\n",
    "    Composer_pd = convertEncoderPD(Composer, prefix = 'Composer')   \n",
    "\n",
    "    encoderArtist = LabelEncoder()\n",
    "    encodedArtist = encoderArtist.fit_transform(data[['Artist']])\n",
    "    # encodedArtist = encodedArtist.ravel()\n",
    "    Artist_pd =  pd.DataFrame(data=encodedArtist, columns= [\"Artist\"])\n",
    "\n",
    "    data.drop(['Key','Album_type', 'Composer',  'Artist'], axis=1, inplace=True)\n",
    "\n",
    "    data = pd.concat([data, key_pd, AlbumType_pd, Composer_pd, Artist_pd], axis=1)\n",
    "\n",
    "\n",
    "    scaledLoudness = scaleMinMaxLoudness(data[['Loudness']])\n",
    "    data['Loudness'] = scaledLoudness\n",
    "\n",
    "    newMinMaxScaler = ['Tempo', 'Duration_ms', 'Views', 'Likes', 'Stream', 'Comments', \"Artist\"]\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    scaledData = scaler.fit_transform(data[newMinMaxScaler])\n",
    "\n",
    "    for i in range(scaledData.shape[1]):\n",
    "        data[newMinMaxScaler[i]] = scaledData[:, i]\n",
    "\n",
    "\n",
    "    return {\"key\": encoderKey, 'AlbumType': encoderAlbumType, 'Composer': encoderComposer, \"Artist\":encoderArtist} , scaler, data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createEncodeDataTesting(encoder, scalerStandard, data):\n",
    "\n",
    "    encoderKey = encoder['key']\n",
    "    encodedKey = encoderKey.transform(data[['Key']])\n",
    "    Key = encodedKey.toarray()\n",
    "    key_pd = convertEncoderPD(Key, prefix = 'key')\n",
    "\n",
    "    encoderAlbumType = encoder['AlbumType']\n",
    "    encodedKeyAlbumType = encoderAlbumType.transform(data[['Album_type']])\n",
    "    AlbumType = encodedKeyAlbumType.toarray()\n",
    "    AlbumType_pd = convertEncoderPD(AlbumType, prefix = 'AlbumType')\n",
    "\n",
    "    encoderComposer = encoder['Composer']\n",
    "    encodedKeyComposer = encoderComposer.transform(data[['Composer']])\n",
    "    Composer = encodedKeyComposer.toarray()\n",
    "    Composer_pd = convertEncoderPD(Composer, prefix = 'Composer')   \n",
    "\n",
    "    encoderArtist = encoder['Artist']\n",
    "    encodedArtist = encoderArtist.transform(data[['Artist']])\n",
    "    encodedArtist = encodedArtist.ravel()\n",
    "    Artist_pd =  pd.DataFrame(data=encodedArtist, columns= [\"Artist\"])\n",
    "\n",
    "    data.drop(['Key','Album_type', 'Composer',  'Artist'], axis=1, inplace=True)\n",
    "\n",
    "    data = pd.concat([data, key_pd, AlbumType_pd, Composer_pd, Artist_pd], axis=1)\n",
    "\n",
    "    scaledLoudness = scaleMinMaxLoudness(data[['Loudness']])\n",
    "    data['Loudness'] = scaledLoudness\n",
    "\n",
    "    newMinMaxScaler = ['Tempo', 'Duration_ms', 'Views', 'Likes', 'Stream', 'Comments', \"Artist\"]\n",
    "\n",
    "    scaler = scalerStandard\n",
    "    scaledData = scaler.transform(data[newMinMaxScaler])\n",
    "\n",
    "    for i in range(scaledData.shape[1]):\n",
    "        data[newMinMaxScaler[i]] = scaledData[:, i]\n",
    "\n",
    "    return data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataPreprocessing(original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Miguel\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:115: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "encoders, scalerStandard, scaledData_pd  = createEncodeDataTraining(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_Y, test_Y = train_test_split(scaledData_pd, trainingLabels, test_size = 0.20, random_state = 123)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Miguel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "75 fits failed out of a total of 225.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "75 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Miguel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Miguel\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 255, in fit\n",
      "    fit(X, y, sample_weight, solver_type, kernel, random_seed=seed)\n",
      "  File \"c:\\Users\\Miguel\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 315, in _dense_fit\n",
      "    ) = libsvm.fit(\n",
      "  File \"sklearn\\svm\\_libsvm.pyx\", line 173, in sklearn.svm._libsvm.fit\n",
      "ValueError: 'polynomial' is not in list\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\Miguel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.19343336        nan 0.12368928 0.19343336        nan 0.1673707\n",
      " 0.19343336        nan 0.18469687 0.19343336        nan 0.14298163\n",
      " 0.19343336        nan 0.11888417 0.1927778         nan 0.16758915\n",
      " 0.1927778         nan 0.18833715 0.1927778         nan 0.17785346\n",
      " 0.1927778         nan 0.14574783 0.1927778         nan 0.12004905\n",
      " 0.19437958        nan 0.18833683 0.19437958        nan 0.19095745\n",
      " 0.19437958        nan 0.17312145 0.19437958        nan 0.14684001\n",
      " 0.19437958        nan 0.11997625]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 100, 'gamma': 0.001, 'kernel': 'linear'}\n",
      "0.19437957724425056\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Create the SVM classifier\n",
    "clf = SVC()\n",
    "\n",
    "# Create the grid of hyperparameters to search\n",
    "param_grid = {\n",
    "    \"C\": [1, 10, 100],\n",
    "    \"kernel\": ['linear', 'polynomial',\"rbf\"],\n",
    "    \"gamma\": [0.001, 0.01, 0.1, 1, 10],\n",
    "}\n",
    "\n",
    "# Create the grid search object\n",
    "grid_search = GridSearchCV(clf, param_grid, cv=5)\n",
    "\n",
    "# Fit the grid search object to the data\n",
    "grid_search.fit(train_X, train_Y)\n",
    "\n",
    "# Print the best parameters\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "# Print the best score\n",
    "print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = SVC(kernel='linear',  gamma=0.001, C=100)\n",
    "clf1.fit(train_X, train_Y)\n",
    "\n",
    "filename = \"best_SVM.model\"\n",
    "pickle.dump(clf1, open(filename, \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 2.33\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "loaded_model = pickle.load(open(filename, \"rb\"))\n",
    "# you can use loaded model to compute predictions\n",
    "predicted = loaded_model.predict(test_X)\n",
    "# predicted = np.rint(predicted)\n",
    "\n",
    "errors = abs(predicted - test_Y)\n",
    "# Print out the mean absolute error (mae)\n",
    "print('Mean Absolute Error:', round(np.mean(errors), 2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Testing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Miguel\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv('../html2023-spring-final-project/test.csv')\n",
    "dataTest = dataPreprocessing(test)\n",
    "testScaled = createEncodeDataTesting(encoders, scalerStandard, dataTest)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing Danceability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "loaded_model_realTest= pickle.load(open(filename, \"rb\"))\n",
    "# you can use loaded model to compute predictions\n",
    "predictedTest = loaded_model_realTest.predict(testScaled)\n",
    "predictedTest = np.rint(predictedTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = 17170\n",
    "idx = []\n",
    "for i in range(predictedTest.shape[0]):\n",
    "    idx.append(label + i)\n",
    "idx = np.array(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "testR = np.vstack((idx,predictedTest))\n",
    "testR = testR.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionTest_pd = pd.DataFrame(data = testR, columns= ['id', 'Danceability'])\n",
    "predictionTest_pd.to_csv('SVM2.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
