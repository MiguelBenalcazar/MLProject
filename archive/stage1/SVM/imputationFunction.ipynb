{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from itertools import product\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pickle\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "original = pd.read_csv('../html2023-spring-final-project/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingLabels = original['Danceability']\n",
    "original.drop(['Danceability'], axis=1, inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillOptions(data, option = 'max'):\n",
    "    if data.isna().sum() != len(data):\n",
    "        if option == 'max':\n",
    "            return data.value_counts().idxmax()\n",
    "        elif option == 'mean':\n",
    "            return data.mean()\n",
    "        elif option == 'median':\n",
    "            return data.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def verifyID(original, newData):\n",
    "#     noInNewData = original[~original['id'].isin(newData['id'])]\n",
    "#     return pd.concat([newData, noInNewData], ignore_index=True)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterArtistComposerDance(data, nameColumnFill):\n",
    "\n",
    "    listArtist = data['Artist'].unique()\n",
    "    listComposer = data['Composer'].unique()\n",
    "    \n",
    "    filter = list(product(listArtist, listComposer))\n",
    "\n",
    "    newData = pd.DataFrame(columns=data.columns)\n",
    "\n",
    "    for i in filter:\n",
    "        artist, composer = i[0], i[1]\n",
    "        filterData = data[(data['Artist'] == artist) & (data['Composer'] == composer) ].copy()\n",
    "        if len(filterData) != 0:\n",
    "            # Fill column Name\n",
    "            for nameColumn in nameColumnFill:\n",
    "                fillInfo = fillOptions(filterData[nameColumn], option = 'max')\n",
    "                if fillInfo != None:\n",
    "                    filterData.loc[:,nameColumn].fillna(fillInfo, inplace=True)\n",
    "\n",
    "            newData = pd.concat([newData, filterData], ignore_index=True)\n",
    "    return newData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterArtist(data, nameColumnFill):\n",
    "    listDance = data['Artist'].unique()\n",
    "    filter = listDance\n",
    "\n",
    "\n",
    "    newData = pd.DataFrame(columns=data.columns)\n",
    "\n",
    "    for i in filter:\n",
    "        dance = i\n",
    "        filterData = data[ (data['Artist'] == dance)].copy()\n",
    "    \n",
    "    \n",
    "        if len(filterData) != 0:\n",
    "            # Fill column Name\n",
    "            for nameColumn in nameColumnFill:\n",
    "                fillInfo = fillOptions(filterData[nameColumn], option = 'max')\n",
    "                if fillInfo != None:\n",
    "                    filterData.loc[:,nameColumn].fillna(fillInfo, inplace=True)\n",
    "\n",
    "            newData = pd.concat([newData, filterData], ignore_index=True)\n",
    "\n",
    "    return newData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterFillData(data, nameColumnFill):\n",
    "    if not data.isnull().any().any():\n",
    "        return data\n",
    "    else:\n",
    "        for nameColumn in nameColumnFill:\n",
    "            fillInfo = fillOptions(data[nameColumn], option = 'max')\n",
    "            if fillInfo != None:\n",
    "                data.loc[:,nameColumn].fillna(fillInfo, inplace=True)\n",
    "    return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataPreprocessing(original):\n",
    "    \n",
    "    data = original.copy()\n",
    "\n",
    "    nameColumnFill = ['Energy', 'Key', 'Loudness', 'Speechiness', 'Acousticness', 'Instrumentalness', 'Liveness', 'Valence', 'Tempo', 'Duration_ms', 'Duration_ms', 'Views', 'Likes', \"Stream\" , \"Comments\"]\n",
    "\n",
    "    # License and official_video\n",
    "    data['Licensed'].fillna(data['official_video'], inplace=True)\n",
    "    data['Licensed'].fillna(False, inplace=True)\n",
    "\n",
    "    data['official_video'].fillna(data['Licensed'], inplace=True)\n",
    "    data['official_video'].fillna(False, inplace=True)\n",
    "\n",
    "    data['official_video'].fillna(False, inplace=True)\n",
    "    data['Licensed'].fillna(False, inplace=True)\n",
    "\n",
    "    data['Licensed'].replace({True: 1, False: 0})\n",
    "    data['official_video'].replace({True: 1, False: 0})\n",
    "\n",
    "    # Create new class = 'Unknown'\n",
    "    data['Composer'].fillna(\"Unknown\", inplace=True)\n",
    "    data['Artist'].fillna(\"Unknown\", inplace=True)\n",
    "    data['Album_type'].fillna(\"Unknown\", inplace=True)\n",
    "\n",
    "    newData = filterArtistComposerDance(data, nameColumnFill)\n",
    "    data = newData.copy()\n",
    "\n",
    "    newData = filterArtist(data, nameColumnFill)\n",
    "    data = newData.copy()\n",
    "\n",
    "    newData = filterFillData(data, nameColumnFill)\n",
    "    data = newData.copy()\n",
    "\n",
    "    #Transform type key to use as class\n",
    "    data['Key'] = data['Key'].astype(int)\n",
    "    data['Key'] = data['Key'].astype(str)\n",
    "\n",
    "    data = data.sort_values('id')\n",
    "\n",
    "    # DELETE Track, Album, Uri, Url_spotify, Url_youtube, Description, Title, Channel, id, Comments\n",
    "    data.drop(['Track', 'Album', 'Uri', 'Url_spotify', 'Url_youtube', 'Description', 'Title', 'Channel', 'id'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "    return data\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertEncoderPD(data, prefix = 'key'):\n",
    "    titleKeys = []\n",
    "    for i in range(data.shape[1]):\n",
    "        titleKeys.append(f'{prefix}_{i}')\n",
    "    \n",
    "    return pd.DataFrame(data=data, columns= titleKeys)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createEncodeDataTraining(data):\n",
    "\n",
    "    encoderKey = OneHotEncoder()\n",
    "    encodedKey = encoderKey.fit_transform(data[['Key']])\n",
    "    Key = encodedKey.toarray()\n",
    "    key_pd = convertEncoderPD(Key, prefix = 'key')\n",
    "\n",
    "    encoderAlbumType = OneHotEncoder()\n",
    "    encodedKeyAlbumType = encoderAlbumType.fit_transform(data[['Album_type']])\n",
    "    AlbumType = encodedKeyAlbumType.toarray()\n",
    "    AlbumType_pd = convertEncoderPD(AlbumType, prefix = 'AlbumType')\n",
    "\n",
    "    encoderComposer = OneHotEncoder()\n",
    "    encodedKeyComposer = encoderComposer.fit_transform(data[['Composer']])\n",
    "    Composer = encodedKeyComposer.toarray()\n",
    "    Composer_pd = convertEncoderPD(Composer, prefix = 'Composer')   \n",
    "\n",
    "    encoderArtist = LabelEncoder()\n",
    "    encodedArtist = encoderArtist.fit_transform(data[['Artist']])\n",
    "    # encodedArtist = encodedArtist.ravel()\n",
    "    Artist_pd =  pd.DataFrame(data=encodedArtist, columns= [\"Artist\"])\n",
    "\n",
    "    data.drop(['Key','Album_type', 'Composer',  'Artist'], axis=1, inplace=True)\n",
    "\n",
    "    data = pd.concat([data, key_pd, AlbumType_pd, Composer_pd, Artist_pd], axis=1)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    scaledData = scaler.fit_transform(data)\n",
    "\n",
    "    scaledData_pd = pd.DataFrame(data=scaledData, columns= data.columns)\n",
    "\n",
    "    return {\"key\": encoderKey, 'AlbumType': encoderAlbumType, 'Composer': encoderComposer, \"Artist\":encoderArtist} , scaler, data, scaledData_pd\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createEncodeDataTesting(encoder, scalerStandard, data):\n",
    "\n",
    "    encoderKey = encoder['key']\n",
    "    encodedKey = encoderKey.transform(data[['Key']])\n",
    "    Key = encodedKey.toarray()\n",
    "    key_pd = convertEncoderPD(Key, prefix = 'key')\n",
    "\n",
    "    encoderAlbumType = encoder['AlbumType']\n",
    "    encodedKeyAlbumType = encoderAlbumType.transform(data[['Album_type']])\n",
    "    AlbumType = encodedKeyAlbumType.toarray()\n",
    "    AlbumType_pd = convertEncoderPD(AlbumType, prefix = 'AlbumType')\n",
    "\n",
    "    encoderComposer = encoder['Composer']\n",
    "    encodedKeyComposer = encoderComposer.transform(data[['Composer']])\n",
    "    Composer = encodedKeyComposer.toarray()\n",
    "    Composer_pd = convertEncoderPD(Composer, prefix = 'Composer')   \n",
    "\n",
    "    encoderArtist = encoder['Artist']\n",
    "    encodedArtist = encoderArtist.transform(data[['Artist']])\n",
    "    encodedArtist = encodedArtist.ravel()\n",
    "    Artist_pd =  pd.DataFrame(data=encodedArtist, columns= [\"Artist\"])\n",
    "\n",
    "    data.drop(['Key','Album_type', 'Composer',  'Artist'], axis=1, inplace=True)\n",
    "\n",
    "    data = pd.concat([data, key_pd, AlbumType_pd, Composer_pd, Artist_pd], axis=1)\n",
    "\n",
    "    scaler = scalerStandard\n",
    "    scaledData = scaler.transform(data)\n",
    "\n",
    "    scaledData_pd = pd.DataFrame(data=scaledData, columns= data.columns)\n",
    "\n",
    "    return data, scaledData_pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataPreprocessing(original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Miguel\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:115: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "encoders, scalerStandard, data, scaledData_pd = createEncodeDataTraining(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_Y, test_Y = train_test_split(scaledData_pd, trainingLabels, test_size = 0.20, random_state = 123)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.19474310734113012\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Create the SVM classifier\n",
    "clf = SVC()\n",
    "\n",
    "# Create the grid of hyperparameters to search\n",
    "param_grid = {\n",
    "    \"C\": [1, 10, 100],\n",
    "    \"kernel\": [\"rbf\"],\n",
    "    \"gamma\": [0.001, 0.01, 0.1, 1, 10],\n",
    "}\n",
    "\n",
    "# Create the grid search object\n",
    "grid_search = GridSearchCV(clf, param_grid, cv=5)\n",
    "\n",
    "# Fit the grid search object to the data\n",
    "grid_search.fit(train_X, train_Y)\n",
    "\n",
    "# Print the best parameters\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "# Print the best score\n",
    "print(grid_search.best_score_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train best Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = SVC(kernel='rbf', gamma=0.001)\n",
    "clf1.fit(train_X, train_Y)\n",
    "\n",
    "filename = \"best_SVM.model\"\n",
    "pickle.dump(clf1, open(filename, \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 2.3\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "loaded_model = pickle.load(open(filename, \"rb\"))\n",
    "# you can use loaded model to compute predictions\n",
    "predicted = loaded_model.predict(test_X)\n",
    "# predicted = np.rint(predicted)\n",
    "\n",
    "errors = abs(predicted - test_Y)\n",
    "# Print out the mean absolute error (mae)\n",
    "print('Mean Absolute Error:', round(np.mean(errors), 2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Testing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Miguel\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv('../html2023-spring-final-project/test.csv')\n",
    "dataTest = dataPreprocessing(test)\n",
    "testOriginal, testScaled = createEncodeDataTesting(encoders, scalerStandard, dataTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "loaded_model_realTest= pickle.load(open(filename, \"rb\"))\n",
    "# you can use loaded model to compute predictions\n",
    "predictedTest = loaded_model_realTest.predict(testScaled)\n",
    "predictedTest = np.rint(predictedTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = 17170\n",
    "idx = []\n",
    "for i in range(predictedTest.shape[0]):\n",
    "    idx.append(label + i)\n",
    "idx = np.array(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "testR = np.vstack((idx,predictedTest))\n",
    "testR = testR.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionTest_pd = pd.DataFrame(data = testR, columns= ['id', 'Danceability'])\n",
    "predictionTest_pd.to_csv('SVM.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
