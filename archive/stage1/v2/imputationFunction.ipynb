{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from itertools import product\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pickle\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "original = pd.read_csv('../html2023-spring-final-project/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingLabels = original['Danceability']\n",
    "original.drop(['Danceability'], axis=1, inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillOptions(data, option = 'max'):\n",
    "    if data.isna().sum() != len(data):\n",
    "        if option == 'max':\n",
    "            return data.value_counts().idxmax()\n",
    "        elif option == 'mean':\n",
    "            return data.mean()\n",
    "        elif option == 'median':\n",
    "            return data.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterArtistComposerDance(data, nameColumnFill):\n",
    "\n",
    "    listArtist = data['Artist'].unique()\n",
    "    listComposer = data['Composer'].unique()\n",
    "    \n",
    "    filter = list(product(listArtist, listComposer))\n",
    "\n",
    "    newData = pd.DataFrame(columns=data.columns)\n",
    "\n",
    "    for i in filter:\n",
    "        artist, composer = i[0], i[1]\n",
    "        filterData = data[(data['Artist'] == artist) & (data['Composer'] == composer) ].copy()\n",
    "        if len(filterData) != 0:\n",
    "            # Fill column Name\n",
    "            for nameColumn in nameColumnFill:\n",
    "                fillInfo = fillOptions(filterData[nameColumn], option = 'max')\n",
    "                if fillInfo != None:\n",
    "                    filterData.loc[:,nameColumn].fillna(fillInfo, inplace=True)\n",
    "\n",
    "            newData = pd.concat([newData, filterData], ignore_index=True)\n",
    "    return newData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterArtist(data, nameColumnFill):\n",
    "    listDance = data['Artist'].unique()\n",
    "    filter = listDance\n",
    "\n",
    "\n",
    "    newData = pd.DataFrame(columns=data.columns)\n",
    "\n",
    "    for i in filter:\n",
    "        dance = i\n",
    "        filterData = data[ (data['Artist'] == dance)].copy()\n",
    "    \n",
    "    \n",
    "        if len(filterData) != 0:\n",
    "            # Fill column Name\n",
    "            for nameColumn in nameColumnFill:\n",
    "                fillInfo = fillOptions(filterData[nameColumn], option = 'max')\n",
    "                if fillInfo != None:\n",
    "                    filterData.loc[:,nameColumn].fillna(fillInfo, inplace=True)\n",
    "\n",
    "            newData = pd.concat([newData, filterData], ignore_index=True)\n",
    "\n",
    "    return newData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterFillData(data, nameColumnFill):\n",
    "    if not data.isnull().any().any():\n",
    "        return data\n",
    "    else:\n",
    "        for nameColumn in nameColumnFill:\n",
    "            fillInfo = fillOptions(data[nameColumn], option = 'max')\n",
    "            if fillInfo != None:\n",
    "                data.loc[:,nameColumn].fillna(fillInfo, inplace=True)\n",
    "    return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataPreprocessing(original):\n",
    "    \n",
    "    # pd.options.mode.chained_assignment = None\n",
    "\n",
    "    data = original.copy()\n",
    "\n",
    "    nameColumnFill = ['Energy', 'Key', 'Loudness', 'Speechiness', 'Acousticness', 'Instrumentalness', 'Liveness', 'Valence', 'Tempo', 'Duration_ms', 'Duration_ms', 'Views', 'Likes', \"Stream\" , \"Comments\"]\n",
    "\n",
    "    # License and official_video\n",
    "    data['Licensed'].fillna(data['official_video'], inplace=True)\n",
    "    data['Licensed'].fillna(False, inplace=True)\n",
    "\n",
    "    data['official_video'].fillna(data['Licensed'], inplace=True)\n",
    "    data['official_video'].fillna(False, inplace=True)\n",
    "\n",
    "    data['official_video'].fillna(False, inplace=True)\n",
    "    data['Licensed'].fillna(False, inplace=True)\n",
    "\n",
    "    data['Licensed'] =  data['Licensed'].map({True: 1, False: 0})\n",
    "    data['official_video'] = data['official_video'].map({True: 1, False: 0})\n",
    "    \n",
    "    # Create new class = 'Unknown'\n",
    "    data['Composer'].fillna(\"Unknown\", inplace=True)\n",
    "    data['Artist'].fillna(\"Unknown\", inplace=True)\n",
    "    data['Album_type'].fillna(\"Unknown\", inplace=True)\n",
    "\n",
    "    newData = filterArtistComposerDance(data, nameColumnFill)\n",
    "    data = newData.copy()\n",
    "\n",
    "    newData = filterArtist(data, nameColumnFill)\n",
    "    data = newData.copy()\n",
    "\n",
    "    newData = filterFillData(data, nameColumnFill)\n",
    "    data = newData.copy()\n",
    "\n",
    "    #Transform type key to use as class\n",
    "    data['Key'] = data['Key'].astype(int)\n",
    "    data['Key'] = data['Key'].astype(str)\n",
    "\n",
    "    data = data.sort_values('id')\n",
    "\n",
    "    # DELETE Track, Album, Uri, Url_spotify, Url_youtube, Description, Title, Channel, id, Comments\n",
    "    data.drop(['Track', 'Album', 'Uri', 'Url_spotify', 'Url_youtube', 'Description', 'Title', 'Channel', 'id'], axis=1, inplace=True)\n",
    "\n",
    "    # pd.options.mode.chained_assignment = 'warn'\n",
    "\n",
    "    return data\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertEncoderPD(data, prefix = 'key'):\n",
    "    titleKeys = []\n",
    "    for i in range(data.shape[1]):\n",
    "        titleKeys.append(f'{prefix}_{i}')\n",
    "    \n",
    "    return pd.DataFrame(data=data, columns= titleKeys)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# minX -60  maxX = 0  ~ 0 - 1\n",
    "# y = (-1/60) x\n",
    "def scaleMinMaxLoudness(data):\n",
    "    return -data/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createEncodeDataTraining(data):\n",
    "\n",
    "    encoderKey = OneHotEncoder()\n",
    "    encodedKey = encoderKey.fit_transform(data[['Key']])\n",
    "    Key = encodedKey.toarray()\n",
    "    key_pd = convertEncoderPD(Key, prefix = 'key')\n",
    "\n",
    "    encoderAlbumType = OneHotEncoder()\n",
    "    encodedKeyAlbumType = encoderAlbumType.fit_transform(data[['Album_type']])\n",
    "    AlbumType = encodedKeyAlbumType.toarray()\n",
    "    AlbumType_pd = convertEncoderPD(AlbumType, prefix = 'AlbumType')\n",
    "\n",
    "    encoderComposer = OneHotEncoder()\n",
    "    encodedKeyComposer = encoderComposer.fit_transform(data[['Composer']])\n",
    "    Composer = encodedKeyComposer.toarray()\n",
    "    Composer_pd = convertEncoderPD(Composer, prefix = 'Composer')   \n",
    "\n",
    "    encoderArtist = LabelEncoder()\n",
    "    encodedArtist = encoderArtist.fit_transform(data[['Artist']])\n",
    "    # encodedArtist = encodedArtist.ravel()\n",
    "    Artist_pd =  pd.DataFrame(data=encodedArtist, columns= [\"Artist\"])\n",
    "\n",
    "    data.drop(['Key','Album_type', 'Composer',  'Artist'], axis=1, inplace=True)\n",
    "\n",
    "    data = pd.concat([data, key_pd, AlbumType_pd, Composer_pd, Artist_pd], axis=1)\n",
    "\n",
    "\n",
    "    scaledLoudness = scaleMinMaxLoudness(data[['Loudness']])\n",
    "    data['Loudness'] = scaledLoudness\n",
    "\n",
    "    newMinMaxScaler = ['Tempo', 'Duration_ms', 'Views', 'Likes', 'Stream', 'Comments', \"Artist\"]\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    scaledData = scaler.fit_transform(data[newMinMaxScaler])\n",
    "\n",
    "    for i in range(scaledData.shape[1]):\n",
    "        data[newMinMaxScaler[i]] = scaledData[:, i]\n",
    "\n",
    "\n",
    "    return {\"key\": encoderKey, 'AlbumType': encoderAlbumType, 'Composer': encoderComposer, \"Artist\":encoderArtist} , scaler, data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createEncodeDataTesting(encoder, scalerStandard, data):\n",
    "\n",
    "    encoderKey = encoder['key']\n",
    "    encodedKey = encoderKey.transform(data[['Key']])\n",
    "    Key = encodedKey.toarray()\n",
    "    key_pd = convertEncoderPD(Key, prefix = 'key')\n",
    "\n",
    "    encoderAlbumType = encoder['AlbumType']\n",
    "    encodedKeyAlbumType = encoderAlbumType.transform(data[['Album_type']])\n",
    "    AlbumType = encodedKeyAlbumType.toarray()\n",
    "    AlbumType_pd = convertEncoderPD(AlbumType, prefix = 'AlbumType')\n",
    "\n",
    "    encoderComposer = encoder['Composer']\n",
    "    encodedKeyComposer = encoderComposer.transform(data[['Composer']])\n",
    "    Composer = encodedKeyComposer.toarray()\n",
    "    Composer_pd = convertEncoderPD(Composer, prefix = 'Composer')   \n",
    "\n",
    "    encoderArtist = encoder['Artist']\n",
    "    encodedArtist = encoderArtist.transform(data[['Artist']])\n",
    "    encodedArtist = encodedArtist.ravel()\n",
    "    Artist_pd =  pd.DataFrame(data=encodedArtist, columns= [\"Artist\"])\n",
    "\n",
    "    data.drop(['Key','Album_type', 'Composer',  'Artist'], axis=1, inplace=True)\n",
    "\n",
    "    data = pd.concat([data, key_pd, AlbumType_pd, Composer_pd, Artist_pd], axis=1)\n",
    "\n",
    "    scaledLoudness = scaleMinMaxLoudness(data[['Loudness']])\n",
    "    data['Loudness'] = scaledLoudness\n",
    "\n",
    "    newMinMaxScaler = ['Tempo', 'Duration_ms', 'Views', 'Likes', 'Stream', 'Comments', \"Artist\"]\n",
    "\n",
    "    scaler = scalerStandard\n",
    "    scaledData = scaler.transform(data[newMinMaxScaler])\n",
    "\n",
    "    for i in range(scaledData.shape[1]):\n",
    "        data[newMinMaxScaler[i]] = scaledData[:, i]\n",
    "\n",
    "    return data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataPreprocessing(original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Miguel\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:115: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "encoders, scalerStandard, scaledData_pd  = createEncodeDataTraining(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_Y, test_Y = train_test_split(scaledData_pd, trainingLabels, test_size = 0.20, random_state = 123)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the model we are using\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Instantiate model with 1000 decision trees\n",
    "rf = RandomForestRegressor(n_estimators = 1000, random_state = 42)\n",
    "# Train the model on training data\n",
    "rf.fit(train_X, train_Y)\n",
    "\n",
    "filename = \"random_forest_regressor.md\"\n",
    "pickle.dump(rf, open(filename, \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 1.76\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "loaded_model = pickle.load(open(filename, \"rb\"))\n",
    "# you can use loaded model to compute predictions\n",
    "predicted = loaded_model.predict(test_X)\n",
    "# predicted = np.rint(predicted)\n",
    "\n",
    "errors = abs(predicted - test_Y)\n",
    "# Print out the mean absolute error (mae)\n",
    "print('Mean Absolute Error:', round(np.mean(errors), 2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Testing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Miguel\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv('../html2023-spring-final-project/test.csv')\n",
    "dataTest = dataPreprocessing(test)\n",
    "testScaled = createEncodeDataTesting(encoders, scalerStandard, dataTest)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing Danceability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "loaded_model_realTest= pickle.load(open(filename, \"rb\"))\n",
    "# you can use loaded model to compute predictions\n",
    "predictedTest = loaded_model_realTest.predict(testScaled)\n",
    "predictedTest = np.rint(predictedTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = 17170\n",
    "idx = []\n",
    "for i in range(predictedTest.shape[0]):\n",
    "    idx.append(label + i)\n",
    "idx = np.array(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "testR = np.vstack((idx,predictedTest))\n",
    "testR = testR.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionTest_pd = pd.DataFrame(data = testR, columns= ['id', 'Danceability'])\n",
    "predictionTest_pd.to_csv('RainForestRegressor2.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
